<?xml version="1.0" encoding="UTF-8"?>
<root><element><date><![CDATA[2012-04-17]]></date><papers/><sessions><element><id><![CDATA[3]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Registro]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[16]]></id><name><![CDATA[Sala Berlín]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[2]]></id><identifier><![CDATA[MA1]]></identifier><name><![CDATA[Inauguración]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:45:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[14]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Pausa]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:20:00]]></start><end><![CDATA[10:30:00]]></end><location><![CDATA[]]></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[4]]></id><identifier><![CDATA[MB1]]></identifier><name><![CDATA[Conferencia plenaria]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[446]]></id><normalized_name><![CDATA[D. Rios Insua]]></normalized_name><name><![CDATA[David ]]></name><lastname><![CDATA[Rios Insua]]></lastname></chairperson><papers><element><id><![CDATA[208]]></id><title><![CDATA[The Statistics of Climate Change]]></title><text><![CDATA[Statisticians have been involved in climate change research in numerous ways, from the assessment of trends in climatic time series through to the processing of large spatial-temporal datasets both from observational networks and from climate models. In this talk, I shall give an overview of some of the different ways that statistical analysis has entered climate science, illustrated by some specific examples from my own research. The examples are likely to cover: (a) methods for detecting trends in correlated time series, (b) how to determine whether observed trends are due to human causes (detection and attribution), (c) paleoclimatology and the ``hockey stick", (d) the problem of single-event attribution: how a single extreme event, such as Hurricane Katrina or the European heatwave of 2003, can be attributed to human as opposed to natural causes. ]]></text><keywords><![CDATA[Climate change]]></keywords><authors/></element></papers></element><element><id><![CDATA[6]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Pausa - Café]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[11:30:00]]></start><end><![CDATA[12:00:00]]></end><location><id><![CDATA[17]]></id><name><![CDATA[Hall Plaza Mayor]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[107]]></id><identifier><![CDATA[MC1]]></identifier><name><![CDATA[Métodos bayesianos 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[226]]></id><normalized_name><![CDATA[J. M. Bernardo]]></normalized_name><name><![CDATA[Jose Miguel]]></name><lastname><![CDATA[Bernardo]]></lastname></chairperson><papers><element><id><![CDATA[41]]></id><title><![CDATA[The intrinsic and the fractional bayes factors for model selection with right censored weibull responses]]></title><text><![CDATA[In this work we consider the problem of covariate selection in Weibull regression analysis for right censored data under an objective Bayesian point of view using the usual improper prior for location-scale models. We compare each candidate model with a null reference model. Model comparison is approached via the intrinsic Bayes Factor (IBF) of Berger and Pericchi (JASA, 1996) and the fractional BF (FBF) of O'Hagan (J. Roy. Statist Soc., 1995). Because of censoring (Berger and Pericchi, Ann.Stat, 2004) we need to define a suitable minimal training sample (MTS) that accounts for censoring. We address this problem using sequential MTS (SMTS) for which the MTS sample size, N, is random. We derive its probability distribution P(N) and show that averaging the conditional (on N) FBF over P(N) may be a feasible alternative to the IBF with SMTS for searching over a large space of models. Comparisons between FBF and IBF are made with a simulation study and an application to a real data set.]]></text><keywords><![CDATA[improper priors, regression, training sample]]></keywords><authors><element><attendee_id><![CDATA[194]]></attendee_id><normalized_name><![CDATA[S. Perra]]></normalized_name><name><![CDATA[Silvia]]></name><lastname><![CDATA[Perra]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Cabras]]></normalized_name><name><![CDATA[Stefano]]></name><lastname><![CDATA[Cabras]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[357]]></attendee_id><normalized_name><![CDATA[M. E. Castellanos Nueda]]></normalized_name><name><![CDATA[Maria Eugenia]]></name><lastname><![CDATA[Castellanos Nueda]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[93]]></id><title><![CDATA[A new family of density functions on the interval (0,1)]]></title><text><![CDATA[A new family of density functions on the interval (0,1) arises from an agreement between frequentist and Bayesian approaches for the multivariate point null testing problem. A mixed prior distribution is used for constructing the p-value by means of a system of least favourable answers. Lindley’s paradox is connected with the axiom of choice. Asymptotic properties are studied and show that the discrepancy in the sense of Berger and Sellke (1987) between both methods does not exist in the two dimensional case.]]></text><keywords><![CDATA[Lindley's paradox, multivariate point null testing problem]]></keywords><authors><element><attendee_id><![CDATA[231]]></attendee_id><normalized_name><![CDATA[B. González Pérez]]></normalized_name><name><![CDATA[Beatriz]]></name><lastname><![CDATA[González Pérez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[300]]></attendee_id><normalized_name><![CDATA[M. Á. Gómez Villegas]]></normalized_name><name><![CDATA[Miguel Ángel ]]></name><lastname><![CDATA[Gómez Villegas]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[103]]></id><title><![CDATA[Heterogeneity in Bayesian stochastic frontier models]]></title><text><![CDATA[Estimation of the one sided error component in stochastic frontier models may erroneously attribute firm characteristics to inefficiency if heterogeneity is not accounted for. However, it is not clear in general in which component of the error distribution the covariates should be included. In the classical context, some studies include covariates in the scale parameter of the inefficiency distribution and in this paper, we extend this idea to Bayesian stochastic frontier models by capturing both observed and unobserved heterogeneity in the scale parameter of half normal, truncated normal and exponentially distributed inefficiencies. Our findings from two real data sets illustrate the relevant effects on shrinking and separating individual posterior efficiencies when heterogeneity is captured in the scale parameter of the inefficiency. We also see that the inclusion of unobserved heterogeneity is relevant when no observable covariates are available.]]></text><keywords><![CDATA[estadística ]]></keywords><authors><element><attendee_id><![CDATA[304]]></attendee_id><normalized_name><![CDATA[J. Galán Camacho]]></normalized_name><name><![CDATA[Jorge]]></name><lastname><![CDATA[Galán Camacho]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[H. Veiga]]></normalized_name><name><![CDATA[Helena]]></name><lastname><![CDATA[Veiga]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Wiper]]></normalized_name><name><![CDATA[Michael]]></name><lastname><![CDATA[Wiper]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[40]]></id><title><![CDATA[Distribuciones de referencia globales]]></title><text><![CDATA[En modelos multiparamétricos, las distribuciones iniciales de referencia dependen de la cantidad de interés, lo que resulta necesario para que las correspondientes distribuciones finales tengan las características más apropiadas. Sin embargo, existen muchas situaciones en las que el investigador está simultáneamente interesado en varias funciones de los parámetros del modelo, y resulta entonces conveniente identíficar una única distribución inicial objetiva que pueda ser utilizada para producir distribuciones finales marginales razonables para todas las magnitudes de interés. En este trabajo se propone un criterio para determinar una distribución inicial conjunta global, capaz de producir distribuciones marginales para todas las magnitudes de interés con un comportamiento aproximado al de las distribuciones posteriores de referencia correspondientes. La metodología utilizada es la teoría de la decisión, con funciones de pérdida basadas en la teoría de la información.]]></text><keywords><![CDATA[metodos bayesianos objetivos, distribuciones de referencia, medidas de discrepancia]]></keywords><authors/></element></papers></element><element><id><![CDATA[72]]></id><identifier><![CDATA[MC2]]></identifier><name><![CDATA[Decisión multicriterio 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[239]]></id><normalized_name><![CDATA[C. Gutiérrez Vaquero]]></normalized_name><name><![CDATA[César]]></name><lastname><![CDATA[Gutiérrez Vaquero]]></lastname></chairperson><papers><element><id><![CDATA[185]]></id><title><![CDATA[Medida de la intensidad de preferencia en MAUT con pesos difusos]]></title><text><![CDATA[Se propone un método basado en la intensidad de preferencia para la ordenación de las alternativas en problemas de decisión multicriterio imprecisos, en base a la Teoría de la Utilidad y la Lógica Borrosa. Consideramos que las consecuencias de las alternativas se representan mediante intervalos y la imprecisión en las preferencias de los decisores con clases de funciones de utilidad y pesos difusos trapezoidales. El método se basa en el concepto de dominación entre pares de alternativas, valores que se obtienen resolviendo problemas de optimización lineales, gracias al uso del modelo multiatributo aditivo. Los valores de dominación se transforman en medidas de intensidad de preferencia utilizando una distancia entre números difusos. Analizamos la calidad del método utilizando simulación Montecarlo a partir de la proporción de veces que el método proporciona como mejor alternativa aquella que lo es y la correlación que existe entre la ordenación proporcionada por el método y la real.]]></text><keywords><![CDATA[decisión multicriterio, lógica borrosa.]]></keywords><authors><element><attendee_id><![CDATA[358]]></attendee_id><normalized_name><![CDATA[P. Sabio Flores]]></normalized_name><name><![CDATA[Pilar]]></name><lastname><![CDATA[Sabio Flores]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[130]]></attendee_id><normalized_name><![CDATA[A. Jiménez Martín]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Jiménez Martín]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[234]]></attendee_id><normalized_name><![CDATA[A. Mateos]]></normalized_name><name><![CDATA[Alfonso]]></name><lastname><![CDATA[Mateos]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[72]]></id><title><![CDATA[Intensidad de preferencia en MCDM con información incompleta]]></title><text><![CDATA[El modelo de utilidad multiatributo aditivo se utiliza ampliamente en problemas de decisión reales, siendo habitual que haya información imprecisa asociada a las preferencias de los decisores. Un enfoque para la toma de decisión en esta situación son los denominados métodos basados en la intensidad de preferencia, que toman como punto de partida la diferencia de utilidades entre pares de alternativas. En este trabajo proponemos un nuevo método basado en la intensidad preferencia considerando información ordinal tanto sobre los pesos de los criterios como en las utilidades de las alternativas. El método calcula para cada alternativa su intensidad de preferencia, en función de la intensidad con la que esta alternativa es preferida al resto y el resto son preferidas a ella, ponderada con la distancia entre el vector de pesos óptimo obtenido en el cálculo de la intensidad de preferencia y el centroide del conjunto de restricciones considerado en ese mismo problema de optimización.]]></text><keywords><![CDATA[modelo de utilidad multi-atributo, información incompleta, intensidad de preferencia]]></keywords><authors><element><attendee_id><![CDATA[248]]></attendee_id><normalized_name><![CDATA[E. A. Aguayo Garcia]]></normalized_name><name><![CDATA[Ernesto Aaron]]></name><lastname><![CDATA[Aguayo Garcia]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[234]]></attendee_id><normalized_name><![CDATA[A. Mateos]]></normalized_name><name><![CDATA[Alfonso]]></name><lastname><![CDATA[Mateos]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[130]]></attendee_id><normalized_name><![CDATA[A. Jiménez Martín]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Jiménez Martín]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[213]]></id><title><![CDATA[Algoritmo geométrico para la resolución de diagramas de influencia con múltiples objetivos]]></title><text><![CDATA[Los diagramas de influencia (DI) son modelos gráficos utilizados para la representación y resolución de problemas de decisión bajo incertidumbre. Los DI normalmente se utilizan bien con un solo nodo objetivo, u organizando los objetivos en un modelo tipo MAUT. El algoritmo geométrico que presentamos resuelve un DI con múltiples objetivos independientes, es decir, sin suponer a priori ningún modelo de preferencias, aproximando su conjunto de estrategias eficientes. Está basado en un método de aproximación adaptiva poliédrica de los conjuntos convexos, y hace uso de cualquier algoritmo de resolución de un DI con un solo objetivo. El algoritmo ofrece las siguientes ventajas: a) El proceso de aproximación puede ser interrumpido en cualquier momento, conociendo la precisión de la aproximación. b) Con un número de estrategias elevado el presente método seguirá siendo eficiente. c) El presente método se puede adaptar a cualquier algoritmo de resolución de DIs, lo cual amplía su aplicabilidad.]]></text><keywords><![CDATA[optimización multiobjetivo, diagramas de influencia, algoritmo geométrico]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Arronte Álvarez]]></normalized_name><name><![CDATA[Aitor]]></name><lastname><![CDATA[Arronte Álvarez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[51]]></id><title><![CDATA[Conceptos de eficiencia aproximada equivalentes en optimización multiobjetivo]]></title><text><![CDATA[Para definir la noción de solución aproximada de un problema de optimización multiobjetivo se han introducido en la literatura varios conceptos. A través de conjuntos coradiantes mostraremos distintas relaciones entre ellos basadas en la elección de determinados parámetros que los determinan.]]></text><keywords><![CDATA[optimización multiobjetivo, solución aproximada, conjunto coradiante]]></keywords><authors><element><attendee_id><![CDATA[239]]></attendee_id><normalized_name><![CDATA[C. Gutiérrez Vaquero]]></normalized_name><name><![CDATA[César]]></name><lastname><![CDATA[Gutiérrez Vaquero]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[116]]></attendee_id><normalized_name><![CDATA[V. Novo Sanjurjo]]></normalized_name><name><![CDATA[Vicente]]></name><lastname><![CDATA[Novo Sanjurjo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[B. Jiménez Martín]]></normalized_name><name><![CDATA[Bienvenido]]></name><lastname><![CDATA[Jiménez Martín]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[111]]></id><identifier><![CDATA[MC3]]></identifier><name><![CDATA[Bioestadística 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[8]]></id><name><![CDATA[Sala Londres]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[381]]></id><normalized_name><![CDATA[S. Barragan Andres]]></normalized_name><name><![CDATA[Sandra]]></name><lastname><![CDATA[Barragan Andres]]></lastname></chairperson><papers><element><id><![CDATA[313]]></id><title><![CDATA[Stochastic modelling for bacterial growth]]></title><text><![CDATA[Bacterial growth models are commonly used in food safety for the prediction of microbial safety and the shelf life of perishable foods. Statistical methods for the analysis of growth curves have been widely studied, nevertheless many challenging problems remain.  Bacterial growth is observed in Petri dish experiments and the experiment can be replicated several times under the same conditions. Even when the conditions are the same, the observed curves are different, reflecting the intrinsic variability of the growth process. The main idea developed in this paper is to introduce  stochastic variability into the deterministic Gompertz growth process by subordination. The resulting stochastic growth model is monotonically nondecreasing and its mean trajectory follows the classical Gompertz equation.  We also show how the model can be fitted using a Bayesian approach and we illustrate the methods using real data from a bacterial growth experiment.]]></text><keywords><![CDATA[stochastic growth models, bayesian inference, subordination, bacterial growth]]></keywords><authors><element><attendee_id><![CDATA[473]]></attendee_id><normalized_name><![CDATA[A. P. Palacios]]></normalized_name><name><![CDATA[Ana Paula]]></name><lastname><![CDATA[Palacios]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. M. Marín Diazaraque]]></normalized_name><name><![CDATA[Juan Miguel]]></name><lastname><![CDATA[Marín Diazaraque]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. P. Wiper]]></normalized_name><name><![CDATA[Michael Peter]]></name><lastname><![CDATA[Wiper]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[202]]></id><title><![CDATA[Selección de puntos de corte óptimos en las pruebas diagnósticas: el paquete en R OptimalCutpoints ]]></title><text><![CDATA[Las pruebas diagnósticas continuas a menudo son empleadas para discriminar entre las poblaciones que presentan o no una determinada enfermedad. Para su aplicación rutinaria en la práctica clínica, es necesario seleccionar un punto de corte o valor de discriminación c de forma que en general, los individuos con un valor de la prueba ? c se clasifican como enfermos. Surge entonces el problema de la búsqueda del ``mejor'' punto de corte c. Se han propuesto diversas estrategias para la selección de puntos de corte óptimos dependiendo del objetivo que se persiga con tal elección. El paquete en R OptimalCutpoints que hemos diseñado permite elegir entre diversos criterios para la obtención del valor óptimo en el ámbito de las pruebas diagnósticas. Se han incorporado métodos que tienen en cuenta los costes de las posibles decisiones del diagnóstico y/o la prevalencia de la enfermedad, y criterios basados en las diferentes medidas de la capacidad diagnóstica de la prueba.]]></text><keywords><![CDATA[pruebas diagnósticas,puntos de corte óptimos,R]]></keywords><authors><element><attendee_id><![CDATA[396]]></attendee_id><normalized_name><![CDATA[M. López Ratón]]></normalized_name><name><![CDATA[Mónica]]></name><lastname><![CDATA[López Ratón]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. X. Rodríguez Álvarez]]></normalized_name><name><![CDATA[María Xosé ]]></name><lastname><![CDATA[Rodríguez Álvarez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Cadarso Suárez]]></normalized_name><name><![CDATA[Carmen]]></name><lastname><![CDATA[Cadarso Suárez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Gude Sampedro]]></normalized_name><name><![CDATA[Francisco]]></name><lastname><![CDATA[Gude Sampedro]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[228]]></id><title><![CDATA[Métodos de fusión de órdenes circulares con aplicaciones en la biología molecular]]></title><text><![CDATA[La motivación de este problema surge en el contexto de la biología molecular. El ciclo de división celular es un proceso de las células eucariotas en el que intervienen ciertos genes con expresión periódica en el tiempo de los cuales nos interesará su momento de máxima expresión. Se sospecha que el orden circular de la expresión máxima de un conjunto básico de genes se conserva en diferentes especies. Recientemente hemos desarrollado un procedimiento de contraste de hipótesis que permite decidir si un conjunto de genes, común a varias especies, sigue un cierto orden. El objetivo de este trabajo es encontrar dicho orden circular que resuma convenientemente los órdenes circulares procedentes de las diferentes especies. Para ello consideramos algunos métodos de fusión de rankings, desarrollados en la recta real, adaptándolos al círculo. Además de la resolución del problema planteado se presentan las diferentes simulaciones realizadas para comparar todos los métodos expuestos.]]></text><keywords><![CDATA[orden circular, fusión de rankings, expresión de genes, ciclo celular]]></keywords><authors><element><attendee_id><![CDATA[381]]></attendee_id><normalized_name><![CDATA[S. Barragan Andres]]></normalized_name><name><![CDATA[Sandra]]></name><lastname><![CDATA[Barragan Andres]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. A. Fernández Temprano]]></normalized_name><name><![CDATA[Miguel Alejandro]]></name><lastname><![CDATA[Fernández Temprano]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[551]]></attendee_id><normalized_name><![CDATA[C. Rueda Sabater]]></normalized_name><name><![CDATA[Cristina]]></name><lastname><![CDATA[Rueda Sabater]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. D. Peddada]]></normalized_name><name><![CDATA[Shyamal D.]]></name><lastname><![CDATA[Peddada]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[58]]></id><identifier><![CDATA[MC4]]></identifier><name><![CDATA[Problemas de secuenciación]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[9]]></id><name><![CDATA[Sala París]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[351]]></id><normalized_name><![CDATA[R. Ruiz García]]></normalized_name><name><![CDATA[Rubén]]></name><lastname><![CDATA[Ruiz García]]></lastname></chairperson><papers><element><id><![CDATA[16]]></id><title><![CDATA[Estado del arte del problema de flujo general flexible con costes en la función objetivo]]></title><text><![CDATA[En el ámbito de la programación de operaciones en taller un importante número de investigaciones se han destinado al estudio del problema de flujo general flexible o fJSP. En el fJSP existen m máquinas y n jobs. Cada job j está compuesto por una secuencia de operaciones y la ejecución de la operación h del job j requiere una máquina de un conjunto de máquinas. En el fJSP se deben tratar dos subproblemas: el de asignación de las operaciones a las máquinas y el de secuenciación de las operaciones en cada una de las máquinas. Aunque en el fJSP es común que se seleccione como criterio de optimización el makespan, en los talleres modernos existe otro tipo de criterios, como por ejemplo, el coste de producción y los costes asociados a los adelantos y retrasos que se generan con respecto a la fecha de entrega comprometida. En este documento se presenta una exposición y análisis del estado del arte del fJSP haciendo énfasis en la literatura que considera costes en la función objetivo.]]></text><keywords><![CDATA[problema del taller mecánico de flujo general flexible]]></keywords><authors><element><attendee_id><![CDATA[88]]></attendee_id><normalized_name><![CDATA[N. A. Gonzalez Vargas]]></normalized_name><name><![CDATA[Nestor Andres]]></name><lastname><![CDATA[Gonzalez Vargas]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Corominas]]></normalized_name><name><![CDATA[Albert]]></name><lastname><![CDATA[Corominas]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Pastor]]></normalized_name><name><![CDATA[Rafael]]></name><lastname><![CDATA[Pastor]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[281]]></id><title><![CDATA[Procedimiento de enumeración para el problema de equilibrado de líneas de montaje simple basado en ramificar según tiempo libre no creciente]]></title><text><![CDATA[Se presenta un nuevo algoritmo exacto para la resolución del problema de equilibrado de líneas de montaje simple, dado un tiempo de ciclo (SALBP-1). Se trata de un procedimiento branch-and-bound bidireccional, orientado a estaciones, basado en una nueva estrategia de enumeración que explora el árbol de soluciones factibles en orden de tiempo libre por estación no creciente. El procedimiento emplea varias cotas y reglas de dominancia conocidas en un preproceso del problema. El algoritmo incluye un nuevo test lógico basado en la asimilación del problema de factibilidad asociado (SALBP-F) a un problema de flujos máximos. Se han realizado una serie de pruebas computacionales para comprobar la calidad del algoritmo en un set de instancias de referencia del problema. Estas demuestran que el algoritmo propuesto supera los resultados obtenidos por el mejor procedimiento exacto desarrollado para la resolución del SALBP-1, verificando 264 óptimos para las 269 instancias de referencia.]]></text><keywords><![CDATA[equilibrado de lineas,branch-and-bound, producción]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Pereira Gude]]></normalized_name><name><![CDATA[Jordi]]></name><lastname><![CDATA[Pereira Gude]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[132]]></id><title><![CDATA[Modelos para el MMSP-W con estaciones en serie, procesadores paralelos, libre interrupción de operaciones y homogeneidad del trabajo requerido]]></title><text><![CDATA[El MMSP-W  (Mixed-Model Sequencing Problem with Workload Minimisation) consiste en secuenciar productos en una línea de montaje (motores). Los productos se agrupan por tipos con una demanda para cada uno. Un producto, al entrar en una estación de trabajo, requiere a cada procesador de la estación (operarios), un determinado tiempo de proceso; mientras que el tiempo estándar concedido a cada estación y producto es fijo y se denomina tiempo de ciclo. A veces, para completar parte del trabajo, se puede retener el producto durante un tiempo mayor que el del ciclo, denominado ventana temporal. Cuando no es posible completar todo el trabajo requerido, se dice que se genera sobrecarga. El objetivo del problema consiste en maximizar el trabajo total completado o minimizar la sobrecarga total. Aquí proponemos modelos para el MMSP-W con regularidad del trabajo requerido a la línea y realizamos una experiencia computacional empleando el solver Gurobi en un caso de estudio de la empresa NISSAN. ]]></text><keywords><![CDATA[manufacturing, sequencing, just-in-time, work overload, linear programming, production mix preservation]]></keywords><authors><element><attendee_id><![CDATA[268]]></attendee_id><normalized_name><![CDATA[J. Bautista Valhondo]]></normalized_name><name><![CDATA[Joaquín]]></name><lastname><![CDATA[Bautista Valhondo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[496]]></attendee_id><normalized_name><![CDATA[R. Alfaro Pozo]]></normalized_name><name><![CDATA[Rocío]]></name><lastname><![CDATA[Alfaro Pozo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Cano Pérez]]></normalized_name><name><![CDATA[Alberto]]></name><lastname><![CDATA[Cano Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[163]]></id><title><![CDATA[Revisión, evaluación y nuevas heurísticas para el taller de flujo de permutación con el objetivo de la minimización del tiempo total de flujo]]></title><text><![CDATA[En los últimos años se han propuesto un buen número de métodos heurísticos para la minimización del tiempo de flujo total en el taller de flujo de permutación. Este problema es muy estudiado en la literatura científica y es de aplicación en muchas industrias. En este trabajo llevamos a cabo una evaluación computacional y estadística exhaustiva de 22 heurísticas existentes de la literatura. Todas ellas se han reprogramado y ejecutado en una misma plataforma computacional para su análisis preciso. Así mismo, proponemos cinco nuevos métodos que van desde heurísticas veloces a otras más elaboradas. Todas las heurísticas se han probado con el conocido conjunto de problemas de Taillard y hemos podido comprobar como los cinco nuevos métodos propuestos resultan ser estado del arte, bien por corto tiempo de CPU empleado como por la calidad de la solución alcanzada, medida como la desviación porcentual por encima de la mejor solución conocida.]]></text><keywords><![CDATA[secuenciación, taller de flujo, heurísticas]]></keywords><authors><element><attendee_id><![CDATA[351]]></attendee_id><normalized_name><![CDATA[R. Ruiz García]]></normalized_name><name><![CDATA[Rubén]]></name><lastname><![CDATA[Ruiz García]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[P. Quan-Ke]]></normalized_name><name><![CDATA[Pan]]></name><lastname><![CDATA[Quan-Ke]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[101]]></id><identifier><![CDATA[MC5]]></identifier><name><![CDATA[Fiabilidad 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[10]]></id><name><![CDATA[Sala Viena]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[328]]></id><normalized_name><![CDATA[N. Torrado Robles]]></normalized_name><name><![CDATA[Nuria]]></name><lastname><![CDATA[Torrado Robles]]></lastname></chairperson><papers><element><id><![CDATA[43]]></id><title><![CDATA[Estimation of the DPRL aging notion under random censorship]]></title><text><![CDATA[We introduce a new estimator of a percentile residual life function with censored data under a monotonicity constraint. Specifically, it is assumed that the percentile residual life is a decreasing function. This assumption is useful when estimating the percentile residual life of units which degenerate with age. We establish a law of the iterated logarithm for the proposed estimator, and its root n equivalence to the unrestricted estimator. The asymptotic normal distribution of the estimator and its strong approximation to a Gaussian process are also established. We investigate the finite sample performance of the monotone estimator in an extensive simulation study. Finally, data from a clinical trial in primary biliary cirrhosis of the liver are analyzed with the proposed methods. One of the conclusions of our work is that the restricted estimator may be much more efficient than the unrestricted one.]]></text><keywords><![CDATA[aging notion, censored data, nonparametric estimation, reliability, survival analysis]]></keywords><authors><element><attendee_id><![CDATA[215]]></attendee_id><normalized_name><![CDATA[A. M. Franco-Pereira]]></normalized_name><name><![CDATA[Alba Maria]]></name><lastname><![CDATA[Franco-Pereira]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. de Uña-Álvarez]]></normalized_name><name><![CDATA[Jacobo]]></name><lastname><![CDATA[de Uña-Álvarez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[79]]></id><title><![CDATA[Órdenes multivariantes basados en distribuciones condicionadas]]></title><text><![CDATA[En este trabajo, proponemos extensiones multivariantes de los órdenes univariantes dispersivo, rs, dmrl y nbue basadas en comparaciones de determinadas distribuciones marginales condicionadas a datos de supervivencia del resto de componentes. Estudiamos algunas relaciones entre ellos, así como aplicaciones a ciertos vectores aleatorios y ejemplos reales que muestran el interés de dichas ordenaciones. ]]></text><keywords><![CDATA[órdenes estocásticos, dispersivo, right-spread, dmrl, nbue, cópulas]]></keywords><authors><element><attendee_id><![CDATA[275]]></attendee_id><normalized_name><![CDATA[J. Mulero]]></normalized_name><name><![CDATA[Julio]]></name><lastname><![CDATA[Mulero]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[83]]></attendee_id><normalized_name><![CDATA[F. Belzunce Torregrosa]]></normalized_name><name><![CDATA[Félixx]]></name><lastname><![CDATA[Belzunce Torregrosa]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[321]]></attendee_id><normalized_name><![CDATA[A. Suárez-Llorens]]></normalized_name><name><![CDATA[Alfonso ]]></name><lastname><![CDATA[Suárez-Llorens]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. M. Ruíz Gómez]]></normalized_name><name><![CDATA[José María]]></name><lastname><![CDATA[Ruíz Gómez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[232]]></id><title><![CDATA[Diseño de planes de muestreo por grupos con censura progresiva para la distribución de Weibull]]></title><text><![CDATA[El diseño de planes de muestreo en fiabilidad es un problema de optimización bajo ciertos requisitos de niveles de calidad fijados por el productor y el consumidor. Este trabajo presenta un procedimiento general para determinar diseños óptimos cuando la variable 'tiempo de fallo' sigue una distribución de Weibull con parámetro de forma desconocido. En los planes propuestos se agrupan las unidades o items experimentales, y los grupos se someten a una prueba de fallo o muerte súbita aplicando esquemas de censura progresiva. La resolución del problema de optimización permite obtener el tamaño muestral y, minimizando el coste total esperado, el número óptimo de grupos que se deben someter a ensayo. Además, se determinan expresiones explícitas aproximadas de las soluciones óptimas. Dichas soluciones son bastante robustas ante pequeñas variaciones en el parámetro de forma de la distribución Weibull. El método se ilustra mediante un ejemplo sobre un proceso de producción de giroscopios.]]></text><keywords><![CDATA[optimización con restricciones, análisis de fiabilidad, curva operativa característica, riesgos del muestreo, distribución de Weibull]]></keywords><authors><element><attendee_id><![CDATA[441]]></attendee_id><normalized_name><![CDATA[A. J. Fernández]]></normalized_name><name><![CDATA[Arturo J.]]></name><lastname><![CDATA[Fernández]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[128]]></id><title><![CDATA[Some results on ordering of spacings from two samples]]></title><text><![CDATA[It is well known that n-k+1’th order statistic in a sample of size n represents the life length of a k-out-of-n system which is an important technical structure in reliability theory. Then, we can consider two spacings from two different k-out-of-n systems in order to examine whether the first system is better than the second one in some stochastic sense. In this talk, we present ordering properties involving spacings between order statistics from non-identical independent random variables. Specifically, we establish conditions under which normalized and simple spacings from two samples are ordered in the likelihood ratio ordering. Moreover, we also show some applications to multiple-outlier models.]]></text><keywords><![CDATA[stochastic orderings, order statistics, spacings ]]></keywords><authors><element><attendee_id><![CDATA[328]]></attendee_id><normalized_name><![CDATA[N. Torrado Robles]]></normalized_name><name><![CDATA[Nuria]]></name><lastname><![CDATA[Torrado Robles]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. E. Lillo Rodríguez]]></normalized_name><name><![CDATA[Rosa E.]]></name><lastname><![CDATA[Lillo Rodríguez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[69]]></id><identifier><![CDATA[MC6]]></identifier><name><![CDATA[Enseñanza de la Estadística y la Investigación Operativa 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[391]]></id><normalized_name><![CDATA[A. López Moreno]]></normalized_name><name><![CDATA[Alberto]]></name><lastname><![CDATA[López Moreno]]></lastname></chairperson><papers><element><id><![CDATA[305]]></id><title><![CDATA[Estimación del efecto de un cambio docente]]></title><text><![CDATA[Antecedentes: la Facultad de Informática de Barcelona (FIB) de la UPC adaptó su nuevo grado a un modelo de aprendizaje continuo. La tasa de aprobados de la asignatura Probabilidad y Estadística, con evaluación diaria, ha experimentado una notable mejora (en torno al 20\%).  Objetivo: descartar que esta mejora pueda ser atribuida a un examen más laxo. Material: comparación del rendimiento de los estudiantes en 18 problemas de examen de cada asignatura. Ajuste: promedio de dificultad de los problemas valorado, de forma enmascarada, por 4 profesores ajenos a la asignatura. Resultados: presentamos el nivel de concordancia entre evaluadores de su apreciación de la dificultad del problema y estimamos el efecto del cambio de método docente controlando por dificultad y temática (probabilidad o estadística).]]></text><keywords><![CDATA[adaptación EEES]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Cobo Valeri]]></normalized_name><name><![CDATA[Erik]]></name><lastname><![CDATA[Cobo Valeri]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[472]]></attendee_id><normalized_name><![CDATA[J. A. González Alastrué]]></normalized_name><name><![CDATA[José Antonio]]></name><lastname><![CDATA[González Alastrué]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. Marco Almagro]]></normalized_name><name><![CDATA[Lluís]]></name><lastname><![CDATA[Marco Almagro]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[P. Muñoz Gracia]]></normalized_name><name><![CDATA[Pilar]]></name><lastname><![CDATA[Muñoz Gracia]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Nonell Torrent]]></normalized_name><name><![CDATA[Ramon]]></name><lastname><![CDATA[Nonell Torrent]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Rius Carrasco]]></normalized_name><name><![CDATA[Roser]]></name><lastname><![CDATA[Rius Carrasco]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. Rodero de Lamo]]></normalized_name><name><![CDATA[Lourdes]]></name><lastname><![CDATA[Rodero de Lamo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[117]]></id><title><![CDATA[Using R for statistical training. An application to Six Sigma methodology for process improvement]]></title><text><![CDATA[Preparing training materials often takes time and effort for the trainer. It complicates when several people collaborate in preparing them. Moreover, a variety of formats are needed for a state-of-the-art course. When training statistics, the resources for the materials come from three main sources: text (including formulas), graphics and code (both input and output). A unified way of integrating all the sources into documents of different formats, such as presentations, lecture notes or assignments is desirable. The R language and statistical software provides the ideal framework for this integration in the field of statistics and other related subjects that entail data analysis. In this work we introduce the elements of the R system needed for the objectives mentioned above, and present an application to Six Sigma methodology for process improvement, with examples on how to integrate input sources and output materials using R.]]></text><keywords><![CDATA[Six Sigma, R, statistics, quality, reproducible research, open source]]></keywords><authors><element><attendee_id><![CDATA[57]]></attendee_id><normalized_name><![CDATA[E. López Cano]]></normalized_name><name><![CDATA[Emilio]]></name><lastname><![CDATA[López Cano]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[554]]></attendee_id><normalized_name><![CDATA[J. Martínez Moguerza]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Martínez Moguerza]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[150]]></id><title><![CDATA[Creación de una interfaz amigable de R para la enseñanza de la Estadística]]></title><text><![CDATA[Uno de los principales objetivos que nos hemos marcado en la enseñanza de la Estadística, es conseguir trabajar con software libre de manera habitual, pero el manejo de este software suele resultar muy complicado para los estudiantes. Con independencia de otros proyectos, como R UCA, que ya están en marcha, hemos querido desarrollar una interfaz amigable de R para la enseñanza de la Estadística, adaptada a los contenidos que se enseñan en los Grados impartidos en esta Universidad. Otros interfaces como R-Commander, incluyen análisis avanzados en los que los estudiantes se pierden y nuestro objetivo es que los estudiantes (sobre todo los de titulaciones de “letras”), puedan realizar con facilidad análisis estadísticos completos y correctos, manejando un software libre y en un entorno que les resulte ``cómodo''. Presentamos el desarrollo que ha realizado, como proyecto fin de carrera, un estudiante de la doble titulación Matemáticas e Ingeniería Técnica en Informática de Gestión.]]></text><keywords><![CDATA[interfaz de R]]></keywords><authors><element><attendee_id><![CDATA[71]]></attendee_id><normalized_name><![CDATA[Z. Hernández Martín]]></normalized_name><name><![CDATA[Zenaida]]></name><lastname><![CDATA[Hernández Martín]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[267]]></attendee_id><normalized_name><![CDATA[M. San Martín Pérez]]></normalized_name><name><![CDATA[Montserrat]]></name><lastname><![CDATA[San Martín Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[H. U. Guzmán Delgado]]></normalized_name><name><![CDATA[Héctor Unai]]></name><lastname><![CDATA[Guzmán Delgado]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[230]]></id><title><![CDATA[TSTutorial: laboratorio interactivo de modelización de series temporales con R]]></title><text><![CDATA[La librería de R desarrollada (TSTutorial) implementa un programa interactivo de tipo tutorial para la modelización de series temporales. El objetivo principal es ayudar a un estudiante con pocos conocimientos tanto de programación en R como de la metodología Box-Jenkins, a obtener un modelo y las correspondientes previsiones. Se ha estructurado en base a menús, ayudas e informes on-line que facilitan el auto-aprendizaje de la metodología. Las recomendaciones del tutorial se han completado con procesos heurísticos que orientan al usuario. Las funcionalidades incluyen la identificación, estimación, validación, selección del mejor modelo, análisis de atípicos y obtención de previsiones. La sesión interactiva guiada queda registrada en un archivo PDF. Se ha incluido un perfil de usuario avanzado para el que se omiten las ayudas guiadas. Este software se usa actualmente como material docente en la asignatura “Previsión y Series Temporales” del Máster de Estadística (UPC-UB).]]></text><keywords><![CDATA[tutorial, series temporales, librería R]]></keywords><authors><element><attendee_id><![CDATA[391]]></attendee_id><normalized_name><![CDATA[A. López Moreno]]></normalized_name><name><![CDATA[Alberto]]></name><lastname><![CDATA[López Moreno]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[390]]></attendee_id><normalized_name><![CDATA[J. A. Sanchez-Espigares]]></normalized_name><name><![CDATA[José A.]]></name><lastname><![CDATA[Sanchez-Espigares]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[78]]></id><identifier><![CDATA[MC7]]></identifier><name><![CDATA[Análisis de datos funcionales 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[12]]></id><name><![CDATA[Sala Roma II]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[119]]></id><normalized_name><![CDATA[A. M. Aguilera del Pino]]></normalized_name><name><![CDATA[Ana María]]></name><lastname><![CDATA[Aguilera del Pino]]></lastname></chairperson><papers><element><id><![CDATA[112]]></id><title><![CDATA[Modelos funcionales penalizados para la mejora de la calidad en la producción de la industria alimenticia]]></title><text><![CDATA[La problemática de la industria alimenticia se centra en la calidad de su producción. Concretamente, la manufacturera DANONE basa la calidad de sus galletas en la calidad del tipo de harina utilizada en la producción de las mismas. De este modo, su objetivo es identificar aquellas harinas que proporcionan las galletas de mejor calidad. Concretamente, se disponen de datos funcionales correspondientes a curvas de resistencia de la masa de las galletas durante los primeros 480 segundos del proceso de horneado. Para cada tipo de harina usado se tiene la calidad de las galletas clasificada como buena o mala. Con objeto de predecir la calidad (buena o mala) de la producción, se puede emplear un modelo de regresión logística funcional en términos de componentes principales y bases de B-splines. Este modelo proporciona una función parámetro poco suave y difícil de interpretar. Como solución, en este trabajo se proponen y comparan distintos modelos de regresión logística funcional penalizados. ]]></text><keywords><![CDATA[regresión logística funcional, análisis en componentes principales, P-splines]]></keywords><authors><element><attendee_id><![CDATA[244]]></attendee_id><normalized_name><![CDATA[M. C. Aguilera Morillo]]></normalized_name><name><![CDATA[M. Carmen]]></name><lastname><![CDATA[Aguilera Morillo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[119]]></attendee_id><normalized_name><![CDATA[A. M. Aguilera del Pino]]></normalized_name><name><![CDATA[Ana María]]></name><lastname><![CDATA[Aguilera del Pino]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[242]]></attendee_id><normalized_name><![CDATA[M. J. Valderrama Bonnet]]></normalized_name><name><![CDATA[Mariano J.]]></name><lastname><![CDATA[Valderrama Bonnet]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[240]]></id><title><![CDATA[Spatial depth-based classification for functional data]]></title><text><![CDATA[There exists a great amount of methods which try to solve supervised functional classification problems. Due to their robustness, we focus our attention on depth-based methods. In particular, we enlarge the number of existing functional depths by considering two functional generalizations of the notion of multivariate spatial depth, i.e. the functional spatial depth and the kernelized functional spatial depth. The first generalization is related to the notion of functional spatial quantile; the second generalization is a kernelized version of the first one, and it enables to take into account the local structure of the considered functional data. We evaluate the performances of these two functional spatial depths to classify curves. For that, we present the main results of a simulation study in which we compare the performances of the functional spatial depths with the performances of some existing functional depths. Finally, we apply spatial depth-based classification to real data.]]></text><keywords><![CDATA[functional classification, functional data depth]]></keywords><authors><element><attendee_id><![CDATA[430]]></attendee_id><normalized_name><![CDATA[C. Sguera]]></normalized_name><name><![CDATA[Carlo]]></name><lastname><![CDATA[Sguera]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[429]]></attendee_id><normalized_name><![CDATA[P. Galeano San Miguel]]></normalized_name><name><![CDATA[Pedro]]></name><lastname><![CDATA[Galeano San Miguel]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Lillo]]></normalized_name><name><![CDATA[Rosa]]></name><lastname><![CDATA[Lillo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[199]]></id><title><![CDATA[Interpretabilidad de los clasificadores SVM para datos funcionales]]></title><text><![CDATA[Las máquinas de vector de apoyo, Support Vector Machines (SVM), han demostrado ser una técnica no paramétrica muy poderosa para clasificación de datos de alta dimensión. Cuando aplicamos directamente SVM a los datos funcionales, por ejemplo discretizándolos en una rejilla, y representamos los coeficientes como una función, ésta puede tener un comportamiento muy errático, con muchas subidas y bajadas, que dificulte su interpretación. Es preferible que dicha función tenga alguna propiedad. Por ejemplo, si la función obtenida es casi siempre cero, y distinta de cero en unos pocos puntos, esos pocos puntos son puntos relevantes en la clasificación. Si esa función es suave, uno puede visualizar cómo, al recorrer el intervalo en una u otra dirección, unas zonas se van haciendo más relevantes que otras. En definitiva, uno puede interpretar el clasificador. En este trabajo proopne un método, basado en SVM, capaz de tener en cuenta las propiedades de interpretabilidad deseadas.]]></text><keywords><![CDATA[máquinas de vector de apoyo, análisis de datos funcionales, clasificación, minería de datos]]></keywords><authors><element><attendee_id><![CDATA[392]]></attendee_id><normalized_name><![CDATA[B. Martín Barragán]]></normalized_name><name><![CDATA[Belén ]]></name><lastname><![CDATA[Martín Barragán]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Lillo]]></normalized_name><name><![CDATA[Rosa]]></name><lastname><![CDATA[Lillo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Romo]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[Romo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[70]]></id><title><![CDATA[Selección de covariables climáticas para la predicción de picos de polen mediante modelos funcionales de respuesta binaria]]></title><text><![CDATA[En este trabajo se desarrolla un método de selección de variables en modelos mixtos funcionales de regresión con respuesta binaria para la predicción de picos de polen a partir de variables climáticas. Se dispone de observaciones de la concentración de polen de olivo, medidas en la ciudad de Granada desde el 1 de Enero de 1992 hasta el 30 de Junio de 2003. Además de la concentración de polen de olivo, que se considera también como covariable, se dispone de la observación diaria de temperaturas máxima, mínima y media, horas de sol, humedad relativa, precipitación y velocidad del viento. Para la selección del conjunto óptimo de variables funcionales se ha utilizado un procedimiento forward-stepwise basado en los tests condicionales de razón de verosimilitudes. Tras la evaluación del método de selección se concluye que las variables que mejor explican la ocurrencia de picos de polen son la propia concentración de polen, la temperatura mínima y la humedad relativa en la semana anterior.]]></text><keywords><![CDATA[selección stepwise, modelo funcional, polen de olivo]]></keywords><authors><element><attendee_id><![CDATA[254]]></attendee_id><normalized_name><![CDATA[M. Escabias Machuca]]></normalized_name><name><![CDATA[Manuel]]></name><lastname><![CDATA[Escabias Machuca]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[242]]></attendee_id><normalized_name><![CDATA[M. J. Valderrama Bonnet]]></normalized_name><name><![CDATA[Mariano J.]]></name><lastname><![CDATA[Valderrama Bonnet]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. E. Santofimia]]></normalized_name><name><![CDATA[María Elena]]></name><lastname><![CDATA[Santofimia]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[119]]></attendee_id><normalized_name><![CDATA[A. M. Aguilera del Pino]]></normalized_name><name><![CDATA[Ana María]]></name><lastname><![CDATA[Aguilera del Pino]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[244]]></attendee_id><normalized_name><![CDATA[M. C. Aguilera Morillo]]></normalized_name><name><![CDATA[M. Carmen]]></name><lastname><![CDATA[Aguilera Morillo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[108]]></id><identifier><![CDATA[MD1]]></identifier><name><![CDATA[Métodos bayesianos 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[340]]></id><normalized_name><![CDATA[F. J. Girón González-Torre]]></normalized_name><name><![CDATA[Francisco Javier]]></name><lastname><![CDATA[Girón González-Torre]]></lastname></chairperson><papers><element><id><![CDATA[193]]></id><title><![CDATA[Default Bayesian analysis of the disability model for the progression of stage IV non-small cells lung cancer ]]></title><text><![CDATA[Bayesian reasoning, survival analysis and multi-state models are used to assess survival times for Stage IV non-small cells lung cancer (NSCLC) patients and the evolution of the disease over time. Bayesian estimation is done under the Jeffreys' prior for the Weibull regression survival model leading to an automatic inferential procedure. Uncertainty about the parameters of the model is expressed in terms of its posterior distribution, approximated via Markov Chain Monte Carlo methods, and it has been propagated to the hazard rate functions of the times between transitions. We can thus  obtain the posterior distribution for the transition probabilities, given the time and the covariates, which offers a complete description of the dynamics of the system. Data for the study come from the Infanta Cristina Hospital of Madrid, Spain, and consist of survival times for stage IV NSCLC patients and measures of several covariates that may be related to the disease.]]></text><keywords><![CDATA[Bayesian information criterion, survival analysis, transition probabilities]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Armero Cervera]]></normalized_name><name><![CDATA[Carmen ]]></name><lastname><![CDATA[Armero Cervera]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Cabras]]></normalized_name><name><![CDATA[Stefano]]></name><lastname><![CDATA[Cabras]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[357]]></attendee_id><normalized_name><![CDATA[M. E. Castellanos Nueda]]></normalized_name><name><![CDATA[María Eugenia]]></name><lastname><![CDATA[Castellanos Nueda]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[194]]></attendee_id><normalized_name><![CDATA[S. Perra]]></normalized_name><name><![CDATA[Silvia]]></name><lastname><![CDATA[Perra]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Quirós Carretero]]></normalized_name><name><![CDATA[Alicia]]></name><lastname><![CDATA[Quirós Carretero]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. J. Oruezabal Moreno]]></normalized_name><name><![CDATA[Mauro Javier]]></name><lastname><![CDATA[Oruezabal Moreno]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Sánchez Rubio Ferrández]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Sánchez Rubio Ferrández]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[158]]></id><title><![CDATA[Bayesian estimation for controlled branching processes through MCMC and ABC methodologies]]></title><text><![CDATA[Branching Processes provide appropriate mathematical models for description of the probabilistic evolution of systems whose components (cells, particles, individuals in general), after a certain life period, reproduce and die. In particular, a controlled branching process (CBP) is a generalization of the classical Galton-Watson branching process, and, in the terminology of population dynamics, is used to describe the evolution of populations in which a control of the population size at each generation is needed. In this work, we deal with the problem of estimating the offspring parameters for a CBP assuming that the only observable data are the total number of individuals in each generation.We tackle the problem from a Bayesian perspective using MCMC and ABC methodologies. The results are illustrated with simulated data examples. Acknowledgement: This research is supported by the Ministerio de Ciencia e Innovación, Junta de Extremadura and  FEDER through the grants MTM2009-13248 and GR10118.]]></text><keywords><![CDATA[branching processes, Bayesian inference, Markov Chain Monte Carlo Methods, approximate Bayesian computation]]></keywords><authors><element><attendee_id><![CDATA[349]]></attendee_id><normalized_name><![CDATA[I. M. del Puerto]]></normalized_name><name><![CDATA[Inés Mª]]></name><lastname><![CDATA[del Puerto]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. González Velasco]]></normalized_name><name><![CDATA[Miguel ]]></name><lastname><![CDATA[González Velasco]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[102]]></attendee_id><normalized_name><![CDATA[C. Gutiérrez Pérez]]></normalized_name><name><![CDATA[Cristina]]></name><lastname><![CDATA[Gutiérrez Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Martínez Quintana]]></normalized_name><name><![CDATA[Rodrigo]]></name><lastname><![CDATA[Martínez Quintana]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[260]]></id><title><![CDATA[Análisis bayesiano objetivo de coste-efectividad para tratamientos clínicos en presencia de covariables]]></title><text><![CDATA[Presentamos una solución al problema de selección de variables en los problemas de coste-efectividad en presencia de covariables, utilizando  directamente la distribución bivariante del coste y la efectividad. El procedimiento de selección previa de variables conjuntamente influyentes permite la identificación correcta de los posibles subgrupos de la población bajo estudio en términos de las covariables influyentes, como demuestran algunos estudios de simulación que hemos efectuado. El nuevo análisis basado en la distribución predictiva conjunta del coste y la efectividad se aplica a un ejemplo real en el que hay cuatro tratamientos, en los que se pone de manifiesto la importancia de la identificación de las variables influyentes para la selección del mejor tratamiento para los individuos de cada uno de los posibles subgrupos.]]></text><keywords><![CDATA[coste-efectividad, selección de variables, análisis de subgrupos]]></keywords><authors><element><attendee_id><![CDATA[340]]></attendee_id><normalized_name><![CDATA[F. J. Girón González-Torre]]></normalized_name><name><![CDATA[Francisco Javier]]></name><lastname><![CDATA[Girón González-Torre]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[547]]></attendee_id><normalized_name><![CDATA[E. Moreno Bas]]></normalized_name><name><![CDATA[Elías ]]></name><lastname><![CDATA[Moreno Bas]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[513]]></attendee_id><normalized_name><![CDATA[M. L. Martínez García]]></normalized_name><name><![CDATA[María Lina]]></name><lastname><![CDATA[Martínez García]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[136]]></attendee_id><normalized_name><![CDATA[F. J. Vázquez Polo]]></normalized_name><name><![CDATA[Francisco José]]></name><lastname><![CDATA[Vázquez Polo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. A. Negrín Hernández]]></normalized_name><name><![CDATA[Miguel Angel]]></name><lastname><![CDATA[Negrín Hernández]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[73]]></id><identifier><![CDATA[MD2]]></identifier><name><![CDATA[Decisión multicriterio 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[73]]></id><normalized_name><![CDATA[J. Gómez Miguel]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Gómez Miguel]]></lastname></chairperson><papers><element><id><![CDATA[153]]></id><title><![CDATA[Un marco para la planificacion pre-desastre de operaciones de emergencia]]></title><text><![CDATA[Localizar los shelters es un paso muy importante en la fase de preparacion de la gestion de emergencias. Cuando se tome esta decision, hay que tener en cuenta diferentes factores, como la vulnerabilidad fisica, la proximidad a rutas de evacuacion y el acceso a las provisiones. En este trabajo proponemos un modelo multicriterio para la definicion de las localizaciones de los shelters mientras se optimizan las operaciones de evacuacion y de distribucion de los recursos de emergencia.]]></text><keywords><![CDATA[localizacion de shelters, logistica humanitaria, programacion multicriterio]]></keywords><authors><element><attendee_id><![CDATA[265]]></attendee_id><normalized_name><![CDATA[F. Liberatore]]></normalized_name><name><![CDATA[Federico]]></name><lastname><![CDATA[Liberatore]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[382]]></attendee_id><normalized_name><![CDATA[M. C. Pizarro Romero]]></normalized_name><name><![CDATA[Maria Celeste]]></name><lastname><![CDATA[Pizarro Romero]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[63]]></attendee_id><normalized_name><![CDATA[C. Simon de Blas]]></normalized_name><name><![CDATA[Clara]]></name><lastname><![CDATA[Simon de Blas]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[501]]></attendee_id><normalized_name><![CDATA[M. T. Ortuño Sanchez]]></normalized_name><name><![CDATA[Maria Teresa]]></name><lastname><![CDATA[Ortuño Sanchez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[487]]></attendee_id><normalized_name><![CDATA[B. Vitoriano Villanueva]]></normalized_name><name><![CDATA[Begoña]]></name><lastname><![CDATA[Vitoriano Villanueva]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[156]]></id><title><![CDATA[Un algoritmo constructivo multicriterio para el diseño de planes de distribución de ayuda humanitaria]]></title><text><![CDATA[Cuando se planifica una operación de distribución de ayuda humanitaria determinados factores adquieren gran importancia, tales como la equidad en el reparto, la atención prioritaria a poblaciones especialmente vulnerables, la seguridad del itinerario -dada la posibilidad de sufrir asaltos-, o su fiabilidad -debido a la eventual incertidumbre en el estado de las comunicaciones-. Junto con las habituales medidas de coste y tiempo total de la operación, dan lugar a un problema de planificación multicriterio de gran complejidad. En este trabajo se presenta un algoritmo constructivo que aborda el problema anterior y permite construir planes factibles de reparto. Las soluciones obtenidas proporcionan los itinerarios a seguir, detallando las rutas que han de seguir los vehículos disponibles, las cargas de material en cada trayecto y los instantes de paso por cada núcleo de población.]]></text><keywords><![CDATA[logística Humanitaria, heurística, multicriterio, rutas]]></keywords><authors><element><attendee_id><![CDATA[296]]></attendee_id><normalized_name><![CDATA[J. M. Ferrer Caja]]></normalized_name><name><![CDATA[José María]]></name><lastname><![CDATA[Ferrer Caja]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[501]]></attendee_id><normalized_name><![CDATA[M. T. Ortuño Sánchez]]></normalized_name><name><![CDATA[M. Teresa]]></name><lastname><![CDATA[Ortuño Sánchez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[G. Tirado Domínguez]]></normalized_name><name><![CDATA[Gregorio]]></name><lastname><![CDATA[Tirado Domínguez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[487]]></attendee_id><normalized_name><![CDATA[B. Vitoriano Villanueva]]></normalized_name><name><![CDATA[Begoña]]></name><lastname><![CDATA[Vitoriano Villanueva]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[223]]></id><title><![CDATA[Decidiendo como decidir: una metodología de diseño de procesos de presupuesto participativo]]></title><text><![CDATA[Existen muchas variantes a la hora de implantar un presupuesto participativo. Surge entonces el problema de cómo escoger el proceso a implantar en una situación determinada. A pesar de que las experiencias de este tipo han incrementado en los últimos años, en la mayoría de los casos, su diseño e implantación se siguen realizando de manera informal. La llegada de la democracia electrónica evidencia la necesidad de disponer de medios que permitan diseñar todo tipo de procesos participativos de manera eficaz. Es por esto que proponemos una metodología de diseño de procesos de presupuesto participativo, basada en un proceso de decisión multicriterio, que nos permita determinar el proceso más adecuado en cada contexto.]]></text><keywords><![CDATA[recursos públicos, presupuesto participativo, sistema de ayuda de decisión, decisión multicriterio ]]></keywords><authors><element><attendee_id><![CDATA[73]]></attendee_id><normalized_name><![CDATA[J. Gómez Miguel]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Gómez Miguel]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[72]]></attendee_id><normalized_name><![CDATA[C. Alfaro Gimeno]]></normalized_name><name><![CDATA[César]]></name><lastname><![CDATA[Alfaro Gimeno]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[98]]></attendee_id><normalized_name><![CDATA[J. M. Lavín de la Cavada]]></normalized_name><name><![CDATA[José María]]></name><lastname><![CDATA[Lavín de la Cavada]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[407]]></attendee_id><normalized_name><![CDATA[J. J. Molero López]]></normalized_name><name><![CDATA[Juan José]]></name><lastname><![CDATA[Molero López]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[112]]></id><identifier><![CDATA[MD3]]></identifier><name><![CDATA[Bioestadística 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[8]]></id><name><![CDATA[Sala Londres]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[305]]></id><normalized_name><![CDATA[A. E. Marín Jiménez]]></normalized_name><name><![CDATA[Ana Eugenia]]></name><lastname><![CDATA[Marín Jiménez]]></lastname></chairperson><papers><element><id><![CDATA[28]]></id><title><![CDATA[A family of deletion diagnostics for generalized estimating equations]]></title><text><![CDATA[Preisser and Qaqish (1996) proposed deletion diagnostics for GEEs. This approach is a global influence analysis which assesses the individual influence of subjects or observations on the estimates of regression parameters. A subject may have influence on the regression coefficients, the variance of the estimated coefficients, the fitted values, and/or the goodness-of-fit statistics. The global influence diagnostics based on the case-deletion had been generalized from linear regression to GEEs to measure the impact of an observation on all above regression outputs except on the variance of the estimated coefficients. Pardo \& Alonso (2012) proposed global influence measures based on the volume of confidence ellipsoids for detecting influence of subjects on the efficiency of coefficient estimations in GEEs. We define a family of influence measures based on the family of divergence measures of Rényi which extends one measure of this paper. Some simulation studies have been done.]]></text><keywords><![CDATA[generalized estimating equations, influence]]></keywords><authors><element><attendee_id><![CDATA[129]]></attendee_id><normalized_name><![CDATA[M. D. C. Pardo Llorente]]></normalized_name><name><![CDATA[Maria del Carmen]]></name><lastname><![CDATA[Pardo Llorente]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[225]]></id><title><![CDATA[Inferencias asintóticas sobre una proporción]]></title><text><![CDATA[Para obtener un intervalo de confianza de dos colas para una proporción binomial, la literatura ha propuesto un gran número de métodos asintóticos. El trabajo evalúa 27 métodos distintos (19 de ellos nuevos) y concluye que: 1) el método clásico de Wilson es el óptimo solo para una confianza del 99\%, aunque puede aplicarse de modo general cuando $n>=50$; 2) para una confianza del 95\% o del 90\%, el método óptimo es el basado en la transformación arco seno (cuando esta se aplica a los datos incrementados en 0.5); 3) una opción más sencilla, pero algo peor que las anteriores, es el clásico método adjusted Wald de Agresti and Coull (aplicar el clásico método de Wald a los datos incrementados en 2).]]></text><keywords><![CDATA[corrección por continuidad, intervalo de confianza, método de Wilson, métodos de Wald y adjusted Wald, transformación arco seno]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Martín Andrés]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Martín Andrés]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[233]]></id><title><![CDATA[Test de hipótesis global para comparar simultáneamente los valores predictivos de múltiples tests diagnósticos binarios con datos faltantes ignorables]]></title><text><![CDATA[El valor predictivo positivo de un test diagnóstico binario es la probabilidad de que un paciente tenga la enfermedad dado que el resultado del test diagnóstico ha sido positivo, y el valor predictivo negativo es la probabilidad de que un paciente no tenga la enfermedad dado que el resultado del test diagnóstico ha sido negativo. Los valores predictivos positivo y negativo de un test diagnóstico representan la exactitud clínica del test diagnóstico, y dependen de la sensibilidad y de la especificidad del test diagnóstico y de la prevalencia de la enfermedad. En este trabajo se estudia un test de hipótesis global, basado en la distribución chi-cuadrado, para comparar simultáneamente los valores predictivos de más de dos tests diagnósticos binarios con datos faltantes ignorables. Se han realizado unos experimentos de simulación para estudiar el error tipo I y la potencia del test de hipótesis global cuando se comparan los valores predicitvos de tres tests diagnósticos.]]></text><keywords><![CDATA[valor predictivo positivo, valor predictivo negativo, test diagnóstico binario, Chi-cuadrado]]></keywords><authors><element><attendee_id><![CDATA[305]]></attendee_id><normalized_name><![CDATA[A. E. Marín Jiménez]]></normalized_name><name><![CDATA[Ana Eugenia]]></name><lastname><![CDATA[Marín Jiménez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. A. Roldán Nofuentes]]></normalized_name><name><![CDATA[José Antonio]]></name><lastname><![CDATA[Roldán Nofuentes]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. D. D. Luna del Castillo]]></normalized_name><name><![CDATA[Juan de Dios]]></name><lastname><![CDATA[Luna del Castillo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[64]]></id><identifier><![CDATA[MD4]]></identifier><name><![CDATA[Modelos de decisión]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[9]]></id><name><![CDATA[Sala París]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[407]]></id><normalized_name><![CDATA[J. J. Molero López]]></normalized_name><name><![CDATA[Juan José]]></name><lastname><![CDATA[Molero López]]></lastname></chairperson><papers><element><id><![CDATA[196]]></id><title><![CDATA[Juegos markovianos aplicados a los acuerdos internacionales de  contaminación ambiental]]></title><text><![CDATA[Se presenta el Problema del Control de la Contaminación Ambiental que se acumula en la atmósfera, debido a las emisiones de CO2 de los distintos países. Se realiza una comparación numérica entre los resultados de un modelo de optimización estocástica discreta en forma de juego cooperativo entre todos los países (siguiendo las directrices del Protocolo de Kyoto), con otros dos modelos no cooperativos, uno de optimización de costes por cada país individual y otro utilizando transferencias monetarias como vía de  motivación para participar de forma cooperativa. Se utilizan datos reales con seis países o regiones.]]></text><keywords><![CDATA[juegos dinámicos estocásticos, control de la contaminación ambiental, métodos de decisión de markov, desarrollo sostenible]]></keywords><authors><element><attendee_id><![CDATA[388]]></attendee_id><normalized_name><![CDATA[O. J. Casas López]]></normalized_name><name><![CDATA[Omar J.]]></name><lastname><![CDATA[Casas López]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Romera Ayllón]]></normalized_name><name><![CDATA[Rosario]]></name><lastname><![CDATA[Romera Ayllón]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[231]]></id><title><![CDATA[Un modelo de ayuda a la decisión para la estimación del combustible óptimo de espera en aeropuertos con demoras significativas]]></title><text><![CDATA[Según la IATA (International Air Transport Association), el precio del combustible es la principal causa de pérdida de rentabilidad en las compañías aéreas. En el contexto actual de crisis económica, y con el constante aumento del precio del crudo, las aerolíneas buscan: 1) reducir sus costes operativos; y 2) mejorar la eficiencia en el consumo de combustible, sin comprometer por ello la seguridad operacional. Un problema de gran interés es, por tanto, determinar la cantidad óptima de combustible adicional que debe ser cargada en una ruta para poder absorber posibles demoras por congestión de tráfico aéreo en destino, evitando así el tener que desviarse a destinos alternativos. Proponemos un modelo de ayuda a la decisión para ello, incorporando todos los otros costes operativos en juego, e ilustramos nuestra propuesta con ejemplos operacionales reales.]]></text><keywords><![CDATA[demoras por congestión de tráfico aéreo, costes operativos, seguridad operacional, análisis bayesiano, modelo de costes, análisis de riesgos y decisión]]></keywords><authors><element><attendee_id><![CDATA[386]]></attendee_id><normalized_name><![CDATA[E. Sánchez Ayra]]></normalized_name><name><![CDATA[Eduardo]]></name><lastname><![CDATA[Sánchez Ayra]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[446]]></attendee_id><normalized_name><![CDATA[D. Ríos Insua]]></normalized_name><name><![CDATA[David]]></name><lastname><![CDATA[Ríos Insua]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[266]]></attendee_id><normalized_name><![CDATA[J. Cano Cancela]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Cano Cancela]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[214]]></id><title><![CDATA[Un modelo de presupuesto participativo con incertidumbre]]></title><text><![CDATA[En los últimos años se ha producido un incremento en la demanda de participación por parte de los ciudadanos. En respuesta a esta demanda, se han desarrollado una gran variedad de instrumentos participativos. Uno de ellos es el presupuesto participativo que permite a los ciudadanos proponer y decidir sobre el destino de parte de los recursos públicos, especialmente a nivel municipal. El modelo habitual del presupuesto participativo se caracteriza por su rigidez presupuestaria ya que la cantidad destinada a la inversión se fija antes de comenzar el proceso y durante su transcurso no es posible modificarla. Sin embargo, este modelo no parece muy adecuado en tiempos de crisis, debido a las circunstancias cambiantes del entorno. Por ello, propondremos un modelo más flexible incorporando variables de incertidumbre.  ]]></text><keywords><![CDATA[presupuesto participativo, incertidumbre, recursos públicos, programación estocástica, optimización]]></keywords><authors><element><attendee_id><![CDATA[407]]></attendee_id><normalized_name><![CDATA[J. J. Molero López]]></normalized_name><name><![CDATA[Juan José]]></name><lastname><![CDATA[Molero López]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[72]]></attendee_id><normalized_name><![CDATA[C. Alfaro Gimeno]]></normalized_name><name><![CDATA[César]]></name><lastname><![CDATA[Alfaro Gimeno]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[73]]></attendee_id><normalized_name><![CDATA[J. Gómez Miguel]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Gómez Miguel]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[98]]></attendee_id><normalized_name><![CDATA[J. M. Lavín de la Cavada]]></normalized_name><name><![CDATA[José María]]></name><lastname><![CDATA[Lavín de la Cavada]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[104]]></id><identifier><![CDATA[MD5]]></identifier><name><![CDATA[Fiabilidad 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[10]]></id><name><![CDATA[Sala Viena]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[228]]></id><normalized_name><![CDATA[R. Pérez Ocón]]></normalized_name><name><![CDATA[Rafael]]></name><lastname><![CDATA[Pérez Ocón]]></lastname></chairperson><papers><element><id><![CDATA[50]]></id><title><![CDATA[Mantenimiento preventivo en un sistema de fiabilidad con pérdida de unidades]]></title><text><![CDATA[En este trabajo se estudia el comportamiento de un sistema de fiabilidad en tiempo discreto con mantenimiento preventivo. El sistema está compuesto por una unidad principal y un número indeterminado finito de unidades en redundancia pasiva. La unidad principal está expuesta a fallos no reparables. Cuando un fallo no reparable ocurre entonces la unidad es eliminada ocupando otra el lugar principal del sistema. Con el fin de aumentar la fiabilidad se realizan inspecciones sobre la unidad principal las cuales pueden dar lugar a reparaciones preventivas. Cuando una inspección tiene lugar se pueden observar un número general de niveles de degradación considerándose distintos tipos de reparaciones preventivas para cada uno de ellos. Cuando sólo hay una unidad operativa entonces se adopta una política de reparación minimal para optimizar el comportamiento del sistema. El sistema funciona hasta que no hay unidades. Se obtienen distintas medidas de forma matricial algorítmica bien estructurada.]]></text><keywords><![CDATA[mantenimiento preventivo, distribuciones tipo-fase discretas, distemas markovianos]]></keywords><authors/></element><element><id><![CDATA[203]]></id><title><![CDATA[Análisis de fiabilidad de dispositivos según su estructura para la herramienta software EMSI]]></title><text><![CDATA[Cualquier sistema está constituido por una serie de dispositivos interconectados de forma  tal  que  sean  capaces de  realizar unas funciones concretas. Estos bloques funcionales pueden estar constituidos por una única componente o por complejos subsistemas, dependiendo del tipo de sistema y de las interconexiones en el mismo. El estado de las componentes y la estructura del sistema determinan si un sistema está funcionando o no. En definitiva, el cuantificar la fiabilidad de un sistema requiere, generalmente, considerar la estructura del sistema y la fiabilidad de sus componentes. La herramienta software EMSI está diseñada para realizar evaluación de la fiabilidad y el rendimiento de configuraciones en Sistemas Informáticos (SSII). En este trabajo analizamos la función de distribución empírica de los datos del tiempo hasta el fallo como variables aleatorias realizando los ajustes necesarios a un determinado modelo de probabilidad.]]></text><keywords><![CDATA[EMSI, distribuciones empíricas, fiabilidad]]></keywords><authors><element><attendee_id><![CDATA[377]]></attendee_id><normalized_name><![CDATA[R. Caro]]></normalized_name><name><![CDATA[Raquel]]></name><lastname><![CDATA[Caro]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[100]]></attendee_id><normalized_name><![CDATA[V. López]]></normalized_name><name><![CDATA[Victoria]]></name><lastname><![CDATA[López ]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[G. Miñana Ropero]]></normalized_name><name><![CDATA[Guadalupe]]></name><lastname><![CDATA[Miñana Ropero]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[64]]></id><title><![CDATA[Un modelo de choque y desgaste: aproximación analítico-matricial]]></title><text><![CDATA[Se estudia un sistema sometido a choque y desgaste. Los choques producen daños debidos a condiciones externas, y cuando el sistema alcanza un cierto número de choques es reparado. Las reparaciones son tan buenas como nuevas. Los fallos internos del sistema son no-reparables, y cuando el fallo ocurre el sistema es reemplazado por otro nuevo e idéntico. Ambos tipos de fallos son independientes. Los choques ocurren según un proceso de llegadas Markoviano (Markovian arrival process). Los tiempos de vida y de reparación del sistema siguen distribuciones tipo-fase. El sistema se estudia siguiendo métodos analítico-matriciales. Se construye el proceso general de Markov gobierna el sistema y se calcula la distribución estacionaria. A partir de esta se determina la disponibilidad y las razones de ocurrencias de fallos. Una aplicación numérica ilustra los resultados.]]></text><keywords><![CDATA[proceso de llegadas Markoviano, distribución tipo-fase, sistema de choque y desgaste]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[D. Montoro Cazorla]]></normalized_name><name><![CDATA[Delia]]></name><lastname><![CDATA[Montoro Cazorla]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[90]]></id><identifier><![CDATA[MD6]]></identifier><name><![CDATA[Modelos estadísticos 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[136]]></id><normalized_name><![CDATA[F. J. Vázquez Polo]]></normalized_name><name><![CDATA[Francisco José]]></name><lastname><![CDATA[Vázquez Polo]]></lastname></chairperson><papers><element><id><![CDATA[285]]></id><title><![CDATA[Evaluación de eficiencias empresariales bajo modelos de distribución libre]]></title><text><![CDATA[La competitividad empresarial involucra necesariamente la comparación respecto de las mejores empresas del sector. Es un aspecto contrastado que la eficiencia empresarial es uno de los parámetros a considerar cuando se desea que una empresa en particular simule o iguale su comportamiento a las mejores empresas. La medida de la eficiencia puede ser llevada a cabo bajo diferentes procedimientos. La verificación y robustez del método de estimación juega un papel importante en la toma de decisiones empresariales. En este trabajo, se analiza el efecto de la selección de modelos sobre las medidas obtenidas bajo el conocido método de distribución libre, aplicable a datos de panel. Ello permite obtener conclusiones sobre las implicaciones de utilización de modelos complejos en diferentes escenarios. A partir de datos reales serán generadas poblaciones simuladas sobre las cuales obtendremos indicadores de robustez del método de estimación.]]></text><keywords><![CDATA[eficiencia, distribución libre, datos de panel]]></keywords><authors><element><attendee_id><![CDATA[462]]></attendee_id><normalized_name><![CDATA[F. M. Rosa-González]]></normalized_name><name><![CDATA[Felipe Manuel]]></name><lastname><![CDATA[Rosa-González]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[470]]></attendee_id><normalized_name><![CDATA[E. González-Dávila]]></normalized_name><name><![CDATA[Enrique]]></name><lastname><![CDATA[González-Dávila]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Arbelo-Álvarez]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Arbelo-Álvarez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[316]]></id><title><![CDATA[Why using a general model in Solvency II is not a good idea]]></title><text><![CDATA[The passing of Directive 2009/138/CE (Solvency II) has opened a new era in the European insurance market. According to this new rule, the volume of own resources will be determined depending on the risks that any insurer would be holding. The Directive establishes that the European entities can use a general model to estimate the level of economic capital. However, this situation is far from being optimal because the calibration of the general model has been made using figures that reflects average behaviour. This paper shows that not all the companies operating in a specific market have the same risk profile. So, it is inappropriate to use a general model for all of them. We use the PAM clustering method and then some Bayesian tools to check the results previously obtained. Analysed data (public information belonging to Spanish insurance companies about balance sheets and income statements from 1998 to 2007) comes from the DGSFP (Spanish insurance regulator).]]></text><keywords><![CDATA[Solvency II, PAM, longitudinal multinomial model]]></keywords><authors><element><attendee_id><![CDATA[465]]></attendee_id><normalized_name><![CDATA[I. Albarrán Lozano]]></normalized_name><name><![CDATA[Irene]]></name><lastname><![CDATA[Albarrán Lozano]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[509]]></attendee_id><normalized_name><![CDATA[P. Alonso González]]></normalized_name><name><![CDATA[Pablo]]></name><lastname><![CDATA[Alonso González]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. M. Marín Diazaraque]]></normalized_name><name><![CDATA[Juan Miguel]]></name><lastname><![CDATA[Marín Diazaraque]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[268]]></id><title><![CDATA[Una generalización de la distribución discreta half-normal y aplicaciones]]></title><text><![CDATA[Se introduce una nueva distribución discreta dependiente de dos parámetros utilizando para ello el procedimiento de Marshall y Olkin (1997) sobre la distribución half-normal. Este trabajo se prueban una serie de propiedades de esta distribución que la hacen especialmente atractiva en distintos ámbitos de aplicación como pueden ser la estadística actuarial y de los seguros. Se prueba que la distribución es unimodal, sobredispersa y con tasa de fallo creciente, entre otras propiedades. Finalmente, se muestra una aplicación concreta con un conjunto de datos reales.]]></text><keywords><![CDATA[discretización, half-normal, procedimiento de Marshall y Olkin.]]></keywords><authors><element><attendee_id><![CDATA[136]]></attendee_id><normalized_name><![CDATA[F. J. Vázquez Polo]]></normalized_name><name><![CDATA[Francisco José]]></name><lastname><![CDATA[Vázquez Polo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[516]]></attendee_id><normalized_name><![CDATA[E. Gómez Déniz]]></normalized_name><name><![CDATA[Emilio ]]></name><lastname><![CDATA[Gómez Déniz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[V. García García]]></normalized_name><name><![CDATA[Victoriano]]></name><lastname><![CDATA[García García]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[35]]></id><identifier><![CDATA[MFR]]></identifier><name><![CDATA[Conmemoración 50 Aniversario SEIO]]></name><description><![CDATA[<h3>Programa<br></h3><p>17:45 - 17:55 Bienvenida y presentación del acto por parte del Presidente de la Real Academia de Ciencias<br>&nbsp;<br>17:55 - 18:05 José Miguel Angulo Ibáñez, Presidente de la Sociedad de Estadística e Investigación Operativa<br>&nbsp;<br>18:05 - 18:25 Mª del Carmen Pardo, 50 Años de la SEIO<br>&nbsp;<br>18:25 - 18:35 Joaquín Sánchez Soriano, Reflexiones de Francisco J. Quintana<br>&nbsp;<br>18:35 – 18:45 Mª Jesús Ríos Insúa, D. Sixto Ríos</p><p>A
 continuación Marco Antonio López Cerdá inaugurará el ciclo de 
conferencias "Sixto Ríos". Al final del acto se servirá un vino de 
bienvenida.</p>]]></description><comments><![CDATA[]]></comments><start><![CDATA[17:45:00]]></start><end><![CDATA[18:45:00]]></end><location><id><![CDATA[13]]></id><name><![CDATA[Real Academia de Ciencias]]></name><venue><![CDATA[
Real Academia de Ciencias Exactas Fisicas y Naturales]]></venue><gps_coords><![CDATA[40.42195,-3.701714]]></gps_coords></location><chairperson><id><![CDATA[68]]></id><normalized_name><![CDATA[J. M. Angulo Ibáñez]]></normalized_name><name><![CDATA[José Miguel]]></name><lastname><![CDATA[Angulo Ibáñez]]></lastname></chairperson><papers/></element><element><id><![CDATA[34]]></id><identifier><![CDATA[MGR]]></identifier><name><![CDATA[Conferencia Sixto Ríos]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[18:45:00]]></start><end><![CDATA[19:45:00]]></end><location><id><![CDATA[13]]></id><name><![CDATA[Real Academia de Ciencias]]></name><venue><![CDATA[
Real Academia de Ciencias Exactas Fisicas y Naturales]]></venue><gps_coords><![CDATA[40.42195,-3.701714]]></gps_coords></location><chairperson><id><![CDATA[299]]></id><normalized_name><![CDATA[E. Carrizosa]]></normalized_name><name><![CDATA[Emilio]]></name><lastname><![CDATA[Carrizosa]]></lastname></chairperson><papers><element><id><![CDATA[145]]></id><title><![CDATA[Pero...,¿hay problemas de optimización reales con infinitas restricciones? ]]></title><text><![CDATA[Se muestra, en primer lugar, que una extensa serie de problemas reales en ámbitos muy diferentes como el de las matemticas y la física (geometría convexa, regresión robusta, diseño de experimentos, aproximación funcional, Dirichlet b.v.p., etc.), la economía (problema de la cartera), robótica, gemología, control de la polución, etc., pueden ser modelizados de forma natural como problemas de optimización con infinitas restricciones, es decir, problemas de programación semi-infinita (PSI, de forma abreviada). Mediante ejemplos simples se evidencia que la estrategia de discretización, consistente en resolver subproblemas resultantes de conservar un número finito, aunque grande, de restricciones no es suficiente en general para abordar de forma satisfactoria la resolución numérica de dichos problemas. Consecuentemente, procede fijar las condiciones bajo las cuales éeta u otras estrategias algorítmicas alternativas producen métodos numéricos de cierta eficiencia computacional. En la segunda parte de la exposición se analizan algunos problemas, de considerable interés, en los que la mera consideración de las condiciones de optimalidad de Karush- Kuhn-Tucker (específicas del PSI) proporciona información suficiente para la caraterización de las soluciones óptimas del problema.

But ..., are there real-world optimization problems with infinitely many constraints?

First we show that a huge number of real-world problems in very different settings as mathematics and physics (convex geometry, robust regression, experimental design, functional approximation, Dirichlet boundary value problem, etc.), economics (portfolio problem), robotics, gemstone cutting industry, pollution control, etc., can be modelled as optimization problems with infinitely many constraints, i.e. semi-infinite programming (SIP, in brief) problems. By means of simple examples we point out that the discretization strategy, which consists of solving some subproblems obtained by keeping a finite number (perhaps, a big number!) of original constraints, is not good enough when one approaches the numerical solution of these problems. Consequently, we must establish the conditions under which this one and other alternative algorithmic strategies yield numerical methods of certain computational efficiency. In the second part of this talk, we analyze some problems of remarkable interest for which the only consideration of the Karush-Kuhn-Tucker optimality conditions (specific for PSI) allows for a characterization of the optimal solutions of the original problem.]]></text><keywords><![CDATA[programación semi-infinita]]></keywords><authors/></element></papers></element><element><id><![CDATA[38]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Vino de bienvenida]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[19:45:00]]></start><end><![CDATA[20:30:00]]></end><location><id><![CDATA[13]]></id><name><![CDATA[Real Academia de Ciencias]]></name><venue><![CDATA[
Real Academia de Ciencias Exactas Fisicas y Naturales]]></venue><gps_coords><![CDATA[40.42195,-3.701714]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element></sessions></element><element><date><![CDATA[2012-04-18]]></date><papers/><sessions><element><id><![CDATA[74]]></id><identifier><![CDATA[XA2]]></identifier><name><![CDATA[Decisión multicriterio 3]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[237]]></id><normalized_name><![CDATA[V. Blanco]]></normalized_name><name><![CDATA[Victor]]></name><lastname><![CDATA[Blanco]]></lastname></chairperson><papers><element><id><![CDATA[211]]></id><title><![CDATA[Un modelo minmax regret para regresión lineal simple con incertidumbre en la variable respuesta]]></title><text><![CDATA[En este trabajo se analiza el modelo de regresión lineal simple asumiendo incertidumbre en la muestra de la variable respuesta y sin contemplar información probabilística al respecto. El modelo de regresión lineal con incertidumbre en la muestra se ha analizado en la literatura usando optimización fuzzy, dando lugar a lo que se denomina  ``interval regression analysis''. Esta metodología, introducida por Tanaka et al. en 1989, determina los coeficientes fuzzy del modelo de regresión valiéndose de la formulación de un problema de Programación Lineal. El presente trabajo plantea un modelo diferente basado en el criterio minmax regret. Se redefine el concepto de "mejor ajuste lineal" posible. Esto permite plantear un problema de optimización cuyas propiedades generales se estudian en términos de la función de coste de los residuos. Finalmente, se plantean métodos numéricos de resolución para funciones de coste cuadrático o valor absoluto de los residuos. ]]></text><keywords><![CDATA[optimización robusta, criterio minmax regret]]></keywords><authors/></element><element><id><![CDATA[29]]></id><title><![CDATA[Optimalidad Lagrangiana para soluciones aproximadas propias en optimización vectorial]]></title><text><![CDATA[Se considera un problema de optimización vectorial cono-restringido en espacios topológicos localmente convexos Hausdorff y con condiciones de convexidad generalizada. En este marco se introduce una función Lagrangiana que valora en las partes del espacio objetivo y se muestran condiciones de optimalidad de tipo Lagrangiano para soluciones aproximadas propias de tipo Benson.]]></text><keywords><![CDATA[convexidad generalizada, función lagrangiana, soluciones aproximadas propias]]></keywords><authors><element><attendee_id><![CDATA[189]]></attendee_id><normalized_name><![CDATA[L. Huerga Pastor]]></normalized_name><name><![CDATA[Lidia]]></name><lastname><![CDATA[Huerga Pastor]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[239]]></attendee_id><normalized_name><![CDATA[C. Gutiérrez Vaquero]]></normalized_name><name><![CDATA[César]]></name><lastname><![CDATA[Gutiérrez Vaquero]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[116]]></attendee_id><normalized_name><![CDATA[V. Novo Sanjurjo]]></normalized_name><name><![CDATA[Vicente]]></name><lastname><![CDATA[Novo Sanjurjo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[98]]></id><title><![CDATA[Un método interactivo de punto de referencia mixto en programación multiobjetivo estocástica]]></title><text><![CDATA[Los métodos interactivos de punto de referencia han sido utilizados de forma exitosa en programación multiobjetivo determinística. Sin embargo, pocos trabajos se pueden encontrar para problemas multiobjetivo estocásticos. Resolver un problema de este tipo, además de analizar la conflictividad entre funciones, es necesario tener presente la naturaleza estocástica de las propias funciones. De ahí el interés en aplicar los métodos de punto de referencia a este tipo de problemas, ya que son capaces de generar soluciones a partir de información preferencial tan intuitiva como unos niveles deseados para las funciones objetivo y unas probabilidades deseadas para cada uno de dichos niveles. Partiendo de dos trabajos previos que usan la metodología de punto de referencia, hemos estudiado sus propiedades teóricas y hemos propuesto un nuevo enfoque que usa simultáneamente toda la información preferencial (niveles de aspiración y probabilidades) mediante un doble punto de referencia.]]></text><keywords><![CDATA[multiobjective programming, stochastic programming, reference point, probability efficiency, interactive methods, minimum risk efficiency]]></keywords><authors><element><attendee_id><![CDATA[295]]></attendee_id><normalized_name><![CDATA[M. Luque Gallego]]></normalized_name><name><![CDATA[Mariano]]></name><lastname><![CDATA[Luque Gallego]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Ruiz de la Rúa]]></normalized_name><name><![CDATA[Francisco]]></name><lastname><![CDATA[Ruiz de la Rúa]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. M. Cabello González]]></normalized_name><name><![CDATA[José Manuel]]></name><lastname><![CDATA[Cabello González]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. B. Ruiz Mora]]></normalized_name><name><![CDATA[Ana Belén]]></name><lastname><![CDATA[Ruiz Mora]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[47]]></id><title><![CDATA[A semidefinite programming approach for solving multiobjective linear programming]]></title><text><![CDATA[Several algorithms are available in the literature for finding the entire set of Pareto-optimal solutions in MultiObjective Linear Programming (MOLP). However, it has not been proposed so far an interior point algorithm that finds all Pareto-optimal solutions of MOLP. We present an explicit construction, based on a transformation of any MOLP into a finite sequence of SemiDefinite Programs (SDP), the solutions of which give the entire set of Pareto-optimal extreme points solutions of MOLP. These SDP problems are solved by interior point methods; thus our approach provides a pseudo-polynomial interior point methodology to find the set of Pareto-optimal solutions of MOLP.]]></text><keywords><![CDATA[multiobjective linear programming, semidefinite programming, moment problem]]></keywords><authors><element><attendee_id><![CDATA[237]]></attendee_id><normalized_name><![CDATA[V. Blanco]]></normalized_name><name><![CDATA[Victor]]></name><lastname><![CDATA[Blanco]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[65]]></attendee_id><normalized_name><![CDATA[J. Puerto]]></normalized_name><name><![CDATA[Justo]]></name><lastname><![CDATA[Puerto]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Ben-Ali]]></normalized_name><name><![CDATA[Safae]]></name><lastname><![CDATA[Ben-Ali]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[110]]></id><identifier><![CDATA[XA3]]></identifier><name><![CDATA[Métodos bayesianos 3]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[8]]></id><name><![CDATA[Sala Londres]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[224]]></id><normalized_name><![CDATA[R. Susi García]]></normalized_name><name><![CDATA[Rosario]]></name><lastname><![CDATA[Susi García]]></lastname></chairperson><papers><element><id><![CDATA[297]]></id><title><![CDATA[Un modelo mixto para datos longitudinales circulares: un enfoque Bayesiano]]></title><text><![CDATA[En varias áreas de investigación existen situaciones que involucran relaciones de dependencia donde la variable de respuesta es de tipo direccional. En este trabajo se presenta el análisis Bayesiano de un modelo para datos longitudinales donde la variable de respuesta es de tipo circular (direcciones en dos dimensiones). El modelo propuesto se basa en la distribución de probabilidad Normal bivariada bajo proyección, donde cada componente del modelo se especifica a través de un modelo lineal de efectos mixtos. Las inferencias para los parámetros involucrados se basan en muestras de las correspondientes distribuciones finales, las cuales son obtenidas utilizando métodos MCMC una vez que se ha introducido un conjunto de variables latentes adecuadas. Los procedimientos son ilustrados usando conjuntos de datos tanto simulados como datos reales previamente analizados en la literatura. ]]></text><keywords><![CDATA[Gibbs sampler, variables, datos longitudinales, modelos de efectos mixtos]]></keywords><authors/></element><element><id><![CDATA[284]]></id><title><![CDATA[Bayesian modelling for financial time series with skewness and high kurtosis  with the Skew Slash distribution]]></title><text><![CDATA[Financial data sets often present skewness and high kurtosis. As a consequence, it is natural to look for a model that is flexible enough to capture these characteristics. The proposal is to perform Bayesian inference and prediction for a generalized autoregressive conditional heteroskedastic (GARCH) model, where the innovations are assumed to follow a Skew Slash distribution. Gibbs sampling is used for parameter estimation and volatility prediction, and the method is illustrated using real financial data.]]></text><keywords><![CDATA[financial time series, Bayesian analysis, Skew Slash distribution, GARCH model, Skewness, Kurtosis]]></keywords><authors><element><attendee_id><![CDATA[429]]></attendee_id><normalized_name><![CDATA[P. Galeano San Miguel]]></normalized_name><name><![CDATA[Pedro]]></name><lastname><![CDATA[Galeano San Miguel]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[443]]></attendee_id><normalized_name><![CDATA[C. Garcia de la Fuente]]></normalized_name><name><![CDATA[Cristina]]></name><lastname><![CDATA[Garcia de la Fuente]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. P. Wiper]]></normalized_name><name><![CDATA[Michael P.]]></name><lastname><![CDATA[Wiper]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[62]]></id><title><![CDATA[Sensibilidad respecto a la eliminación de arcos en redes bayesianas gaussianas]]></title><text><![CDATA[En Redes Bayesianas Gaussianas (RBGs) se ha estudiado la sensibilidad del modelo a cambios en los parámetros, comparando las salidas de la red tras la propagación de la evidencia, y a cambios en la estructura de la red en la fase inicial, es decir, sin propagar la evidencia. En este trabajo se evalúan cambios en la estructura de la red estudiando la salida de la misma tras la propagación de la evidencia con el objetivo de encontrar una red más sencilla que facilite el proceso de inferencia en el modelo. Para ello, proponemos un análisis de sensibilidad que permita determinar como de sensible es la RBG cuando se eliminan arcos de la misma, así, si la red no es sensible a eliminar un arco se puede trabajar con la red simplificada. 
Para estudiar la sensibilidad utilizamos la divergencia de Kullback-Leibler que permite comparar las salidas de la red tras la propagación de la evidencia entre la RBG definida inicialmente y la RBG de estructura simplificada.]]></text><keywords><![CDATA[redes bayesianas gaussianas, sensibilidad, divergencia de Kullback-Leibler]]></keywords><authors><element><attendee_id><![CDATA[300]]></attendee_id><normalized_name><![CDATA[M. A. Gómez-Villegas]]></normalized_name><name><![CDATA[Miguel Angel]]></name><lastname><![CDATA[Gómez-Villegas]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[295]]></id><title><![CDATA[Uso de modelos gráficos probabilísticos y aprendizaje automático para optimizar la adquisición de terminales en una operadora]]></title><text><![CDATA[Se presenta cómo el uso de estos modelos permite ofrecer el móvil adecuado a un determinado cliente post-pago con la finalidad de aumentar su consumo y, así, optimizar la compra de los terminales futuros por parte de la compañía. Qué problemas aparecen: a) Terminal: gran número de fabricantes y modelos, múltiples características por terminal (algunas futuras no existentes), diferentes sistemas operativos (Android, Qwerty, Táctil, Bluetooth, Cámara, \dots). b) Usuario: distintos usos que da al móvil (GPS, SMSs, Redes sociales, \dots). c) Dinamismo del negocio: abandono de clientes porque la competencia le ofrece otro terminal o tarifa. d) Volumen: millones de clientes.  e) Predicción: si es difícil tomar decisiones con los terminales actuales, mucho más es realizarlo con terminales futuros. ¿A qué precio hay que adquirirlos? f) Ciclo de vida. Los modelos permiten extraer los datos de las múltiples fuentes y preprocerlos para aplicar data mining. Este proceso se realiza una vez y se automatiza para nuevos datos. Se obtienen mejoras de un 83\% al evaluar el terminal más eficaz.]]></text><keywords><![CDATA[aprendizaje automático, data mining, predictive analytics, redes bayesianas, mgp]]></keywords><authors><element><attendee_id><![CDATA[457]]></attendee_id><normalized_name><![CDATA[M. Marin Martinez]]></normalized_name><name><![CDATA[Manuel]]></name><lastname><![CDATA[Marin Martinez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. M. del Río]]></normalized_name><name><![CDATA[Jose Manuel]]></name><lastname><![CDATA[del Río]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[65]]></id><identifier><![CDATA[XA4]]></identifier><name><![CDATA[Optimización combinatoria y optimización entera]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[9]]></id><name><![CDATA[Sala París]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[70]]></id><normalized_name><![CDATA[A. Sedeño Noda]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Sedeño Noda]]></lastname></chairperson><papers><element><id><![CDATA[262]]></id><title><![CDATA[Production planning of supply chains in the pig industry by a mixed integer linear programming model]]></title><text><![CDATA[This research presents the formulation of a mixed integer linear programming model with the aim to optimize the production planning of a pig supply chain. The model maximizes the total revenue of the chain. Income depends on animals sold to the abattoir and main costs summarises feeding, doses of insemination, labour, transportation and veterinary expenses. A time horizon of three years is considered on a weekly basis. Furthermore, the proposed model provides the best production planning, that is, the flow of animals among farms and towards the abattoir, the number of animals to be produced and transferred at each phase and stage. Number of trucks and optimal replacement policy for each sow farm, as well as the optimal delivering of fattened pigs to the abattoir. Finally, It is demonstrated how the optimal solution for the whole supply chain it is different that the optimal solution for individual farms.]]></text><keywords><![CDATA[planning production, mixed linear programming, supply chain model, sow herd management, replacement, herd transport]]></keywords><authors><element><attendee_id><![CDATA[438]]></attendee_id><normalized_name><![CDATA[E. Nadal]]></normalized_name><name><![CDATA[Esteve]]></name><lastname><![CDATA[Nadal]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[517]]></attendee_id><normalized_name><![CDATA[L. M. Pla Aragones]]></normalized_name><name><![CDATA[Lluis M.]]></name><lastname><![CDATA[Pla Aragones]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[254]]></id><title><![CDATA[Integrated allocation of tasks, projects and departaments]]></title><text><![CDATA[En este trabajo se presentará un modelo de asignación de personal a proyectos, tareas y departamentos. No conocemos ningún modelo en la literatura que integre dichas asignaciones conjuntamente. El estudio de esta problemática se acerca más a la realidad de las empresas de servicio cuyos empleados realizan tareas y proyectos que necesitan diferentes requisitos. Así, se presentará un modelo de programación entera considerando personal polivalente con diferente eficiencia en cada una de las habilidades que puede realizar. Adicionalmente, se minimizarán las rotaciones de los empleados de unos proyectos a otros manteniendo, en la mayoría de lo posible, continuidad de los empleados que realizan un proyecto. Además, se minimizará el número de empleados asignados a proyectos con el objetivo de conseguir que trabajen en los proyectos los empleados más indicados y de evitar que haya muchos empleados asignados a un mismo proyecto, lo que provocaría que la contribución de cada uno fuese escasa.]]></text><keywords><![CDATA[project staffing, integer programming, integrated assignment]]></keywords><authors><element><attendee_id><![CDATA[202]]></attendee_id><normalized_name><![CDATA[V. Fernandez-Viagas]]></normalized_name><name><![CDATA[Victor]]></name><lastname><![CDATA[Fernandez-Viagas]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. M. Framiñán Torres]]></normalized_name><name><![CDATA[Jose Manuel]]></name><lastname><![CDATA[Framiñán Torres]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[102]]></id><title><![CDATA[Un estudio poliédrico del problema de la mochila con restricciones de empaquetamiento]]></title><text><![CDATA[En este trabajo proponemos el estudio del problema de la mochila al que hemos añadido una colección de restricciones de empaquetamiento. En primer lugar, se justifica el interés del nuevo problema. En segundo lugar, obtenemos propiedades poliédricas del poliedro intersección a partir de propiedades del poliedro de la mochila y a partir de las propiedades del poliedro del problema de empaquetamineto. Los resultados obtenidos generalizan otros problemas de la mochila anteriormente estudiados en la literatura.]]></text><keywords><![CDATA[problema de la  mochila, desigualdades de cubrimiento, facetas, problema de empaquetamiento]]></keywords><authors><element><attendee_id><![CDATA[302]]></attendee_id><normalized_name><![CDATA[M. Landete Ruiz]]></normalized_name><name><![CDATA[Mercedes]]></name><lastname><![CDATA[Landete Ruiz]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[12]]></id><title><![CDATA[Enumerando los k mejores caminos en orden de su longitud en DAGs]]></title><text><![CDATA[En este trabajo, consideramos el problema de los K mejores caminos conectando un par de nodos en un grafo sin ciclos dirigido (DAG) con longitudes arbitrarias. Demostramos que el árbol conteniendo el k-ésimo mejor camino difiere sólo en un arco con alguno de los (k-1) árboles conteniendo los (k-1) primeros mejores caminos. Esto nos permite diseñar un algoritmo de complejidad temporal O(m + K(n + logK)) y complejidad espacial O(K + m) para redes con longitudes reales. En el caso de DAGs con longitudes enteras la complejidad temporal se reduce a O(m + Kn). Un estudio computacional revela que el algoritmo propuesto supera en la práctica a los algoritmos existentes en la literatura.]]></text><keywords><![CDATA[optimización combinatoria, algoritmos de caminos mínimos, k mejores soluciones]]></keywords><authors><element><attendee_id><![CDATA[70]]></attendee_id><normalized_name><![CDATA[A. Sedeño Noda]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Sedeño Noda]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. M. B. Pascoal]]></normalized_name><name><![CDATA[Marta M. B.]]></name><lastname><![CDATA[Pascoal]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[71]]></id><identifier><![CDATA[XA5]]></identifier><name><![CDATA[Algoritmos metaheurísticos]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[10]]></id><name><![CDATA[Sala Viena]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[345]]></id><normalized_name><![CDATA[E. Vallada Regalado]]></normalized_name><name><![CDATA[Eva]]></name><lastname><![CDATA[Vallada Regalado]]></lastname></chairperson><papers><element><id><![CDATA[69]]></id><title><![CDATA[A successive-approximations method for the heterogeneous vehicle routing problem]]></title><text><![CDATA[In this work, an alternative procedure for solving vehicle routing problems (VRP) with different types of vehicle capacities, say Heterogeneous Vehicle Routing Problem (HVRP), has been proposed to deal with the HVRP. The main issue for VRP  is to serve node demands with a vehicle fleet located in a depot and minimize the routes costs. Our approach is based on the Successive Approximations Method (SAM) which solves, in each iteration, the Capacitated Vehicle Routing Problem (CVRP) for the non- served nodes and the maximum capacity of unused vehicles.  Any efficient algorithm can be used to solve the CVRP and the so-called Simulation Routing via Generalized Clark and Wright (SR-GCW) is applied in this work. Then, successively, the largest routes that hold from the CVRP solution are saved as a partial solution for the HVRP. Finally, regarding problem benchmarks, competitive results are obtained in reasonable computing times.]]></text><keywords><![CDATA[heterogeneous vehicle routing problem, combinatorial optimization, heuristics, local search]]></keywords><authors><element><attendee_id><![CDATA[182]]></attendee_id><normalized_name><![CDATA[A. Agustín Martín]]></normalized_name><name><![CDATA[Alba]]></name><lastname><![CDATA[Agustín Martín]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[Á. A. Juan Pérez]]></normalized_name><name><![CDATA[Ángel A.]]></name><lastname><![CDATA[Juan Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Faulín Fajardo]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Faulín Fajardo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Á. Llorente García]]></normalized_name><name><![CDATA[Miguel Ángel]]></name><lastname><![CDATA[Llorente García]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[176]]></id><title><![CDATA[Heurísticas para el problema de planificación de la extracción de bloques en minas a cielo abierto]]></title><text><![CDATA[El problema de planificación de la extracción de bloques en minas a cielo abierto (PEB) se modela como un problema de optimización lineal binario en el cual, por cada bloque de la mina (un bloque es una pequeña porción de la mina completa), se toma la decisión de si extraerlo o no y en qué momento. Desafortunadamente, una mina puede consistir en varios miles e incluso millones de bloques, de modo que el problema lineal binario asociado requiere un número enorme de variables, haciéndolo difícil de resolver. Este trabajo propone e implementa heurísticas para encontrar buenas soluciones factibles de PEB. Las heurísticas esán basadas en agregación, es decir, buscan resolver instancias del mismo problema pero de tamaño reducido o con un nivel mayor de abstracción que ayuden a buscar una solución para el problema original. Se presentan además algunos resultados numéricos promisorios al aplicar las heurísticas en instancias de tamaños similares a casos reales.]]></text><keywords><![CDATA[planificación minera, heurísticas, optimización, programación lineal entera]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Jelvez]]></normalized_name><name><![CDATA[Enrique]]></name><lastname><![CDATA[Jelvez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[N. Morales]]></normalized_name><name><![CDATA[Nelson]]></name><lastname><![CDATA[Morales]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Peypouquet]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[Peypouquet]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[155]]></id><title><![CDATA[Algoritmo genético para el problema de secuenciación en máquinas paralelas con tiempos de cambio y minimización del retraso/adelanto ponderado]]></title><text><![CDATA[En este trabajo se propone un algoritmo genético y varios modelos matemáticos existentes para el problema de secuenciación en máquinas paralelas con tiempos de cambio dependientes de la secuencia y con el objetivo de minimizar el retraso/adelanto ponderado total de los trabajos. El algoritmo incluye un procedimiento que inserta tiempos de parada en las máquinas con el objetivo de mejorar el valor del retraso/adelanto ponderado total. El valor de la función objetivo puede mejorarse de manera notable al retrasar trabajos que van adelantados, es decir, cuando la suma de los pesos o ponderaciones de los trabajos adelantados es superior a la suma de los pesos de los trabajos que van retrasados, la inserción de tiempos de parada provocando el retraso de algunos trabajos adelantados mejora el valor de la función objetivo. Se realiza una exhaustiva experimentación computacional incluyendo test estadísticos que muestran que el algoritmo propuesto se comporta de manera muy eficaz.]]></text><keywords><![CDATA[secuenciación, máquinas paralelas, algoritmo genético]]></keywords><authors><element><attendee_id><![CDATA[345]]></attendee_id><normalized_name><![CDATA[E. Vallada Regalado]]></normalized_name><name><![CDATA[Eva]]></name><lastname><![CDATA[Vallada Regalado]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[351]]></attendee_id><normalized_name><![CDATA[R. Ruiz García]]></normalized_name><name><![CDATA[Rubén]]></name><lastname><![CDATA[Ruiz García]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[68]]></id><identifier><![CDATA[XA6]]></identifier><name><![CDATA[Enseñanza de la Estadística y la Investigación Operativa 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[390]]></id><normalized_name><![CDATA[J. A. Sanchez-Espigares]]></normalized_name><name><![CDATA[José A.]]></name><lastname><![CDATA[Sanchez-Espigares]]></lastname></chairperson><papers><element><id><![CDATA[138]]></id><title><![CDATA[Aplicación Java desktop para la resolución interactiva del Simplex]]></title><text><![CDATA[Se presenta una aplicación Java desktop basada en Swing Framework que resuelve de forma guiada un problema de Programación Lineal introducido por el usuario. El objetivo fundamental es proporcionar un material didáctico que permita al usuario adquirir el mecanismo de resolución del método Simplex, estando limitada a problemas de PL en forma canónica de maximizar y un máximo de 4 variables de decisión y restricciones. La introducción de los datos del problema puede ser en formato tabla (tabla inicial del Simplex) o formato ecuación, en cuyo caso la tabla inicial la construye la aplicación. La aplicación muestra de forma sucesiva cuestiones encaminadas a la resolución del problema y plantea dos posibilidades: 1) Continuar y comprobar: se suministra la solución, sin detalles, a la pregunta propuesta. 2) Necesito ayuda: se muestra, de forma detallada sobre el problema planteado, cómo realizar los cálculos necesarios y comprobar las condiciones necesarias para llegar a la respuesta adecuada]]></text><keywords><![CDATA[método Simplex, aplicación interactiva, Java]]></keywords><authors><element><attendee_id><![CDATA[208]]></attendee_id><normalized_name><![CDATA[M. J. García-Ligero Ramírez]]></normalized_name><name><![CDATA[Maria Jesús]]></name><lastname><![CDATA[García-Ligero Ramírez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[157]]></attendee_id><normalized_name><![CDATA[P. Román Román]]></normalized_name><name><![CDATA[Patricia]]></name><lastname><![CDATA[Román Román]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[P. Valentín Serrano]]></normalized_name><name><![CDATA[Patricia]]></name><lastname><![CDATA[Valentín Serrano]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[173]]></id><title><![CDATA[Nuevos módulos de Moodle para la enseñanza de la estadística]]></title><text><![CDATA[Se presentan dos nuevos módulos de Moodle (preguntas programadas y cuestionarios con apartados) que pueden ser usados para la enseñanza de la Estadística o de cualquier otra asignatura de ámbito numérico. Estos nuevos módulos amplían las funcionalidades que ofrecen los módulos clásicos de preguntas y cuestionarios de Moodle. Con el módulo de preguntas programadas se pueden crear preguntas numéricas donde los datos del enunciado pueden ser diferentes de un alumno a otro y, por tanto, la respuesta correcta será diferente para cada alumno y debe estar programada. En este trabajo se han programado más de 200 funciones estadísticas. En el módulo de cuestionarios con apartados se pueden crear ejercicios donde se hagan diversas preguntas y que estas preguntas compartan el mismo enunciado. La combinación de estos dos nuevos módulos permite crear ejercicios diferentes para cada alumno y que se pueden realizar durante las clases prácticas de la asignatura o en clases no presenciales.]]></text><keywords><![CDATA[enseñanza, ejercicios, Moodle]]></keywords><authors><element><attendee_id><![CDATA[341]]></attendee_id><normalized_name><![CDATA[J. M. Mateo Sanz]]></normalized_name><name><![CDATA[Josep Maria]]></name><lastname><![CDATA[Mateo Sanz]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Olivé Farré]]></normalized_name><name><![CDATA[Carme]]></name><lastname><![CDATA[Olivé Farré]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[D. Puigjaner Riba]]></normalized_name><name><![CDATA[Dolors]]></name><lastname><![CDATA[Puigjaner Riba]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[229]]></id><title><![CDATA[PRESTON: Prácticas estadísticas competitivas online para la toma de decisiones]]></title><text><![CDATA[Se presenta un caso de rediseño de las sesiones prácticas en asignaturas de introducción a la estadística. Tras realizar un diagnóstico del diseño previo teniendo en cuenta la introducción del EEES,  se propuso un juego competitivo on-line de toma de decisiones utilizando la estadística. El juego se basa en un caso realista, lo que permite que las prácticas no se perciban como un ejercicio en el que el fin sea obtener p-valores, $R^2$, etc., y mejore la motivación. El juego utiliza datos simulados y una interface web en la que los estudiantes (1) adquieren datos consumiendo un presupuesto (con ello se pretende incitarles a pensar la estrategia de obtención y a reflexionar sobre su coste), (2) introducen las decisiones que toman, y (3) hacen el seguimiento de su posición en el juego. El formato on-line permite mayor flexibilidad posibilidades de auto-aprendizaje. El resultado final, denominado PRESTON (PRácticas de ESTadística ON-line), ha sido ya probado con un grupo de estudiantes. ]]></text><keywords><![CDATA[estadística, innovación docente, auto-aprendizaje, formato on-line, sesiones prácticas, juego, toma de decisiones, EEES]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[O. Camps Lorente]]></normalized_name><name><![CDATA[Oriol]]></name><lastname><![CDATA[Camps Lorente]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[390]]></attendee_id><normalized_name><![CDATA[J. A. Sanchez-Espigares]]></normalized_name><name><![CDATA[José A.]]></name><lastname><![CDATA[Sanchez-Espigares]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. Rodero de Lamo]]></normalized_name><name><![CDATA[Lourdes]]></name><lastname><![CDATA[Rodero de Lamo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. Marco Almagro]]></normalized_name><name><![CDATA[Lluis]]></name><lastname><![CDATA[Marco Almagro]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[X. Tort-Martorell Llabrés]]></normalized_name><name><![CDATA[Xavier]]></name><lastname><![CDATA[Tort-Martorell Llabrés]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[X. Puig Oriol]]></normalized_name><name><![CDATA[Xavier]]></name><lastname><![CDATA[Puig Oriol]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Riba Civil]]></normalized_name><name><![CDATA[Alexandre]]></name><lastname><![CDATA[Riba Civil]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[77]]></id><identifier><![CDATA[XA7]]></identifier><name><![CDATA[Análisis de datos funcionales 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[12]]></id><name><![CDATA[Sala Roma II]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[454]]></id><normalized_name><![CDATA[D. Valencia]]></normalized_name><name><![CDATA[Dalia]]></name><lastname><![CDATA[Valencia]]></lastname></chairperson><papers><element><id><![CDATA[216]]></id><title><![CDATA[Caracterización estadística de las medidas tomadas en las subestaciones eléctricas ]]></title><text><![CDATA[En este trabajo se propone un algoritmo para caracterizar la distribución estadística de las medidas transmitidas al Centro de Control de cualquier subestación eléctrica. El procedimiento propuesto se basa en el Método de Estimación por Puntos, y permite calcular una estimación del primer y el segundo momento (cruzado y no cruzado) de dichas medidas. Adicionalmente se ha diseñado un algoritmo de Monte Carlo para comprobar los resultados. La eficiencia computacional y la precisión numérica se evalúan usando el sistema IEEE de 118 nudos.]]></text><keywords><![CDATA[estimación por puntos, método de Monte Carlo, dependencias, coeficiente de correlación.]]></keywords><authors/></element><element><id><![CDATA[261]]></id><title><![CDATA[Propuestas para la selección de variables en el problema de clasificación funcional]]></title><text><![CDATA[La clasificación de datos funcionales es un problema relevante en la actualidad. Las técnicas de selección de variables, hasta ahora poco estudiadas en el ámbito funcional, pueden ser herramientas eficaces. Sus objetivos básicos serían similares al de las técnicas usuales de reducción de la dimensión (componentes principales, PLS, etc.) pero con la ventaja de una mayor interpretabilidad. En este trabajo en curso, se plantean  distintas propuestas y resultados preliminares sobre selección de variables en clasificación funcional teniendo en cuenta las características propias de estos datos. Se exploran las vías de la utilización de algoritmos ya existentes en el análisis multivariado como el de ``mínima redundacia y máxima relevancia'', mRMR (Ding y Peng 2005), la incorporación de nuevas medidas de asociación a estos algoritmos y nuevas formas de usar estas medidas basadas en el estudio de sus máximos. ]]></text><keywords><![CDATA[clasificación supervisada, FDA, selección de variables, medidas de asociación, mRMR]]></keywords><authors><element><attendee_id><![CDATA[405]]></attendee_id><normalized_name><![CDATA[J. R. Berrendero Díaz]]></normalized_name><name><![CDATA[José Ramón]]></name><lastname><![CDATA[Berrendero Díaz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[378]]></attendee_id><normalized_name><![CDATA[A. Cuevas González]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Cuevas González]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[198]]></id><title><![CDATA[Sobre la estimación del eje medial]]></title><text><![CDATA[El eje medial (``medial axis'') de un conjunto C se define como el subconjunto de los puntos de C que tienen al menos dos proyecciones sobre la frontera de C. El estudio del eje medial tiene interés en problemas de análisis de imágenes y presenta ciertas afinidades conceptuales con la teoría de ``curvas principales''. Presentamos un estimador consistente de ``la parte substancial'' del eje medial para el caso en que el conjunto C sea compacto y r-convexo (i.e., C puede expresarse como la intersección de los complementarios de una familia de bolas abiertas de radio r) y la información muestral procede de una muestra aleatoria de puntos elegidos dentro de C. Se comentarán brevemente los aspectos prácticos y computacionales de este estimador y se analizarán las conexiones de este problema con otros temas afines en la teoría de estimación de conjuntos. Este es un trabajo en proceso de elaboración, aún incompleto en el momento de redactar este resumen. ]]></text><keywords><![CDATA[set estimation, medial axis, r-convexity]]></keywords><authors><element><attendee_id><![CDATA[378]]></attendee_id><normalized_name><![CDATA[A. Cuevas González]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Cuevas González]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[P. Llop]]></normalized_name><name><![CDATA[Pamela]]></name><lastname><![CDATA[Llop]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[B. Pateiro López]]></normalized_name><name><![CDATA[Beatriz]]></name><lastname><![CDATA[Pateiro López]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[275]]></id><title><![CDATA[Contraste de independencia para datos funcionales]]></title><text><![CDATA[El coeficiente de correlación de Spearman es un coeficiente que mide tradicionalmente dependencia entre variables aleatorias y presenta ventajas sobre el coeficiente de Pearson pues no captura solamente la dependencia lineal.  En esta charla se presenta una extensión del coeficiente  de correlación de Spearman para datos funcionales que permite cuantificar la dependencia para este tipo de datos. Se propone además un  contraste de hipótesis de independencia  basado en dicho coeficiente. La eficacia y potencia del contraste se ilustra con ejemplos de datos simulados y reales.]]></text><keywords><![CDATA[test de independencia, datos funcionales]]></keywords><authors><element><attendee_id><![CDATA[454]]></attendee_id><normalized_name><![CDATA[D. Valencia]]></normalized_name><name><![CDATA[Dalia]]></name><lastname><![CDATA[Valencia]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. E. Lillo]]></normalized_name><name><![CDATA[Rosa E.]]></name><lastname><![CDATA[Lillo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Romo]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[Romo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[15]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Pausa]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:20:00]]></start><end><![CDATA[10:30:00]]></end><location><![CDATA[]]></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[33]]></id><identifier><![CDATA[XB1]]></identifier><name><![CDATA[Conferencia plenaria]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[218]]></id><normalized_name><![CDATA[M. A. López-Cerdá]]></normalized_name><name><![CDATA[Marco Antonio]]></name><lastname><![CDATA[López-Cerdá]]></lastname></chairperson><papers><element><id><![CDATA[95]]></id><title><![CDATA[Some combinatorial optimization problems in a conflict situation]]></title><text><![CDATA[When a complex system has to be protected  against attacks, one is often led to identify the d most vital elements of the system. In a similar spirit when a player A has to choose an action between a collection of “optimal” actions, one may imagine that an opponent P may try to prevent A from making a good choice by destroying some elements of the system. This can be concretized in several ways. We shall concentrate for illustration purposes to the case where the system is represented by a graph G (in which every vertex has a positive weight); the possible actions of A are the maximum weight independent (or stable) subsets S of vertices in G. Let d be a fixed integer. The opponent P has two options.  Either find a minimum subset T of vertices to remove from G which is such that T has in common with every S  a subset of vertices with total weight at least d or find a minimum subset  B of vertices to remove such that in G-B the maximum weight of an independent subset S has decreased by at least d. We shall discuss this model and related ones and present a solution procedure for a bipartite graph G. Complexity of related problems will be stated.  This is joint work with C.Bentz (Univ. Paris-Sud, Orsay), M.C.Costa (ENSTA, Paris), C.Picouleau (CNAM,Paris), B.Ries (Univ . Dauphine, Paris).]]></text><keywords><![CDATA[transversal, stable set, bipartite graph, network flow]]></keywords><authors/></element></papers></element><element><id><![CDATA[7]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Pausa - Café]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[11:30:00]]></start><end><![CDATA[12:00:00]]></end><location><id><![CDATA[17]]></id><name><![CDATA[Hall Plaza Mayor]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[36]]></id><identifier><![CDATA[XC1a]]></identifier><name><![CDATA[Pósters (Estadística)]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[266]]></id><normalized_name><![CDATA[J. Cano Cancela]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Cano Cancela]]></lastname></chairperson><papers><element><id><![CDATA[52]]></id><title><![CDATA[Possibilistic mean-variance (M-V) and mean-semivariance (M-SV) models for portfolio selection]]></title><text><![CDATA[It is studied extensions of the classical Markowitz's portfolio selection model in a fuzzy context using new fuzzy measures. Markowitz's M-V model presents the investor's problem as a mathematical programming problem. Fuzzy theory allows us to represent the investor's preferences. It is possible to integrate these techniques and to consider portfolio selection problems in fuzzy contexts. Though variance (v) has been a popular risk measure, it considers that deviations above the mean (m) are equally undesirable than deviations below m, but in economic context, since low part deviation from m means possible loss of wealth and high part deviation from m means the existence of potential return, it has shown that semivariance is better, as a risk measure, than v. Due to this fact, a new approximation is proposed, introducing the crisp possibilistic semivariance of a fuzzy number and defining the optimization problems for that risk measure. Some numerical examples are given.]]></text><keywords><![CDATA[fuzzy number, mean-variance model, mean-semivariance model, portfolio selection]]></keywords><authors><element><attendee_id><![CDATA[120]]></attendee_id><normalized_name><![CDATA[E. Almaraz Luengo]]></normalized_name><name><![CDATA[Elena]]></name><lastname><![CDATA[Almaraz Luengo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Almaraz Luengo]]></normalized_name><name><![CDATA[Eduardo]]></name><lastname><![CDATA[Almaraz Luengo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Luengo y Dos Santos]]></normalized_name><name><![CDATA[Maribel ]]></name><lastname><![CDATA[Luengo y Dos Santos]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[227]]></id><title><![CDATA[Atractivo de una localidad como lugar de residencia y de trabajo. Un análisis bayesiano basado en modelos de interacción con efectos espaciales.]]></title><text><![CDATA[En este trabajo se propone un modelo de interacción con efectos espaciales para estimar, de forma simultánea, los niveles de accesibilidad laboral y atracción como lugar de residencia de un conjunto de localidades, incorporando en el proceso de estimación la influencia de características socio-demográficas así como la existencia de dependencias espaciales. La estimación de los parámetros del modelo se realiza desde una óptica bayesiana que permite obtener inferencias exactas acerca de los mismos así como realizar procesos de comparación de modelos que ayuden a determinar, por un lado, la forma en la que influye la distancia entre localidades (función de impedancia) y, por el otro, cuáles son las covariables que ejercen una influencia significativa sobre su atractivo como lugar de residencia y de trabajo. La metodología se ilustra con un ejemplo empírico que utiliza datos del Censo de 2001 referentes a la movilidad laboral diaria entre municipios de la comunidad de Aragón (España).]]></text><keywords><![CDATA[accesibilidad laboral, atractivo residencial, modelos de interacción espacial, inferencia bayesiana ]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. P. Alonso Logroño]]></normalized_name><name><![CDATA[Mª Pilar]]></name><lastname><![CDATA[Alonso Logroño ]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Beamonte San Agustín]]></normalized_name><name><![CDATA[Asunción]]></name><lastname><![CDATA[Beamonte San Agustín]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[412]]></attendee_id><normalized_name><![CDATA[P. Gargallo Valero]]></normalized_name><name><![CDATA[Pilar]]></name><lastname><![CDATA[Gargallo Valero]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Salvador Figueras]]></normalized_name><name><![CDATA[Manuel]]></name><lastname><![CDATA[Salvador Figueras ]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[279]]></id><title><![CDATA[Measuring the real estate   bubble: a house price index for Bilbao]]></title><text><![CDATA[During the first years of the present century housing prices in Spain have experienced substantial increases. As the real state bubble began to deteriorate after the onset of the financial crisis of 2008, widely different figures have been given on how much housing prices have already dropped. In this paper we obtain an index as the estimate of the price level in a semi-parametric model of readily available offered prices in the city of Bilbao (Spain). We fit a model to the log price per squared meter to capture the influence on house prices of several attributes, the effect of time and the influence of the location. The suitably normalized profile of the effect of time provides an estimate of the price index. To include the effect of the location, two approaches have been used: including the postal code as a categorical regressor and using geographically weighted regression, with each house geocoded to UTM coordinates, and a backfitting algorithm.]]></text><keywords><![CDATA[hedonic models, geographically weighted regression,price index, spatio-temporal data]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. J. Bárcena Ruiz]]></normalized_name><name><![CDATA[Mª Jesús]]></name><lastname><![CDATA[Bárcena Ruiz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[P. Menéndez]]></normalized_name><name><![CDATA[Patricia]]></name><lastname><![CDATA[Menéndez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[447]]></attendee_id><normalized_name><![CDATA[M. B. Palacios Navarro]]></normalized_name><name><![CDATA[Mª Blanca]]></name><lastname><![CDATA[Palacios Navarro]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Tusell Palmer]]></normalized_name><name><![CDATA[Fernando]]></name><lastname><![CDATA[Tusell Palmer]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[26]]></id><title><![CDATA[Un enfoque Bayesiano para las medidas de acuerdo entre dos decisores]]></title><text><![CDATA[En los procesos de toma de decisiones, en algunas ocasiones, resulta necesario conocer el grado de acuerdo entre los decisores. En estos casos es importante medir la homogeneidad del acuerdo y los índices de acuerdo cumplen con este propósito, proporcionando una medida basada en la opinión de los decisores. En este trabajo se analizan diferentes medidas de acuerdo planteadas desde el punto de vista Bayesiano, utilizando varios escenarios de información inicial que muestran la importancia de contar con información previa. Para este trabajo se ha diseñado y llevado a cabo una prueba triangular de análisis sensorial. Esta prueba consiste en cata por parte de dos personas (no expertas) de dos embutidos ibéricos extra, uno de marca blanca y otro de marca reconocida con denominación de origen. El estudio de las medidas de acuerdo permitió deducir la existencia de un grado de acuerdo alto entre los decisores y que la marca con denominación de origen era considerada de mayor calidad.]]></text><keywords><![CDATA[medidas de acuerdo, metodología Bayesiana, mixtura de distribuciones a priori, prueba triangular]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Calle Alonso]]></normalized_name><name><![CDATA[Fernando]]></name><lastname><![CDATA[Calle Alonso]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[198]]></attendee_id><normalized_name><![CDATA[C. J. Pérez Sánchez]]></normalized_name><name><![CDATA[Carlos Javier]]></name><lastname><![CDATA[Pérez Sánchez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. P. Arias Nicolás]]></normalized_name><name><![CDATA[José Pablo]]></name><lastname><![CDATA[Arias Nicolás]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[298]]></attendee_id><normalized_name><![CDATA[J. Martín Jiménez]]></normalized_name><name><![CDATA[Jacinto]]></name><lastname><![CDATA[Martín Jiménez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[104]]></id><title><![CDATA[Un estudio por simulación de la  influencia de las técnicas de predicción de la demanda en  la eficiencia de una cadena de suministro ]]></title><text><![CDATA[En el estudio de una cadena de suministro resulta primordial controlar tres parámetros que de alguna manera miden la eficiencia de la misma: el Fill Rate (proporción de la demanda que se satisface), el NSAMP (Net Stock Amplification) y el llamado efecto Forrester o Bullwhip. Una ineficiente previsión de la demanda es en muchos casos la causante del aumento de estos parámetros y por tanto del funcionamiento ineficiente de la cadena de suministro.  En el presente trabajo se muestran los resultados obtenidos por simulación utilizando diversas técnicas de predicción sobre diferentes patrones de demanda.]]></text><keywords><![CDATA[técnicas de predicción, Bullwhip, NSAMP, fill rate, cadena de suministro]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Campuzano Bolarín]]></normalized_name><name><![CDATA[Francisco]]></name><lastname><![CDATA[Campuzano Bolarín]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[238]]></attendee_id><normalized_name><![CDATA[A. Guillamón Frutos]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Guillamón Frutos]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[139]]></attendee_id><normalized_name><![CDATA[M. D. C. Ruiz Abellón]]></normalized_name><name><![CDATA[María del Carmen]]></name><lastname><![CDATA[Ruiz Abellón]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[270]]></id><title><![CDATA[Objective bayesian model selection approach to linear contrasts between means for one way ANOVA]]></title><text><![CDATA[An objective Bayesian model selection procedure for one way analysis of variance under heteroscedasticity was proposed in Bertolino et al. (2000)  and, and, recently, specific solutions for the special case when homoscedasticity is present have been developed in Cano et al. (2011). In this paper a solution based on an objective Bayesian model selection procedure is proposed for linear contrasts between means for the one way ANOVA in the context of both homoscedasticity and heteroscedasticity. Bayes factors for intrinsic priors are used instead of Bayes factors for the usual default prior distributions since for them Bayes factors are not well defined. The classical p-value and posterior probability of the null hypothesis are compared through so-called calibration curves. The behavior of these calibration curves as a function of the sample size is studied too and some interesting conclusions are drawn.]]></text><keywords><![CDATA[linear contrasts between means, model selection, Bayes factor, intrinsic priors, robustness, calibration curve]]></keywords><authors><element><attendee_id><![CDATA[426]]></attendee_id><normalized_name><![CDATA[J. A. Cano Sánchez]]></normalized_name><name><![CDATA[Juan Antonio]]></name><lastname><![CDATA[Cano Sánchez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Carazo Díaz]]></normalized_name><name><![CDATA[Carmen]]></name><lastname><![CDATA[Carazo Díaz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[D. Salmerón Martínez]]></normalized_name><name><![CDATA[Diego]]></name><lastname><![CDATA[Salmerón Martínez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[300]]></id><title><![CDATA[Capacidad de modelización de la distribución NLM-multinomial]]></title><text><![CDATA[Las mixturas gaussianas han sido ampliamente utilizadas para la clasificación i/o modelización de variables multivariantes continuas. En el caso de variables discretas o de conteo, diferentes mixturas de distribuciones han sido propuestas en la literatura, desde mixturas multinomiales a propuestas más recientes como mixturas de distribuciones basadas en familias de Liouville. En su amplia bibliografia Aitchison introduce una metología para el análisis de datos composicionales. Una de las principales distribuciones presentadas, la normal logística multivariante (NLM), permite la modelización de probabilidades de variables discretas de forma equivalente a la distribución normal multivariante para variables continuas en espacios reales. En este trabajo se modelan las probabilidades(parámetros) de una multinomial con una distribución NLM, obteniendo así, una nueva distribución NLM-multinomial. También, se analizarán las capacidades expresivas de una NLM-multinomial mixtura.]]></text><keywords><![CDATA[mixturas, multinomial, datos composicionales, modelización]]></keywords><authors><element><attendee_id><![CDATA[471]]></attendee_id><normalized_name><![CDATA[M. Comas-Cufí]]></normalized_name><name><![CDATA[Marc]]></name><lastname><![CDATA[Comas-Cufí]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[230]]></attendee_id><normalized_name><![CDATA[G. Mateu-Figueras]]></normalized_name><name><![CDATA[Glòria]]></name><lastname><![CDATA[Mateu-Figueras]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Thió-Henestrosa]]></normalized_name><name><![CDATA[Santi]]></name><lastname><![CDATA[Thió-Henestrosa]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[267]]></id><title><![CDATA[Estimación de funciones de regresión con datos no directamente observables]]></title><text><![CDATA[El objetivo de este trabajo consiste en la estimación no paramétrica de una función de regresión en donde la variable respuesta no es directamente observable, y está definida como el tiempo transcurrido entre dos sucesos de un proceso de renovación estacionario. Los datos observables son los tiempos desde la ocurrencia del último suceso del proceso hasta el instante de muestreo, esto es, los tiempos de recurrencia hacia atrás en dicho proceso, junto con observaciones de un conjunto dado de covariables. Los estimadores se obtienen adaptando un procedimiento bootstrap a datos sesgados que están íntimamente relacionados con los datos obtenidos bajo nuestro tipo particular de muestreo. Finalmente, damos un pequeño estudio de simulación para ilustrar el comportamiento de los estimadores obtenidos.]]></text><keywords><![CDATA[bootstsrap, distribución sesgada por longitud, estimación no paramétrica, proceso de renovación, tiempos de recurrencia]]></keywords><authors><element><attendee_id><![CDATA[413]]></attendee_id><normalized_name><![CDATA[J. A. Cristóbal Cristóbal]]></normalized_name><name><![CDATA[José Antonio]]></name><lastname><![CDATA[Cristóbal Cristóbal]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[508]]></attendee_id><normalized_name><![CDATA[P. Olave Rubio]]></normalized_name><name><![CDATA[Pilar]]></name><lastname><![CDATA[Olave Rubio]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[433]]></attendee_id><normalized_name><![CDATA[J. T. Alcalá Nalvaiz]]></normalized_name><name><![CDATA[José Tomás]]></name><lastname><![CDATA[Alcalá Nalvaiz]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[122]]></id><title><![CDATA[Representación y clasificación basada en RFD]]></title><text><![CDATA[En trabajos previos, los autores han propuesto la construcción de un índice de disimilaridad entre poblaciones estadísticas sin la hipótesis de un modelo estadístico concreto. Dicho índice está basado en algunas propiedades de la métrica informativa y permite distanciar las poblaciones basándose en aquellas características poblacionales que el investigador considera relevantes. Nos referiremos a ella como Relevant Features Dissimilarity (RFD). Hasta el momento la disimilaridad RFD se ha utilizado para el cálculo de matrices de disimilaridad entre poblaciones y para su posterior representación en dimensión reducida a través de un MDS. Se ha aplicado y verificado tanto en datos simulados como en datos reales. En el presente trabajo nos planteamos un paso más allá al utilizar la disimilaridad para permitir una representación simultánea de poblaciones e individuos, así como para permitir la detección gráfica de outliers con una posible utilidad en análisis discriminante y clasificación.]]></text><keywords><![CDATA[métrica informativa, distancia de Mahalanobis, distancia de Rao]]></keywords><authors><element><attendee_id><![CDATA[184]]></attendee_id><normalized_name><![CDATA[M. Cubedo Culleré]]></normalized_name><name><![CDATA[Marta]]></name><lastname><![CDATA[Cubedo Culleré]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[175]]></attendee_id><normalized_name><![CDATA[A. Miñarro Alonso]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Miñarro Alonso]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. M. Oller Sala]]></normalized_name><name><![CDATA[Josep Maria]]></name><lastname><![CDATA[Oller Sala]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[310]]></id><title><![CDATA[Fitting FPCA - based mixed effect model for testing significance level]]></title><text><![CDATA[En este trabajo se propone un modelo de efectos mixtos para describir las curvas de percepción táctil humana, en términos de su proyección en las bases de autofunciones que diagonalizan sus estructuras empíricas funcionales de autocovarianza. La variabilidad residual, tras el truncamiento, se asocia al término de  error del modelo de efectos mixtos funcional, mientras que el efecto aleatorio recoge la variabilidad explicada con la aproximación finito-dimensional. Se plantea asimismo un test para contrastar la significación de los efectos fijos funcionales. Los resultados derivados se ilustran mediante un ejemplo simulado, a partir de la generación de curvas de percepción táctil humana.]]></text><keywords><![CDATA[análisis de componentes principales funcional, representación de Fourier, modelo de efectos mixtos, pruebas de nivel de significación]]></keywords><authors><element><attendee_id><![CDATA[241]]></attendee_id><normalized_name><![CDATA[E. Delgado Márquez]]></normalized_name><name><![CDATA[Elvira]]></name><lastname><![CDATA[Delgado Márquez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[476]]></attendee_id><normalized_name><![CDATA[M. D. Ruiz Medina]]></normalized_name><name><![CDATA[María Dolores]]></name><lastname><![CDATA[Ruiz Medina ]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[335]]></attendee_id><normalized_name><![CDATA[J. López Fidalgo]]></normalized_name><name><![CDATA[Jesús]]></name><lastname><![CDATA[López Fidalgo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[84]]></id><title><![CDATA[50 aniversario de la SEIO: una fecha para conmemorar]]></title><text><![CDATA[Con motivo de cumplirse este año 2012 medio siglo de la fundación de la SEIO (Sociedad Española de Estadística e Investigación Operativa), nuestro trabajo pretende homenajear a la Institución y a sus fundadores haciendo un recorrido desde sus orígenes hasta la actualidad. En esta trayectoria intervendrán los personajes más destacados, la historia y evolución de sus publicaciones en los distintos formatos existentes, el nivel de impacto de sus actuales revistas de investigación (TEST y TOP), la estructura interna de la sociedad, los vínculos con otras instituciones, los grupos de investigación y trabajo existentes en su seno, y otros hechos relevantes para la Sociedad que pondrán en evidencia su importancia tanto a nivel nacional como internacional.]]></text><keywords><![CDATA[historia, aniversario, SEIO]]></keywords><authors/></element><element><id><![CDATA[147]]></id><title><![CDATA[Algoritmos para el cálculo de diseños óptimos en modelos multifactoriales]]></title><text><![CDATA[En muchos experimentos de interés en la biología y la industria, varios factores se encuentran de manera simultánea bajo el control del experimentador. En estos casos es de gran utilidad el cálculo de diseños óptimos que permitan obtener estimaciones más precisas de los parámetros desconocidos. En la mayoría de modelos no lineales y de carácter multifactorial, la obtención analítica de los diseños localmente óptimos resulta imposible, siendo necesarios procedimientos algorítmicos para su cálculo. En este trabajo comparamos el algoritmo secuencial de Wynn-Fedorov con el algoritmo Multiplicativo para el cálculo de diseños D- y A-óptimos en modelos de inhibición enzimática. El primero de los métodos añade puntos al diseño inicial basándose en la información proporcionada por el teorema de equivalencia, mientras que el segundo método calcula los puntos del diseño transformando el espacio de diseño en proporciones definidas por los subintervalos entre puntos del diseño consecutivos.]]></text><keywords><![CDATA[diseño optimo de experimentos, algoritmo multiplicativo, algoritmo de Wynn-Fedorov ]]></keywords><authors><element><attendee_id><![CDATA[531]]></attendee_id><normalized_name><![CDATA[M. M. Fernández]]></normalized_name><name><![CDATA[Mª Mercedes]]></name><lastname><![CDATA[Fernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Martín Martín]]></normalized_name><name><![CDATA[Raúl]]></name><lastname><![CDATA[Martín Martín]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[227]]></attendee_id><normalized_name><![CDATA[L. J. Rodríguez-Aragón]]></normalized_name><name><![CDATA[Licesio J.]]></name><lastname><![CDATA[Rodríguez-Aragón]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[20]]></id><title><![CDATA[Nuevos algoritmos de estimación en sistemas lineales con observaciones inciertas con correlación en la incertidumbre]]></title><text><![CDATA[En este trabajo abordamos el problema de estimación lineal mínimo cuadrática en sistemas lineales con observaciones inciertas, que incluyen en la ecuación de observación ruido aditivo y ruido multiplicativo descrito por una sucesión de variables de Bernoulli cuyos valores -uno o cero- indican la presencia o no de señal en la observación correspondiente. Suponiendo que dichas variables están correladas en instantes que difieren m unidades de tiempo (hipótesis que permite considerar modelos en los que la señal no puede estar ausente en m+1 observaciones consecutivas) y usando un tratamiento por innovaciones, obtenemos algoritmos para el filtro y suavizador punto fijo, que proporcionan también las covarianzas de sus errores de estimación. Para ilustrar el comportamiento de los estimadores, consideramos una señal bidimensional y estudiamos la precisión de los estimadores para diferentes valores de la probabilidad de que la señal esté presente en las observaciones y distintos valores de m.]]></text><keywords><![CDATA[estimación de mínimos cuadrados, observaciones inciertas]]></keywords><authors><element><attendee_id><![CDATA[143]]></attendee_id><normalized_name><![CDATA[I. García Garrido]]></normalized_name><name><![CDATA[Irene]]></name><lastname><![CDATA[García Garrido]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Linares Pérez]]></normalized_name><name><![CDATA[Josefa]]></name><lastname><![CDATA[Linares Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[484]]></attendee_id><normalized_name><![CDATA[C. R. Caballero Águila]]></normalized_name><name><![CDATA[Carmen Raquel]]></name><lastname><![CDATA[Caballero Águila]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[140]]></id><title><![CDATA[Suavizamiento punto fijo en sistemas estocásticos con retrasos markovianos]]></title><text><![CDATA[La estimación de señales a partir de múltiples sensores es de gran interés debido a su aplicación en sistemas complejos. La fusión de la información proporcionada por los sensores se procesa usualmente por los métodos centralizado y distribuido; las ventajas computacionales del primero generalmente lo hacen preferible frente al segundo. Por otra parte, en redes de comunicaciones, es inevitable la existencia de errores que pueden llevar a retrasos en la llegada de las observaciones. En este trabajo se estudia el problema de suavizamiento punto fijo a partir de observaciones retrasadas procedentes de múltiples sensores con retrasos modelizados por cadenas de Markov homogéneas. Utilizando la información proporcionada por las covarianzas de la señal y los ruidos, se obtienen suavizadores locales de menor error cuadrático medio a partir de cada uno de los sensores y el suavizador distribuido se deduce como combinación lineal de estos usando el criterio de mínimos cuadrados.]]></text><keywords><![CDATA[suavizamiento punto fijo, retrasos markovianos]]></keywords><authors><element><attendee_id><![CDATA[208]]></attendee_id><normalized_name><![CDATA[M. J. García-Ligero Ramírez]]></normalized_name><name><![CDATA[Maria Jesús]]></name><lastname><![CDATA[García-Ligero Ramírez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Hemoso-Carazo]]></normalized_name><name><![CDATA[Aurora]]></name><lastname><![CDATA[Hemoso-Carazo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Linares-Pérez]]></normalized_name><name><![CDATA[Josefa]]></name><lastname><![CDATA[Linares-Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[137]]></id><title><![CDATA[Medidas complementarias para la decisión en el pronóstico del número de Wolf]]></title><text><![CDATA[El conocimiento de las variaciones de la actividad solar y sus causas responde a necesidades de tipo práctico en áreas tan diversas como la comunicación, navegación o el clima. Un registro de éste tipo de actividad solar es el llamado número de Wolf, una cantidad que mide el número y tamaño de las manchas solares. Este trabajo muestra que los modelos ARMA para el pronóstico en el número de Wolf adolecen de información conjunta tiempo-frecuencia, y se aportan medidas complementarias basadas en la entropía wavelet que suplen dicha debilidad. En este sentido se demostrará que en los momentos de baja actividad solar puede existir un desorden (en términos de información) elevado de la serie, influyendo en la posible toma de decisiones en las áreas de investigación anteriormente citadas.]]></text><keywords><![CDATA[número de Wolf, modelos ARMA, entropía wavelet.]]></keywords><authors><element><attendee_id><![CDATA[320]]></attendee_id><normalized_name><![CDATA[J. A. García Ramos]]></normalized_name><name><![CDATA[Juan Antonio]]></name><lastname><![CDATA[García Ramos]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[105]]></attendee_id><normalized_name><![CDATA[A. Berihuete]]></normalized_name><name><![CDATA[Angel]]></name><lastname><![CDATA[Berihuete]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[104]]></attendee_id><normalized_name><![CDATA[A. Jimenez Jimenez]]></normalized_name><name><![CDATA[Andres]]></name><lastname><![CDATA[Jimenez Jimenez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Álvarez González]]></normalized_name><name><![CDATA[Francisco]]></name><lastname><![CDATA[Álvarez González]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[184]]></id><title><![CDATA[A single index model procedure for interpolation intervals in time series]]></title><text><![CDATA[In this paper we propose a Single Index Model procedure for constructing interpolation intervals for a general class of linear processes. We present a Monte Carlo experiment studying the finite sample properties of the Single Index Model. Finally, we illustrate the performance of the proposed method with a real data example.]]></text><keywords><![CDATA[single index model, interpolation intervals, sieve bootstrap]]></keywords><authors><element><attendee_id><![CDATA[371]]></attendee_id><normalized_name><![CDATA[A. E. García Sipols]]></normalized_name><name><![CDATA[Ana Elizabeth]]></name><lastname><![CDATA[García Sipols]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[146]]></attendee_id><normalized_name><![CDATA[A. M. Alonso Fernandez]]></normalized_name><name><![CDATA[Andres M.]]></name><lastname><![CDATA[Alonso Fernandez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Quintas]]></normalized_name><name><![CDATA[Silvia]]></name><lastname><![CDATA[Quintas]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[110]]></id><title><![CDATA[Estimación de la distribución espacial a través del variograma indicador de tipo núcleo]]></title><text><![CDATA[En diversas situaciones prácticas se precisa la aproximación de la distribución de un proceso estocástico espacial. Con este objeto, se puede elegir un modelo paramétrico, aunque la validez del mismo no siempre se puede garantizar a partir del conjunto de datos observados. El kriging indicador proporciona un mecanismo alternativo para aproximar la distribución, si bien requiere la estimación del variograma indicador. En este trabajo se sugiere la utilización del variograma de tipo núcleo, que se comparará con el estimador de Matheron en su aplicación a la resolución del sistema de ecuaciones kriging. También se considerará otro mecanismo de aproximación de la distribución, basado en la relación entre esta última y el umbral del variograma. Dicho procedimiento también requiere la construcción de un estimador del variograma (de tipo núcleo o de Matheron) pero, a diferencia del kriging indicador, se reduce a la resolución de una ecuación de segundo grado.]]></text><keywords><![CDATA[kriging indicador, método núcleo, umbral, variograma]]></keywords><authors><element><attendee_id><![CDATA[306]]></attendee_id><normalized_name><![CDATA[P. García Soidán]]></normalized_name><name><![CDATA[Pilar]]></name><lastname><![CDATA[García Soidán]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Menezes]]></normalized_name><name><![CDATA[Raquel]]></name><lastname><![CDATA[Menezes]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[Ó. Rubiños López]]></normalized_name><name><![CDATA[Óscar]]></name><lastname><![CDATA[Rubiños López]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[266]]></id><title><![CDATA[Estimación de mínima divergencia en procesos de semi-Markov]]></title><text><![CDATA[En este trabajo consideramos el problema de estimación de los elementos que definen un proceso semi-Markov homogéneo. Dada una trayectoria muestral del proceso registrada en un intervalo finito, pueden construirse los estimadores empíricos para las componentes de la matriz núcleo de semi-Markov así como para las correspondientes derivadas de Radon-Nikodym. En nuestro enfoque del problema, vamos a considerar que tenemos cierta información previa sobre el proceso subyacente. Esta información se refiere a los tiempos medios de permanencia en los diversos estados del proceso y debe tenerse en cuenta en el procedimiento de estimación.  Por tanto, en primer lugar construimos estimadores suaves de las funciones que definen el proceso a partir de los estimadores empíricos antes mencionados y en segundo lugar, obtenemos estimadores de mínima divergencia con respecto a estos estimadores suaves, bajo algunas restricciones sobre los momentos asociados a los tiempos de permanencia del proceso.]]></text><keywords><![CDATA[estimacion tipo núcleo, entropia, Kullback-Leibler, sistemas multi-estados]]></keywords><authors><element><attendee_id><![CDATA[448]]></attendee_id><normalized_name><![CDATA[M. Gámiz Pérez]]></normalized_name><name><![CDATA[M.Luz]]></name><lastname><![CDATA[Gámiz Pérez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[N. Limnios]]></normalized_name><name><![CDATA[Nikolaos]]></name><lastname><![CDATA[Limnios]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[48]]></id><title><![CDATA[Adaptación y aplicación de un test de tipicalidad para la identificación de lugares desconocidos en robótica móvil]]></title><text><![CDATA[Uno de los grandes retos de la investigación en Robótica es la exploración autónoma de entornos desconocidos. Para  ello, el robot utiliza métodos de navegación, y además de algoritmos para poder realizar movimientos seguros en el entorno,  necesita disponer de la habilidad de ``reconocer'' sitios que ya haya visitado. Muy frecuentemente, el objetivo de la exploración en entornos semiestructurados es la construcción del mapa del entorno. Para ello, el robot debe ser capaz de identificar durante la exploración del entorno que lleva a cabo cuándo llega a un sitio nuevo, o a uno previamente visitado. En este trabajo se muestra que el test de tipicalidad basado en distancias (INCA) es una herramienta multivariante adecuada para resolver este problema. Tras adaptar el test a las necesidades específicas de la obtención de datos del robot, se muestra el proceso completo de construcción de un mapa del entorno realizado por un robot real en un proceso de exploración.]]></text><keywords><![CDATA[typicality, loop-closing, robot exploration]]></keywords><authors><element><attendee_id><![CDATA[164]]></attendee_id><normalized_name><![CDATA[I. Irigoien Garbizu]]></normalized_name><name><![CDATA[Itziar]]></name><lastname><![CDATA[Irigoien Garbizu]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Jauregi Iztueta]]></normalized_name><name><![CDATA[Ekaitz]]></name><lastname><![CDATA[Jauregi Iztueta]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[B. Sierra Araujo]]></normalized_name><name><![CDATA[Basilio]]></name><lastname><![CDATA[Sierra Araujo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Lazkano Ortega]]></normalized_name><name><![CDATA[Elena]]></name><lastname><![CDATA[Lazkano Ortega]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[163]]></attendee_id><normalized_name><![CDATA[C. Arenas Sola]]></normalized_name><name><![CDATA[Concepcion]]></name><lastname><![CDATA[Arenas Sola]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[226]]></id><title><![CDATA[Estimación de modelos de regresión semi-paramétricos  con datos de tiempos de vida]]></title><text><![CDATA[En este trabajo consideramos el problema de estimación de los parámetros de un modelo de tiempo de vida acelerada sin asumir una distribución específica para la población base. A partir de información muestral incompleta, construimos un estimador de mínimos cuadrados ponderados para el vector de coeficientes de regresión y usamos un método Jackknife para estimar los errores estándar de estos estimadores. Comparamos las estimaciones obtenidas por este método con distintas versiones paramétricas del modelo con el fin de valorar el compromiso entre la flexibilidad del modelo inherente en los métodos semi-paramétricos y la eficiencia de la estimación que proporcionan los métodos paramétricos. Para evaluar el comportamiento de este procedimiento consideramos dos conjuntos de datos reales: una muestra de tiempos de rotura de tuberías de una red de suministro de agua; y una muestra de datos de cáncer.]]></text><keywords><![CDATA[modelo de tiempo de vida  acelerada , censura, truncamiento]]></keywords><authors><element><attendee_id><![CDATA[145]]></attendee_id><normalized_name><![CDATA[A. J. López Montoya]]></normalized_name><name><![CDATA[Antonio Jesús]]></name><lastname><![CDATA[López Montoya]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[448]]></attendee_id><normalized_name><![CDATA[M. L. Gámiz Pérez]]></normalized_name><name><![CDATA[M. Luz]]></name><lastname><![CDATA[Gámiz Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[439]]></attendee_id><normalized_name><![CDATA[M. D. Martínez Miranda]]></normalized_name><name><![CDATA[M. Dolores]]></name><lastname><![CDATA[Martínez Miranda]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[55]]></id><title><![CDATA[Bandas de confianza en un Q-Q plot normal]]></title><text><![CDATA[Los Q-Q Plots se utilizan como técnicas gráficas de bondad de ajuste. Estas técnicas son más intuitivas y fácilmente interpretables frente a las técnicas analíticas. El Q-Q Plot Normal se utiliza para determinar si un conjunto de observaciones muestrales proceden de una distribución normal; se representan los cuantiles empíricos (observaciones ordenadas) frente a los cuantiles teóricos (los de la distribución normal). Si los datos proceden de una distribución normal, los puntos representados adoptarán una configuración aproximadamente rectilínea. Sin embargo, la conclusión puede verse afectada por la subjetividad del observador. Por ello, estas técnicas se suelen clasificar como “técnicas informales”. Para evitar este inconveniente y dar rigor al procedimiento, consiguiendo conclusiones únicas independientes del observador, se introducen las bandas de confianza. Se realiza una revisión de las principales bandas de confianza o regiones de aceptación propuestas por diversos autores.]]></text><keywords><![CDATA[Q-Q Plot, bandas de confianza]]></keywords><authors><element><attendee_id><![CDATA[74]]></attendee_id><normalized_name><![CDATA[E. D. Lozano Aguilera]]></normalized_name><name><![CDATA[Emilio D.]]></name><lastname><![CDATA[Lozano Aguilera]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[147]]></attendee_id><normalized_name><![CDATA[M. D. Estudillo Martínez]]></normalized_name><name><![CDATA[María Dolores]]></name><lastname><![CDATA[Estudillo Martínez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Castillo Gutiérrez]]></normalized_name><name><![CDATA[Sonia]]></name><lastname><![CDATA[Castillo Gutiérrez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[100]]></id><title><![CDATA[Métodos estadísticos implicados en la estimación y modelado de la tasa de incidencia en enfermedades crónicas]]></title><text><![CDATA[La incidencia es una medida usada en el análisis epidemiológico de enfermedades. En enfermedades crónicas se estudian dos aspectos: Incidencia de personas (primer episodio), se estima la probabilidad de sufrir un primer episodio, no condicionada o condicionada y son necesarios modelos basados en análisis de supervivencia (Modelo de Cox de riesgos proporcionales, univariantes o multivariantes). Incidencia de episodios, cada paciente puede manifestar un numero diferente de episodios a lo largo del tiempo, hay que estimar la probabilidad de que un individuo que está libre de episodio pueda desarrollarlo en un periodo corto de tiempo y hay diferentes enfoques de analisis, desde simples estimaciones a complejos modelos de regresión de Poisson. La aplicación a diferentes cohortes de pacientes, permiten obtener indicadores de incidencia (Riesgo Relativo, Riesgo atribuíble, Fracción etiológica de riesgo) que apoyan la toma de decisiones en Salud Pública.]]></text><keywords><![CDATA[regresion Poisson, incidencia, riesgo relativo]]></keywords><authors><element><attendee_id><![CDATA[249]]></attendee_id><normalized_name><![CDATA[R. Madero Jarabo]]></normalized_name><name><![CDATA[Rosario]]></name><lastname><![CDATA[Madero Jarabo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[263]]></attendee_id><normalized_name><![CDATA[E. Pérez Fernández]]></normalized_name><name><![CDATA[Elia]]></name><lastname><![CDATA[Pérez Fernández]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Diez Sebastian]]></normalized_name><name><![CDATA[Jesús]]></name><lastname><![CDATA[Diez Sebastian]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[280]]></id><title><![CDATA[Un modelo espacio-temporal para la propagación de enfermedades infecciosas]]></title><text><![CDATA[En este trabajo se considera un modelo de interacción espacio-temporal para la propagación de enfermedades de tipo infeccioso que permite tener en cuenta diversas fuentes de incertidumbre y generaliza el modelo frecuentemente utilizado de susceptibilidad-infección-recuperación (SIR) puramente temporal. En particular, se analiza e ilustra mediante simulación el efecto de factores tales como las razones de contagio y recuperación, así como posibles movimientos migratorios, sobre la dinámica de las proporciones de la población susceptible, infectada e inmune. Para ello, se utiliza un enfoque basado en datos composicionales considerando la geometría específica del espacio soporte. Este trabajo ha sido financiado por los proyectos MTM2009-1350 de la SGPI, Ministerio de Ciencia e Innovación, y P08-FQM-03834 de la CICYE, Junta de Andalucía.]]></text><keywords><![CDATA[datos composicionales, interacción espacio-temporal, modelo SIR]]></keywords><authors><element><attendee_id><![CDATA[316]]></attendee_id><normalized_name><![CDATA[A. E. Madrid García]]></normalized_name><name><![CDATA[Ana Esther]]></name><lastname><![CDATA[Madrid García]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[68]]></attendee_id><normalized_name><![CDATA[J. M. Angulo Ibáñez]]></normalized_name><name><![CDATA[José Miguel]]></name><lastname><![CDATA[Angulo Ibáñez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[259]]></id><title><![CDATA[Estrategias para la incorporación de información a priori a través de Double Chain Ladder]]></title><text><![CDATA[Consideramos el problema de predicción de provisiones IBNR y RBNS y ofrecemos soluciones coherentes y aplicables en práctica, respondiendo a urgencia de las aseguradoras ante los dictados de Solvencia 2. Nuestro punto de partida es el método denominado double chain ladder, que permite descubrir cuál es el micro-modelo que subyace en el popular método chain ladder. Se modelizan datos recogidos en dos triángulos de siniestralidad: número de reclamaciones y cuantías pagadas. Ambos triángulos están ligados a través de una función que define el retraso que sufre cada reclamación desde su registro hasta su liquidación. Chain ladder asume que dicho retraso no depende del año de registro ni de resolución y además, que los pagos individuales sólo dependen del año de registro. Conservando la simplicidad, intuición y practicabilidad que han popularizado chain ladder, investigamos cómo se pueden relajar estas hipótesis, incoporando información a priori a través del modelo double chain ladder.]]></text><keywords><![CDATA[double chain ladder, prior knowledge, inflation, claims reserves, reserve risk]]></keywords><authors><element><attendee_id><![CDATA[439]]></attendee_id><normalized_name><![CDATA[M. D. Martínez Miranda]]></normalized_name><name><![CDATA[M. Dolores]]></name><lastname><![CDATA[Martínez Miranda]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. P. Nielsen]]></normalized_name><name><![CDATA[Jens Perch]]></name><lastname><![CDATA[Nielsen]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Verrall]]></normalized_name><name><![CDATA[Richard]]></name><lastname><![CDATA[Verrall]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Wüethrich]]></normalized_name><name><![CDATA[Mario]]></name><lastname><![CDATA[Wüethrich]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[118]]></id><title><![CDATA[Evaluación de la actividad de grupos mediante el análisis de trazas]]></title><text><![CDATA[En los últimos años hemos desarrollado una metodología que permite recopilar de forma pormenorizada la actividad de los alumnos cuando resuelven ejercicios de aprendizaje asistidos por ordenador. La exhaustiva monitorización del alumno mediante la aplicación Statmedia queda recogida en un listado que incluye todas sus posibles interacciones con el software y sus respuestas enviadas al servidor. Este listado de trazas es generado por nuestro software de forma transparente para el estudiante. El seguimiento se realiza en una o en varias sesiones, según cómo cada usuario decida resolver la actividad propuesta. En ediciones anteriores del congreso hemos presentado la utilidad de los informes automáticos que procesan las trazas y proporcionan información a nivel individual. Actualmente estamos desarrollando con R la tecnología necesaria para obtener información útil del comportamiento a nivel de grupo. En este sentido, presentaremos las conclusiones más relevantes obtenidas hasta ahora.]]></text><keywords><![CDATA[trazas, evaluación, Internet]]></keywords><authors><element><attendee_id><![CDATA[175]]></attendee_id><normalized_name><![CDATA[A. Miñarro Alonso]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Miñarro Alonso]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[178]]></attendee_id><normalized_name><![CDATA[M. Calvo Llorca]]></normalized_name><name><![CDATA[Miguel]]></name><lastname><![CDATA[Calvo Llorca]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Rodriguez Formisano]]></normalized_name><name><![CDATA[Emer ]]></name><lastname><![CDATA[Rodriguez Formisano]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Carnicer González]]></normalized_name><name><![CDATA[Artur]]></name><lastname><![CDATA[Carnicer González]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Cuadros Margarit]]></normalized_name><name><![CDATA[Jordi]]></name><lastname><![CDATA[Cuadros Margarit]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[326]]></id><title><![CDATA[Modelling the hemodynamic response in functional magnetic resonance imaging using Gaussian processes ]]></title><text><![CDATA[During the last few decades our knowledge of the human brain has developed significantly as a result of new neuroimaging techniques, such as functional magnetic resonance imaging (fMRI). By observing the relation between a stimulus paradigm and the changes in blood oxygenation in the brain, the so-called hemodynamic response function (HRF), fMRI provides a measure of brain activation. Modeling the HRF in fMRI experiments is therefore an important aspect of the analysis of data in functional neuroimaging. This has been done in the past using parametric response functions, typically Poisson, gamma or Gaussian densities. In this work, we consider the case in which the HRF is simply defined by an unknown function z(.). General Gaussian Processes theory presents an attractive way of expressing prior beliefs about the function z(.) and we show how, in this context, a combination of analytical methods may be used for making inference about the posterior predictive distribution of interest.]]></text><keywords><![CDATA[fMRI, Gaussian processes]]></keywords><authors><element><attendee_id><![CDATA[485]]></attendee_id><normalized_name><![CDATA[R. Montes Diez]]></normalized_name><name><![CDATA[Raquel]]></name><lastname><![CDATA[Montes Diez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Quirós]]></normalized_name><name><![CDATA[Alicia]]></name><lastname><![CDATA[Quirós]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[99]]></id><title><![CDATA[Un modelo Bayesiano de regresión binaria con función de enlace potencial-exponencial asimétrica]]></title><text><![CDATA[Los modelos lineales generalizados permiten describir la dependencia de datos sobre variables explicativas cuando la variable respuesta es binaria. La elección de la liga es un tema importante. Las más usadas son las inversas de la cdf logística y normal. Ambas ligas son simétricas, por lo que el ajuste de un modelo puede ser mejorado mediante ligas asimétricas. La proporción de cambio en la cual la probabilidad de que una respuesta binaria dada se aproxime a 1 o 0 ayuda para describir la liga. En este trabajo se presenta un modelo Bayesiano de regresión binaria que utiliza como liga a la  inversa de la cdf de la distribución potencial-exponencial asimétrica. Esta familia de distribuciones incluye como caso particular a la distribución potencial-exponencial simétrica y, además, incorpora distribuciones con formas platicúrticas y/o leptocúrticas.  La introducción de variables latentes y el uso de una representación de mixturas permiten desarrollar algoritmos de Gibbs eficientes.]]></text><keywords><![CDATA[datos binarios, distribución potencial-exponencial asimétrica, regresión  bayesiana, modelos lineales generalizados]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. Naranjo]]></normalized_name><name><![CDATA[Lizbeth]]></name><lastname><![CDATA[Naranjo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[198]]></attendee_id><normalized_name><![CDATA[C. J. Pérez Sánchez]]></normalized_name><name><![CDATA[Carlos Javier]]></name><lastname><![CDATA[Pérez Sánchez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[325]]></id><title><![CDATA[Una técnica de predicción AL para series temporales complejas]]></title><text><![CDATA[En el presente trabajo se propone una técnica de predicción de pasado infinito para los modelos de función de transferencia en el campo complejo. La metodología propuesta se basa en un procesamiento ampliamente lineal (AL), que se caracteriza por aprovechar la información disponible de la señal y su conjugada. En base a esta metodología, se define un sistema de transferencia AL y se diseña un algoritmo recursivo para el cálculo de un predictor subóptimo que converge al óptimo cuando el tamaño de la serie crece indefinidamente. Desde el punto de vista práctico, esta solución es especialmente útil en aquellas situaciones en las que se disponen de un elevado número de observaciones.]]></text><keywords><![CDATA[señal aleatoria compleja, procesamiento ampliamente lineal, función de transferencia]]></keywords><authors><element><attendee_id><![CDATA[500]]></attendee_id><normalized_name><![CDATA[J. Navarro Moreno]]></normalized_name><name><![CDATA[Jesús]]></name><lastname><![CDATA[Navarro Moreno]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[499]]></attendee_id><normalized_name><![CDATA[R. M. Fernández Alcalá]]></normalized_name><name><![CDATA[Rosa María]]></name><lastname><![CDATA[Fernández Alcalá]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. C. Ruiz Molina]]></normalized_name><name><![CDATA[Juan Carlos]]></name><lastname><![CDATA[Ruiz Molina]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[247]]></id><title><![CDATA[Muestreo del parque de contadores de agua de A Coruña para la determinación de su vida útil]]></title><text><![CDATA[El objetivo de este trabajo es presentar los resultados y metodología empleada en el estudio del parque de contadores de agua en la ciudad de A Coruña. El trabajo se centra en proponer un método de muestreo para determinar cuántos de ellos, según su calibre, caudal y antigüedad, es necesario examinar por su posterior estudio metrológico. Para ello se propone una media del error porcentual de medición de ese tipo de contadores con objeto de calcular el tamaño muestral mediante la estimación de la varianza de dicho error en cada uno de los escenarios de calibre, caudal y antigüedad. Posteriormente, en base a los contadores muestreados, se realiza un estudio estadístico que permite dar información a la empresa sobre la sustitución de los contadores (vida útil) y sobre la selección de los mejores proveedores.]]></text><keywords><![CDATA[muestreo, vida útil, metrología]]></keywords><authors><element><attendee_id><![CDATA[415]]></attendee_id><normalized_name><![CDATA[S. Naya Fernández]]></normalized_name><name><![CDATA[Salvador]]></name><lastname><![CDATA[Naya Fernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[144]]></attendee_id><normalized_name><![CDATA[R. Cao Abad]]></normalized_name><name><![CDATA[Ricardo]]></name><lastname><![CDATA[Cao Abad]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Francisco Fernández]]></normalized_name><name><![CDATA[Mario]]></name><lastname><![CDATA[Francisco Fernández]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[416]]></attendee_id><normalized_name><![CDATA[J. Tarrío Saavedra]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Tarrío Saavedra]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[18]]></id><title><![CDATA[Estimación de la razón poblacional en la ocasión actual cuando hay no respuesta]]></title><text><![CDATA[En este trabajo, estudiamos el problema de la estimación de la razón de medias bajo un diseño de muestreo sucesivo en dos ocasiones, cuando hay no-respuesta en ambas ocasiones, cuando hay no-respuesta sólo en la primera ocasión y cuando hay no-respuesta sólo en la segunda ocasión. Obtenemos el porcentaje de pérdida en precisión de estos estimadores sobre el estimador de la razón de medias cuando no hay no-respuesta. Además se calculan los tamaños muestrales y los correspondientes costes esperados para los estimadores propuestos, considerando que éstos tienen igual precisión que el estimador de la razón de medias cuando no hay no-respuesta. Para finalizar, los resultados obtenidos se demuestran con la ayuda de un estudio empírico, donde se observa que en la mayoría de los casos el porcentaje de pérdida en precisión es mayor para el estimador de la razón de medias con no-respuesta en la segunda ocasión, mientras que es menor para el que tiene no-respuesta sólo en la primera ocasión.]]></text><keywords><![CDATA[muestreo sucesivo, no-respuesta, estimador de la razón]]></keywords><authors><element><attendee_id><![CDATA[555]]></attendee_id><normalized_name><![CDATA[I. Oña Casado]]></normalized_name><name><![CDATA[Inmaculada]]></name><lastname><![CDATA[Oña Casado]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[273]]></id><title><![CDATA[Diseños óptimos maximin para modelos exponenciales]]></title><text><![CDATA[En este trabajo se estudian los diseños A-óptimos para varios modelos de decrecimiento exponencial. Estos modelos son muy usados en química, farmacocinética y microbiología. Consideramos un criterio de optimalidad maximin que se basa en determinar el diseño óptimo que maximiza la mínima eficiencia. Para ello primero calculamos los diseños óptimos locales. En el caso de que los diseños óptimos maximin estén soportados en un número mínimo de puntos de diseño, derivamos sus soluciones analíticas. En otros casos se determinan los diseños numéricamente a partir de un software programado en Gauss. El trabajo se completa con un estudio de comparación de los diseños A- y D-óptimos, tanto locales como maximin.]]></text><keywords><![CDATA[diseños, criterio, maximin]]></keywords><authors><element><attendee_id><![CDATA[303]]></attendee_id><normalized_name><![CDATA[I. M. Ortiz Rodríguez]]></normalized_name><name><![CDATA[Isabel María]]></name><lastname><![CDATA[Ortiz Rodríguez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[525]]></attendee_id><normalized_name><![CDATA[C. Rodríguez Torreblanca]]></normalized_name><name><![CDATA[Carmelo]]></name><lastname><![CDATA[Rodríguez Torreblanca]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[I. Martínez López]]></normalized_name><name><![CDATA[Ignacio]]></name><lastname><![CDATA[Martínez López]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[76]]></id><title><![CDATA[Metodología estadística aplicada para el estudio de datos correlacionados en investigación biomédica]]></title><text><![CDATA[En la investigación biomédica son frecuentes los estudios en los que la variable respuesta tiene varias observaciones para el mismo sujeto y no se puede suponer independencia entre estas observaciones. Es el caso de los estudios de crecimiento, en los que un sujeto se evalúa a diferentes edades, o de los estudios de curva dosis-respuesta, donde se evalúa la respuesta del sujeto para diferentes dosis del fármaco.También es frecuente encontrarse con datos no balanceados, en presencia de datos perdidos para la variable dependiente. En estos casos, se tiene que recurrir a modelos más complejos que incluyen el Análisis de la Varianza de Medidas Repetidas, los Modelos Mixtos o los Modelos Lineales Generalizados. Estos modelos permiten modelar relaciones no lineales, incluir efectos fijos y efectos aleatorios y usar distintas estructuras de la covarianza. El objetivo de este trabajo es describir la metodología estadística aplicada en distintos estudios con datos reales de esta naturaleza.]]></text><keywords><![CDATA[modelos lineales mixtos, modelos lineales mixtos generalizados]]></keywords><authors><element><attendee_id><![CDATA[263]]></attendee_id><normalized_name><![CDATA[E. Pérez Fernández]]></normalized_name><name><![CDATA[Elia]]></name><lastname><![CDATA[Pérez Fernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[249]]></attendee_id><normalized_name><![CDATA[R. Madero Jarabo]]></normalized_name><name><![CDATA[Rosario]]></name><lastname><![CDATA[Madero Jarabo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Díez Sebastián]]></normalized_name><name><![CDATA[Jesús]]></name><lastname><![CDATA[Díez Sebastián]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[24]]></id><title><![CDATA[Análisis de supervivencia aplicado al sector financiero cooperativo en entorno de riesgo sistémico]]></title><text><![CDATA[La actual situación económica está teniendo una repercusión muy significativa en el sector financiero que debe de reorientar sus metodologías de control de riesgo. En este contexto se debe analizar la situación actual en la que se encuentran los distintos agentes que operan en éste mercado, estudiar su comportamiento frente a la crisis y detectar oportunidades de negocio con objeto de optimizar la posible reestructuración del sector cooperativo crediticio. Se pretende evaluar, proponiendo un modelo basado en el Análisis de Supervivencia, la influencia de diferentes factores económicos en el análisis de los tiempos de cambio de estado del Sector Financiero Cooperativo en España, prestando especial atención a la estructura corporativa, al balance y a los principales ratios financieros de las entidades que lo componen, con el fin de detectar los efectos del riesgo sistémico en el sector como consecuencia de una posible quiebra. ]]></text><keywords><![CDATA[análisis de supervivencia, riesgo sistémico, stress financiero, cooperativas de crédito]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Pérez Valencia]]></normalized_name><name><![CDATA[Federico]]></name><lastname><![CDATA[Pérez Valencia]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[V. Molina Moreno]]></normalized_name><name><![CDATA[Vicente]]></name><lastname><![CDATA[Molina Moreno]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[Y. Román Montoya]]></normalized_name><name><![CDATA[Yolanda]]></name><lastname><![CDATA[Román Montoya]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[121]]></id><title><![CDATA[Comparaciones basadas en curvas y áreas TIP: aplicación a la evolución de la pobreza en España (2004-2009)]]></title><text><![CDATA[En su contribución a la medición de la pobreza Jenkins y Lambert (1997) definen la curva TIP (Three I’s of Poverty), que sintetiza las tres dimensiones básicas de la pobreza: incidencia, intensidad y desigualdad. La no intersección de dos curvas TIP sirve como criterio para comparar en pobreza de forma unánime dos distribuciones de renta para una amplia clase de índices de pobreza.  Se plantea un problema cuando las curvas de las distribuciones que deseamos comparar se cortan. En Sordo, Ramos y Ramos (2007) y Sordo y Ramos (2011) se proporcionan resultados que permiten ordenar en pobreza distribuciones para las que sus curvas TIP se cruzan. En este trabajo aplicamos los citados resultados a los datos españoles que proporcionan las Encuestas de Condiciones de Vida (ECV) en el período 2004-2009. ]]></text><keywords><![CDATA[curvas TIP, ordenación en pobreza, mominancia de las curvas TIP]]></keywords><authors><element><attendee_id><![CDATA[132]]></attendee_id><normalized_name><![CDATA[C. D. Ramos González]]></normalized_name><name><![CDATA[Carmen D.]]></name><lastname><![CDATA[Ramos González]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[408]]></attendee_id><normalized_name><![CDATA[M. Á. Sordo Díaz]]></normalized_name><name><![CDATA[Miguel Ángel]]></name><lastname><![CDATA[Sordo Díaz]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[35]]></id><title><![CDATA[Estimación de modelos de estructura de medias y covarianzas para datos dicotómicos mediante modelos de teoría de rRespuesta al ítem]]></title><text><![CDATA[Los modelos de estructura de medias y covarianzas ofrecen un marco estadístico que permite analizar simultáneamente el ajuste del modelo estructural y estimar las medias de las variables latentes. Con datos cuantitativos, los análisis se llevan a cabo mediante modelos de ecuaciones estructurales (SEM) mientras que con datos dicotómicos se utilizan los modelos de la Teoría de Respuesta al Ítem (TRI). Los modelos SEM se basan en una relación lineal entre las variables observadas y latentes, mientras que los modelos de TRI asumen una función no lineal y la interpretación de las medias latentes menos directa. Este trabajo resume la formulación de modelos de TRI para analizar la estructura de medias y covarianzas en datos dicotómicos. Se proponen una serie de procedimientos para definir las restricciones del modelo, y se ilustra la implementación del procedimiento con un ejemplo que utiliza datos reales tomados del campo de la psicología del trabajo y las organizaciones.]]></text><keywords><![CDATA[teoría de respuesta al ítem, análisis factorial para datos categóricos, modelos de estructura de medias y covarianzas, psicometría, análisis multivariante]]></keywords><authors><element><attendee_id><![CDATA[216]]></attendee_id><normalized_name><![CDATA[J. Revuelta Menéndez]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Revuelta Menéndez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Ximénez Gómez]]></normalized_name><name><![CDATA[Carmen]]></name><lastname><![CDATA[Ximénez Gómez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[107]]></id><title><![CDATA[Diseños óptimos bayesianos para el modelo logístico con efectos aleatorios]]></title><text><![CDATA[El modelo logístico con todos los efectos aleatorios no ha sido hasta la fecha estudiado en la literatura. En este caso se puede probar que la matriz de  información de Fisher es equivalente a la del modelo linealizado, al igual que ocurre cuando los efectos son fijos. El problema principal es la dependencia de esta matriz de varias integrales, en general, costosas computacionalmente  hablando, para las que se proponen diversas aproximaciones. Además, la matriz depende de los parámetros desconocidos, por lo que habrá que proporcionar unos valores iniciales de los mismos y por tanto los diseños óptimos serán óptimos locales. Como esta dependencia de los parámetros iniciales puede ser muy importante respecto del punto de vista de la eficiencia, en este trabajo se propone el cálculo de diseños óptimos bayesianos,  más robustos respecto de la elección de los valores iniciales aunque lógicamente mucho más costosos de calcular. El procedimiento se ilustra con un adecuado ejemplo.]]></text><keywords><![CDATA[modelo logístico, diseños óptimos bayesianos, efectos aleatorios ]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. M. Rodríguez Díaz]]></normalized_name><name><![CDATA[Juan Manuel ]]></name><lastname><![CDATA[Rodríguez Díaz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[247]]></attendee_id><normalized_name><![CDATA[M. T. Santos Martín]]></normalized_name><name><![CDATA[Mª Teresa]]></name><lastname><![CDATA[Santos Martín]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Tommasi]]></normalized_name><name><![CDATA[Chiara]]></name><lastname><![CDATA[Tommasi]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[54]]></id><title><![CDATA[Detecting structural changes in time series]]></title><text><![CDATA[An alternative procedure to detect structural changes in time series is proposed, which is based on the number of different permutations  that appear in a data series.  The efficacy of the method is shown through simulated data and the influence of the embedding dimension (permutations length) is also pointed out. Some applications to real data are included, such as detecting epileptic seizures from EEG signals or the awake or sleeping state in depth of anesthesia.]]></text><keywords><![CDATA[time series, permutations, structural changes]]></keywords><authors><element><attendee_id><![CDATA[139]]></attendee_id><normalized_name><![CDATA[M. D. C. Ruiz Abellón]]></normalized_name><name><![CDATA[María del Carmen]]></name><lastname><![CDATA[Ruiz Abellón]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[238]]></attendee_id><normalized_name><![CDATA[A. Guillamón Frutos]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Guillamón Frutos]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. S. Cánovas Peña]]></normalized_name><name><![CDATA[José S.]]></name><lastname><![CDATA[Cánovas Peña]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[151]]></id><title><![CDATA[An exploratory data analysis to validate an analytical orbit propagator program]]></title><text><![CDATA[A scalable second-order analytical orbit propagator program (AOPP) is being carried out. This AOPP combines modern and classical perturbation methods in function of orbit types or the requirements needed for a space mission, such as catalog maintenance operations, long period evolution, and so on. In this work, we present part of  our AOPP and its validation. It implements a second order closed-form zonal  analytical theory, in the cases of J2-J4 and J2-J12, which  integrates the problem using the classical Delaunay Normalization and the Krylov-Bogoliubov-Mitropolsky method. A methodology based on an exploratory data analysis (EDA) is proposed in order to validate both integration methods and determine the values of the initial conditions, where these methods are valid in function of the duration of propagation.]]></text><keywords><![CDATA[exploratory data analysis, analytical orbit propagator]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. F. San Juan Díaz]]></normalized_name><name><![CDATA[Juan Félix]]></name><lastname><![CDATA[San Juan Díaz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[324]]></attendee_id><normalized_name><![CDATA[D. Ortigosa Martínez]]></normalized_name><name><![CDATA[David]]></name><lastname><![CDATA[Ortigosa Martínez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. M. López Ochoa]]></normalized_name><name><![CDATA[Luis María]]></name><lastname><![CDATA[López Ochoa]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Lara Coira]]></normalized_name><name><![CDATA[Martín]]></name><lastname><![CDATA[Lara Coira]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[148]]></id><title><![CDATA[Propagadores de órbitas híbridos basados en métodos de suavizado exponencial]]></title><text><![CDATA[Un propagador de órbitas analítico (AOPP) es una aplicación informática que reúne y organiza las expresiones matemáticas asociadas a una solución analítica de las ecuaciones del movimiento de un satélite artificial. En determinadas etapas del análisis y diseño de misiones espaciales es necesario considerar modelos de fuerzas de perturbación más completos con el fin de mejorar las prestaciones del AOPP. En estos casos, las soluciones analíticas dejan de ser eficientes debido al incremento del número de términos de la solución. En este trabajo se presenta una nueva metodología, que llamaremos Teoría Híbrida de perturbaciones, que combina la eficacia de un propagador analítico simplificado con métodos de suavizado exponencial. Con esta combinación se podrán modelizar las fuerzas de perturbación no consideradas en el teoría analítica y obtener precisiones sólo alcanzables con modelos más complejos y de mayor orden. Todo ello sin pérdida de eficiencia computacional.]]></text><keywords><![CDATA[suavizado exponencial, propagadores de órbitas híbridos]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. F. San Juan Díaz]]></normalized_name><name><![CDATA[Juan Félix]]></name><lastname><![CDATA[San Juan Díaz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[267]]></attendee_id><normalized_name><![CDATA[M. San Martín Pérez]]></normalized_name><name><![CDATA[Montserrat]]></name><lastname><![CDATA[San Martín Pérez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[I. Pérez Barrón]]></normalized_name><name><![CDATA[Iván]]></name><lastname><![CDATA[Pérez Barrón]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[66]]></id><title><![CDATA[Stochastic comparison of composite indices: The case of human development index]]></title><text><![CDATA[A new methodology for stochastic comparison of composite indices is proposed. The stochastic component of the index is introduced in the weights vector using a Dirichlet distribution. The exact probability distribution of the index is obtained. Several probabilistic properties of the stochastic indices are obtained, including raw moments, which can be written in terms of the confluent and Lauricella functions. A method for the elicitation of the parameters of the Dirichlet distribution is proposed. The stochastic composite indices can be easily estimated by simulation. A matrix of pairwise probabilistic comparisons between countries is defined and several stochastic orderings are proposed and compared. The new methodology is used to construct a stochastic version of the Human Development Index (HDI). The method is illustrated with data of the OECD countries for 2010. The new stochastic orderings are consistent with the ranking established by PNUD to classify the OECD countries by HDI.]]></text><keywords><![CDATA[composite index, stochastic comparisons, Dirichlet distribution, human development index]]></keywords><authors><element><attendee_id><![CDATA[121]]></attendee_id><normalized_name><![CDATA[J. M. Sarabia Alegría]]></normalized_name><name><![CDATA[José María]]></name><lastname><![CDATA[Sarabia Alegría]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[340]]></attendee_id><normalized_name><![CDATA[F. J. Girón]]></normalized_name><name><![CDATA[Francisco Javier]]></name><lastname><![CDATA[Girón]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[130]]></id><title><![CDATA[Estimación de parámetros de instalaciones portuarias mediante redes bayesianas]]></title><text><![CDATA[La planificación y gestión de las terminales portuarias tradicionalmente se realiza empleando ratios de gestión y explotación  de la bibliografía internacional, y no con ratios determinados expresamente, lo que hace difícil planificar y gestionar las terminales de contendedores españolas. Se pretende mostrar la aplicación de las redes bayesianas para el caso portuario continuando una linea de investigación abierta en el Departamento de Ingeniería Civil. Transportes de la UPM. Las redes bayesianas representan una distribución de probabilidad multivariante de las variables físicas de la terminal y, asociada a cada nodo de la red hay una distribución de probabilidad condicionada a los padres de cada nodo, de manera que la distribución conjunta factoriza como el producto de las distribuciones condicionadas asociadas a los nodos de la red. Dada la red obtenida se confirma que la superficie total de la terminal (área en que opera la terminal) se puede elegir como elemento de planificación.]]></text><keywords><![CDATA[redes bayesianas, planificación, ingeniería portuaria, análisis de datos]]></keywords><authors><element><attendee_id><![CDATA[75]]></attendee_id><normalized_name><![CDATA[F. Soler Flores]]></normalized_name><name><![CDATA[Francisco ]]></name><lastname><![CDATA[Soler Flores]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Camarero Orive]]></normalized_name><name><![CDATA[Alberto]]></name><lastname><![CDATA[Camarero Orive]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[N. González Cancelas]]></normalized_name><name><![CDATA[Nicoletta ]]></name><lastname><![CDATA[González Cancelas]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Domínguez Guijarro]]></normalized_name><name><![CDATA[Eduardo]]></name><lastname><![CDATA[Domínguez Guijarro]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[253]]></id><title><![CDATA[Clasificación supervisada de especies de madera industriales]]></title><text><![CDATA[El objetivo de este estudio es la clasificación de especies de madera de interés comercial e industrial: roble, castaño, haya, nogal, pino rojo y silvestre, eucalipto y jatobá. Se pretende maximizar el ratio de acierto y disminuir los costes de esta actividad. La identificación de especies se efectúa usando las curvas de degradación termooxidativa obtenidas mediante la Calorimetría Diferencial de Barrido a altas presiones (PDSC) y las micrografías a 1500x aumentos que proporciona la Microscopía Electrónica de Barrido (SEM). Se han propuesto dos métodos para la extracción de características representativas. En el caso de las curvas PDSC, se han utilizado los parámetros de ajuste de un modelo no lineal. Por otro lado, a partir de las micrografías segmentadas, se han extraído 5 características relacionadas con la estructura de las traqueidas. Se han aplicado métodos de clasificación multivariante y aprendizaje máquina, validados mediante validación cruzada.]]></text><keywords><![CDATA[clasificación multivariante, madera, segmentación de imágenes, análisis térmico]]></keywords><authors><element><attendee_id><![CDATA[416]]></attendee_id><normalized_name><![CDATA[J. Tarrío Saavedra]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Tarrío Saavedra]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[415]]></attendee_id><normalized_name><![CDATA[S. Naya Fernández]]></normalized_name><name><![CDATA[Salvador]]></name><lastname><![CDATA[Naya Fernández]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Francisco Fernandez]]></normalized_name><name><![CDATA[mario]]></name><lastname><![CDATA[Francisco Fernandez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. López-Beceiro]]></normalized_name><name><![CDATA[Jorge]]></name><lastname><![CDATA[López-Beceiro]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[T. Sebio  Puñal]]></normalized_name><name><![CDATA[Teresa]]></name><lastname><![CDATA[Sebio  Puñal]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Artiaga]]></normalized_name><name><![CDATA[Ramón]]></name><lastname><![CDATA[Artiaga]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[108]]></id><title><![CDATA[Influencia de la terapia hormonal sustitutoria en la densidad mineral ósea]]></title><text><![CDATA[La THS se considera un tratamiento efectivo para aliviar los problemas asociados con la deficiencia de estrógenos y sus secuelas,como la disminución de la DMO. El propósito de este trabajo es analizar el estado y los cambios en la DMO en una muestra de 185 pacientes tratadas con THS.La evaluación de la DMO plantea problemas ya que los valores normales de este índice varían con la edad. Por ello se proponen dos métodos de evaluación cuyo punto de partida son las curvas normales para la DMO publicadas en 1997 en Osteoporosis Internacional. El primer método evalúa la diferencia entre valores observados de la DMO y valores medios normales según edad. El segundo método está basado en el valor que presentaba la paciente al inicio del tratamiento y en la evolución normal según su grupo de edad y el número de años de THS. Para el cálculo de estos índices se emplean técnicas de interpolación lineal. Además mediante  un diseño de medidas repetidas se analiza la evolución de las pacientes, tratadas durante un período de al menos nueve años. En todos los casos, la THS presenta resultados positivos.]]></text><keywords><![CDATA[terapia hormonal sustitutoria, densidad mineral ósea, medidas repetidas]]></keywords><authors><element><attendee_id><![CDATA[256]]></attendee_id><normalized_name><![CDATA[M. L. Vicente Hernanz]]></normalized_name><name><![CDATA[Mª Lina]]></name><lastname><![CDATA[Vicente Hernanz]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[255]]></attendee_id><normalized_name><![CDATA[R. Cintas del Río]]></normalized_name><name><![CDATA[Rosario]]></name><lastname><![CDATA[Cintas del Río]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[482]]></attendee_id><normalized_name><![CDATA[J. L. Brita-Paja Segoviano]]></normalized_name><name><![CDATA[Jose Luis]]></name><lastname><![CDATA[Brita-Paja Segoviano]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[288]]></id><title><![CDATA[Gráfico $T^2$ de Hotelling para datos composicionales]]></title><text><![CDATA[Uno de los gráficos de control multivariante más conocidos y utilizados es el gráfico $T^2$ de Hotelling. Este gráfico consiste en la monitorización de la distancia de Mahalanobis entre las observaciones y el centro de su distribución. Cuando los datos a controlar son vectores composicionales, es decir, de suma constante, dicha distancia no se puede calcular debido a la singularidad de la matriz de covarianzas. En el presente estudio se propone un enfoque basado en la metodología log-cociente que consiste en aplicar la metodología clásica a las coordenadas respecto una base ortonormal. De esta manera se consigue trabajar con valores en el espacio real a la vez que se reduce la dimensionalidad. A partir de conjuntos de datos reales se dan orientaciones para la interpretación de las observaciones identificadas como fuera de control.]]></text><keywords><![CDATA[T^2 Hotelling, control multivariante, datos composicionales, log-cociente]]></keywords><authors><element><attendee_id><![CDATA[455]]></attendee_id><normalized_name><![CDATA[M. Vives-Mestres]]></normalized_name><name><![CDATA[Marina]]></name><lastname><![CDATA[Vives-Mestres]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[278]]></attendee_id><normalized_name><![CDATA[J. Daunis-i-Estadella]]></normalized_name><name><![CDATA[Josep]]></name><lastname><![CDATA[Daunis-i-Estadella]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[246]]></attendee_id><normalized_name><![CDATA[J. A. Martín Fernández]]></normalized_name><name><![CDATA[Josep Antoni]]></name><lastname><![CDATA[Martín Fernández]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[181]]></id><title><![CDATA[Análisis bayesiano de un modelo de suavizado exponencial con datos censurados]]></title><text><![CDATA[En este trabajo desarrollamos un procedimiento de predicción, basado en los modelos de suavizado exponencial, para el análisis de series temporales de demanda no negativas con una proporción de valores nulos y una gran variabilidad entre los valores observados mayores que cero. Proponemos analizar los datos como si existiera una demanda latente irrestringida subyacente a la demanda observada; valores observados nulos se corresponderían con valores de la demanda latente menores o iguales a cero. Predicciones precisas para la demanda observada pueden ser derivadas a partir de las obtenidas para la demanda latente mediante suavizado exponencial. El análisis Bayesiano de los modelos de suavizado exponencial, formulados como modelos lineales, simplifica considerablemente el análisis de datos censurados. El funcionamiento del procedimiento propuesto es ilustrado mediante series reales de venta de libros.]]></text><keywords><![CDATA[series temporales de demanda, demanda nula, predicción bayesiana, suavizado exponencial, datos censurados  ]]></keywords><authors><element><attendee_id><![CDATA[354]]></attendee_id><normalized_name><![CDATA[E. Vercher González]]></normalized_name><name><![CDATA[Enriqueta]]></name><lastname><![CDATA[Vercher González]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. D. Bermúdez Edo]]></normalized_name><name><![CDATA[José D.]]></name><lastname><![CDATA[Bermúdez Edo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[327]]></attendee_id><normalized_name><![CDATA[A. Corberán Vallet]]></normalized_name><name><![CDATA[Ana]]></name><lastname><![CDATA[Corberán Vallet]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[283]]></id><title><![CDATA[Bivariate density approximation using random Bernstein polynomials]]></title><text><![CDATA[We examine the properties of bivariate random Berstein polynomials for  density estimation on the unit square. In particular, we use a Bernstein-Dirichlet prior for the class of Bernstein densities. We study the convergence rate of the posterior distribution of a bivariate Bernstein polynomial model under very general conditions. We also demonstrate that when the true data generating distribution is Bernstein, we obtain a nearly parametric convergence rate. Finally, we illustrate the practical application of bivariate Bayesian Bernstein polynomial based approximations with various simulated and real data examples.]]></text><keywords><![CDATA[Bernstein polynomials, bayesian nonparametrics, bivariate density estimation]]></keywords><authors><element><attendee_id><![CDATA[461]]></attendee_id><normalized_name><![CDATA[Y. Zhao]]></normalized_name><name><![CDATA[Yanyun]]></name><lastname><![CDATA[Zhao]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Wiper]]></normalized_name><name><![CDATA[Michael]]></name><lastname><![CDATA[Wiper]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[526]]></attendee_id><normalized_name><![CDATA[C. Ausin]]></normalized_name><name><![CDATA[Concepcion]]></name><lastname><![CDATA[Ausin]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[131]]></id><identifier><![CDATA[XC1b]]></identifier><name><![CDATA[Pósters (Estadística Pública)]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[266]]></id><normalized_name><![CDATA[J. Cano Cancela]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Cano Cancela]]></lastname></chairperson><papers><element><id><![CDATA[243]]></id><title><![CDATA[Diseño metodológico para el análisis estadístico de la Prueba de Acceso a la Universidad]]></title><text><![CDATA[En esta comunicación se presenta la elaboración a través del software estadístico R de una serie de informes automatizados referentes a las Pruebas de Acceso a la Universidad llevadas a cabo en el Principado de Asturias durante el año 2011. En este trabajo se evaluaron los resultados obtenidos por el alumnado, tanto en la fase general como en la fase específica de la prueba, así como desagregados según la convocatoria concreta. Se realizaron concretamente tres tipos de informes, uno de carácter general destinado a la Comisión Organizadora de las pruebas, otro de carácter individualizado para cada uno de los centros docentes asturianos y por último, un informe relativo a cada asignatura. Se evaluaron las variaciones obtenidas en la comparación de las calificaciones que el alumnado obtuvo en los estudios de Bachillerato con las conseguidas durante la prueba, y se indicaron los centros y  asignaturas con diferencias estadísticamente significativas.]]></text><keywords><![CDATA[análisis estadístico, R]]></keywords><authors><element><attendee_id><![CDATA[434]]></attendee_id><normalized_name><![CDATA[T. Iglesias Cabo]]></normalized_name><name><![CDATA[Tania]]></name><lastname><![CDATA[Iglesias Cabo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[P. Díaz Díaz]]></normalized_name><name><![CDATA[Patricia]]></name><lastname><![CDATA[Díaz Díaz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Torres Manzanera]]></normalized_name><name><![CDATA[Emilio]]></name><lastname><![CDATA[Torres Manzanera]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[133]]></id><title><![CDATA[Bondad económica y crisis financiera: efectos sobre la población inmigrante en las ciudades autónomas y en el conjunto del territorio español.]]></title><text><![CDATA[En este trabajo se analizan las causas y consecuencias que las leyes de extranjería y el comienzo de crisis económica y financiera, han tenido sobre el fenómeno de la inmigración. Entre 2000 y 2010, período analizado, España ha sido un territorio de alta atracción migratoria, aumentando del 2\% al 10,5\% los extranjeros respecto de la población total española. El aumento de la población extranjera en este periodo ha sido más elevado en España y Andalucía que en Melilla y Ceuta, aunque a partir de 2008, con el comienzo de la crisis financiera, el crecimiento de la población extranjera en Melilla ha sido de un 56\% frente al 29\% de la media nacional. Dicha crisis provoca, además de un incremento de la economía sumergida, un aumento del desempleo en la población de inmigrantes que en ocasiones, han regresado a sus países de origen, sin dejar de estar censados en el territorio español para continuar recibiendo subsidios o prestaciones económicas a las que tienen derecho.]]></text><keywords><![CDATA[inmigración, crisis económica, ley de extranjería]]></keywords><authors><element><attendee_id><![CDATA[76]]></attendee_id><normalized_name><![CDATA[J. A. Marmolejo Martín]]></normalized_name><name><![CDATA[Juan Antonio]]></name><lastname><![CDATA[Marmolejo Martín]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. D. Huete Morales]]></normalized_name><name><![CDATA[María Dolores]]></name><lastname><![CDATA[Huete Morales]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Á. Pérez Castro]]></normalized_name><name><![CDATA[Miguel Ángel ]]></name><lastname><![CDATA[Pérez Castro]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[149]]></id><title><![CDATA[Bootstrap procedures in time-correlated area-level linear mixed models]]></title><text><![CDATA[We consider models for normal random variables at  the area level, by considering different types of temporal correlations. 
The temporal correlation is introduced by means of time-specific random effects whose distributions might be AR(1), MA(1) or ARMA(1,1). We propose algorithms to fit the models and estimate its parameters; for example, by using the Fisher-scoring algorithm to obtain residual maximum likelihood (REML) estimates. We obtain EBLUPs  of linear parameters. We obtain explicit estimators of mean squared error studying the order of efficiency. We introduce bootstrap resampling methods to estimate mean squared errors of EBLUPs. We study the consistency of the proposed methods. Finally, we carry out simulation experiment to study the behavior of the bootstrap procedures under controlled situations.]]></text><keywords><![CDATA[small area estimation, linear mixed models, bootstrap]]></keywords><authors><element><attendee_id><![CDATA[159]]></attendee_id><normalized_name><![CDATA[D. Morales González]]></normalized_name><name><![CDATA[Domingo]]></name><lastname><![CDATA[Morales González]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[162]]></attendee_id><normalized_name><![CDATA[M. D. Esteban Lefler]]></normalized_name><name><![CDATA[María Dolores]]></name><lastname><![CDATA[Esteban Lefler]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[114]]></id><title><![CDATA[Estudio cuantitativo de la población afrodescendiente en Colombia]]></title><text><![CDATA[Enmarcado dentro del Programa de Cooperación ``Derechos de los grupos étnicos en Colombia: género, familia y tierra en Popayán y su entorno'', concedido por la AECID a la Univ. Córdoba, en colaboración con la Univ. Medellín, se realiza un estudio de la población afrocolombiana desplazada por razones del conflicto colombiano. Este estudio pretende elaborar una memoria de la situación actual de dicha población desde distintos puntos de vista como DDHH, Justicia Transicional, Educación y Acceso a la Tierra, con la transversal de género. La rica jurisprudencia existente en Colombia, apoyada en estadísticas oficiales, va marcando la hoja de ruta de las políticas públicas. Existen otras fuentes multilaterales que aparentemente arrojan conclusiones distintas y son usadas por asociaciones no gubernamentales provocando una visible controversia. El objetivo de este estudio es el análisis propio de datos primarios disponibles con el fin último de valorar esa posible indeterminación estadística.]]></text><keywords><![CDATA[población afrocolombiana, indeterminación estadística]]></keywords><authors><element><attendee_id><![CDATA[314]]></attendee_id><normalized_name><![CDATA[M. I. Sánchez-Rodríguez]]></normalized_name><name><![CDATA[M. Isabel]]></name><lastname><![CDATA[Sánchez-Rodríguez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[375]]></attendee_id><normalized_name><![CDATA[Á. Ruiz Gándara]]></normalized_name><name><![CDATA[África]]></name><lastname><![CDATA[Ruiz Gándara]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Tocón]]></normalized_name><name><![CDATA[Maribel]]></name><lastname><![CDATA[Tocón]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Sanchís Vidal]]></normalized_name><name><![CDATA[Amelia]]></name><lastname><![CDATA[Sanchís Vidal]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[132]]></id><identifier><![CDATA[XC1c]]></identifier><name><![CDATA[Pósters (Probabilidad)]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[56]]></id><normalized_name><![CDATA[A. Udías Moinelo]]></normalized_name><name><![CDATA[Angel ]]></name><lastname><![CDATA[Udías Moinelo]]></lastname></chairperson><papers><element><id><![CDATA[21]]></id><title><![CDATA[Reaseguro y probabilidades de supervivencia]]></title><text><![CDATA[Este trabajo se centra en la definición y el cálculo de las distintas probabilidades de supervivencia/ruina que aparecen en un análisis bivariante de un contrato de reaseguro. Los riesgos de siniestralidad del asegurador y del reasegurador son dependientes entre sí. Se aplica un método numérico para calcular las distintas probabilidades de supervivencia que tienen en cuenta esta dependencia en un horizonte de tiempo finito. Se presentan resultados numéricos y se solucionan diferentes problemas de optimización que pueden plantearse en un reaseguro de Stop-loss y de Excess of loss.]]></text><keywords><![CDATA[tiempo discreto, probabilidad de ruina en tiempo finitio, métodos recursivos, reaseguro]]></keywords><authors><element><attendee_id><![CDATA[192]]></attendee_id><normalized_name><![CDATA[A. Castañer Garriga]]></normalized_name><name><![CDATA[Anna]]></name><lastname><![CDATA[Castañer Garriga]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[369]]></attendee_id><normalized_name><![CDATA[M. M. Claramunt Bielsa]]></normalized_name><name><![CDATA[M. Mercè ]]></name><lastname><![CDATA[Claramunt Bielsa]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Lefèvre]]></normalized_name><name><![CDATA[Claude]]></name><lastname><![CDATA[Lefèvre]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[80]]></id><title><![CDATA[Construcción de procesos de difusión gaussianos para el ajuste de curvas de crecimiento]]></title><text><![CDATA[En el estudio de fenómenos regidos por variables dinámicas es importante disponer de forma explícita de modelos que sean tratables desde el punto de vista numérico para analizar características concretas de interés del fenómeno en estudio. Por ello los procedimientos de ajuste de procesos estocásticos a datos observados están experimentando un gran auge. En esta comunicación se considera el uso de procesos de difusión gaussianos para modelar fenómenos dinámicos con tendencia positiva. La media infinitesimal del proceso se calcula para asegurar que la media del proceso se ajuste a la tendencia observada a partir de datos muestrales, mientras que se plantean diversas alternativas para controlar la variabilidad del proceso, tanto desde un punto de vista teórico como a partir de la información muestral disponible. El desarrollo establecido es aplicado al caso concreto de algunos procesos asociados a curvas de crecimiento.]]></text><keywords><![CDATA[procesos de difusión, procesos gaussianos, curvas de crecimiento]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. J. Barrera García]]></normalized_name><name><![CDATA[Antonio Jesús]]></name><lastname><![CDATA[Barrera García]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[157]]></attendee_id><normalized_name><![CDATA[P. Román Román]]></normalized_name><name><![CDATA[Patricia]]></name><lastname><![CDATA[Román Román]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[306]]></id><title><![CDATA[Sobre un sistema de ecuaciones en derivadas parciales en modelos de control estocástico de inversión y consumo]]></title><text><![CDATA[El método clásico para resolver problemas de control óptimo estocástico en tiempo continuo es el método de la programación dinámica, dado por la ecuación de Hamilton-Jacobi-Bellman (HJB), que caracteriza a la función valor óptimo. En este trabajo proporcionamos un método alternativo para resolver un problema de control estocástico que incluye al problema clásico de inversión y consumo. El método consiste en caracterizar al control óptimo mediante un sistema de ecuaciones en derivadas parciales con estructura más sencilla que la HJB, que es completamente no lineal. Aplicamos este método al estudio del problema lineal cuadrático, al análisis del problema clásico de inversión y consumo, y a la identificación de problemas de control estocástico donde el control óptimo es también óptimo del problema determinista asociado.]]></text><keywords><![CDATA[control estocástico, programación dinámica, ecuación en derivadas parciales, problema de inversión y consumo]]></keywords><authors><element><attendee_id><![CDATA[398]]></attendee_id><normalized_name><![CDATA[R. Josa Fombellida]]></normalized_name><name><![CDATA[Ricardo]]></name><lastname><![CDATA[Josa Fombellida]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. P. Rincón Zapatero]]></normalized_name><name><![CDATA[Juan Pablo]]></name><lastname><![CDATA[Rincón Zapatero]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[248]]></id><title><![CDATA[Uso de las distribuciones lambda generalizadas para ajustar curvas de fecundidad]]></title><text><![CDATA[Este trabajo responde al desarrollo de nuestra propuesta metodológica de realizar el análisis de las curvas de fecundidad desde la perspectiva de la desigualdad, evaluada a través de las usuales ordenaciones de Lorenz. Esta nueva perspectiva proporciona una visión complementaria para el análisis demográfico. En este caso utilizaremos la familia de distribuciones lambda generalizada GLD$(\lambda_1, \lambda_2, \lambda_3, \lambda_4)$, que ha sido estudiada como modelo de ajuste de distribuciones empíricas por Karian y Dudewicz (2000), para ajustar la serie observada de tasas específicas de fecundidad en Andalucía desde el año 1975. El carácter tetraparamétrico de las distribuciones lambda generalizada introduce un cierto nivel de complejidad en el tratamiento analítico de la obtención de los estimadores por el método de los momentos, por lo que utilizaremos el algoritmo FindLambdasM escrito en Maple,  que puede encontrarse en http://www.crcpress.com.]]></text><keywords><![CDATA[curvas defecundidad, distribución lambda generalizada]]></keywords><authors><element><attendee_id><![CDATA[402]]></attendee_id><normalized_name><![CDATA[H. M. Ramos Romero]]></normalized_name><name><![CDATA[Héctor M.]]></name><lastname><![CDATA[Ramos Romero]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[507]]></attendee_id><normalized_name><![CDATA[A. Peinado Calero]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Peinado Calero]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Ollero]]></normalized_name><name><![CDATA[Jorge]]></name><lastname><![CDATA[Ollero]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. G. Ramos Alcalá]]></normalized_name><name><![CDATA[María G.]]></name><lastname><![CDATA[Ramos Alcalá]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[304]]></id><title><![CDATA[Estudio de la función intensidad mediante SiZer]]></title><text><![CDATA[Cuando se analizan datos del tiempo de servicio de un sistema reparable es esencial determinar la forma de la función ROCOF para valorar si los tiempos entre sucesivos fallos presentan algún tipo de tendencia. Estudiamos un sistema reparable modelizado por un PPNH. En contra de la corriente general que considera básicamente dos formas monótonas (el modelo log-lineal y Weibull) no fijamos una forma funcional específica para el ROCOF, de modo que nos planteamos el problema de estimación no paramétrica de la función intensidad de un PPNH usando funciones núcleo. El principal inconveniente está en seleccionar el parámetro de suavizado óptimo. Sin embargo, dado que nuestro interés está en detectar si existen cambios de comportamiento de la función ROCOF, usamos la herramienta gráfica SiZer map que, a partir de una familia de estimadores basados en diferentes niveles de suavizado, permite descubrir qué características de la función ROCOF reflejadas por los datos son significativas.]]></text><keywords><![CDATA[ROCOF, SiZeR, ancho de banda]]></keywords><authors><element><attendee_id><![CDATA[250]]></attendee_id><normalized_name><![CDATA[R. Raya Miranda]]></normalized_name><name><![CDATA[Rocío]]></name><lastname><![CDATA[Raya Miranda]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[448]]></attendee_id><normalized_name><![CDATA[M. Gámiz Pérez]]></normalized_name><name><![CDATA[M.Luz]]></name><lastname><![CDATA[Gámiz Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[439]]></attendee_id><normalized_name><![CDATA[M. D. Martínez Miranda]]></normalized_name><name><![CDATA[M. Dolores]]></name><lastname><![CDATA[Martínez Miranda]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[133]]></id><identifier><![CDATA[XC1d]]></identifier><name><![CDATA[Pósters (Investigación Operativa)]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[407]]></id><normalized_name><![CDATA[J. J. Molero López]]></normalized_name><name><![CDATA[Juan José]]></name><lastname><![CDATA[Molero López]]></lastname></chairperson><papers><element><id><![CDATA[142]]></id><title><![CDATA[Estimando eficiencia ambiental en DEA considerando la condición de balance de materia]]></title><text><![CDATA[Los aspectos más relevantes de este artículo son el diseño de nuevos índices de eficiencia y de productividad para mejorar su nivel actual de fiabilidad y aplicabilidad dentro del ámbito de la economía del medioambiente. Con mayor precisión, para el estudio de los nuevos índices consideraremos la generación de modelos de eficiencia DEA (Data Envelopment Analysis o Análisis Envolvente de Datos, en castellano) y de sus relaciones duales. Esto, en particular, nos permitirá mejorar alguna de las aproximaciones recientemente publicadas en la literatura para la medición de la eficiencia técnica en sistemas productivos gerenadores de residuos contaminantes.]]></text><keywords><![CDATA[análisis envolvente de datos, eficiencia ambiental, modelos con slacks]]></keywords><authors><element><attendee_id><![CDATA[336]]></attendee_id><normalized_name><![CDATA[J. Aparicio Baeza]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[Aparicio Baeza]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[338]]></attendee_id><normalized_name><![CDATA[F. Vidal Giménez]]></normalized_name><name><![CDATA[Fernando]]></name><lastname><![CDATA[Vidal Giménez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[207]]></id><title><![CDATA[Optimización de costes en una productora de doblaje de películas]]></title><text><![CDATA[En este trabajo se propone un modelo de programación binaria para la optimización de los costes en los que incurre una productora cuando asume el doblaje de una película. Dicho modelo, programado utilizando el paquete AIMMS, es capaz de obtener siempre los esquemas óptimos para un amplio conjunto de películas. A pesar de esto, el tiempo de obtención de gran parte de las soluciones no el del todo satisfactorio para un manejo pr áctico dentro de la productora. Es por ello que se ha diseñado un algoritmo alternativo que, en el conjunto experimental del trabajo, obtiene esquemas óptimos en muy poco tiempo.]]></text><keywords><![CDATA[programación binaria, recocido simulado]]></keywords><authors><element><attendee_id><![CDATA[313]]></attendee_id><normalized_name><![CDATA[M. L. Carpente Rodríguez]]></normalized_name><name><![CDATA[Mª Luisa]]></name><lastname><![CDATA[Carpente Rodríguez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Cerdeira-Pena]]></normalized_name><name><![CDATA[Ana]]></name><lastname><![CDATA[Cerdeira-Pena]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[281]]></attendee_id><normalized_name><![CDATA[S. Lorenzo Freire]]></normalized_name><name><![CDATA[Silvia]]></name><lastname><![CDATA[Lorenzo Freire]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[85]]></id><title><![CDATA[Optimización del reaprovisionamiento del stock en una empresa de bricolaje]]></title><text><![CDATA[Mantener el stock correcto, en la cantidad precisa, durante el tiempo óptimo y en el precio adecuado es el desafío de todo negocio. El exceso de inventario  aumenta considerablemente los gastos de una tienda; poco inventario se traduce en pérdida de ventas y de lealtad de los clientes. La situación ideal sería mantener el stock con un nivel de servicio al cliente cercano al 100\%, es decir, que siempre haya un producto cuando un cliente lo solicita. No obstante, ello acarrearía problemas de inversión, espacio, seguros (a mayor inventario, más caros son los seguros), obsolescencia (los productos tienen un tiempo útil limitado) y robo y daños. El objetivo principal de este trabajo es, por tanto, minimizar el stock en tienda tratando de satisfacer la demanda. Para ello diseñamos un algoritmo de reaprovisionamiento automático que será puesto en práctica a través de un estudio de simulación, con varios proveedores en distintos centros de una empresa de bricolaje.]]></text><keywords><![CDATA[optimización, problemas de inventario, stock, puntos de pedido]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Domínguez Gómez]]></normalized_name><name><![CDATA[Roberto]]></name><lastname><![CDATA[Domínguez Gómez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[480]]></attendee_id><normalized_name><![CDATA[M. J. Lombardía Cortiña]]></normalized_name><name><![CDATA[María José]]></name><lastname><![CDATA[Lombardía Cortiña]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[313]]></attendee_id><normalized_name><![CDATA[L. Carpente Rodríguez]]></normalized_name><name><![CDATA[Luisa]]></name><lastname><![CDATA[Carpente Rodríguez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[G. Estévez Pérez]]></normalized_name><name><![CDATA[Graciela]]></name><lastname><![CDATA[Estévez Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[116]]></id><title><![CDATA[Algunas propiedades para una extensión del problema del ``newsboy'' con pedido de emergencia y umbral de pérdida de ventas]]></title><text><![CDATA[El propósito de este trabajo es estudiar una extensión del problema del ``newsboy'' cuando se considera la existencia de un pedido de emergencia para satisfacer una fracción variable de la demanda no servida inicialmente. Dicha fracción se describe mediante una función no creciente del tamaño de la escasez, la cual supondremos que satisface, además, algunas hipótesis muy débiles que suelen ser habituales en la práctica. Para el modelo así establecido, se deducen propiedades generales y, en el supuesto de que esta función sea lineal, se dan condiciones suficientes de convexidad para la función objetivo. Como consecuencia de este trabajo, se identifican y corrigen algunos errores encontrados en un artículo de investigación sobre teoría de inventarios publicado en EJOR. Se ilustran los resultados teóricos con algunos ejemplos numéricos.]]></text><keywords><![CDATA[``newsboy'', demanda pendiente, pedido de emergencia ]]></keywords><authors><element><attendee_id><![CDATA[191]]></attendee_id><normalized_name><![CDATA[J. García Laguna]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[García Laguna]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[107]]></attendee_id><normalized_name><![CDATA[V. Pando Fernández]]></normalized_name><name><![CDATA[Valentín]]></name><lastname><![CDATA[Pando Fernández]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[128]]></attendee_id><normalized_name><![CDATA[L. A. San José Nieto]]></normalized_name><name><![CDATA[Luis Augusto]]></name><lastname><![CDATA[San José Nieto]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[197]]></attendee_id><normalized_name><![CDATA[J. Sicilia Rodríguez]]></normalized_name><name><![CDATA[Joaquín]]></name><lastname><![CDATA[Sicilia Rodríguez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[53]]></id><title><![CDATA[Un algoritmo lineal para el problema del segundo camino mínimo estricto en redes no dirigidas]]></title><text><![CDATA[Se estudia el problema del segundo camino mínimo estricto, entre dos pares de vértices s y t, en redes no dirigidas con n vértices y m aristas. En base al concepto de costo reducido efectivo, se propone un algoritmo para determinar dicho camino que, en el caso de redes con longitudes positivas, se ejecuta en O(m). Un resultado similar se obtiene para el caso de redes no dirigidas con longitudes no negativas, cuando cualquier camino mínimo entre s y t no usa aristas de longitud cero.]]></text><keywords><![CDATA[segundo camino mínimo estricto, redes no dirigidas, costo reducido efectivo]]></keywords><authors><element><attendee_id><![CDATA[69]]></attendee_id><normalized_name><![CDATA[C. González Martín]]></normalized_name><name><![CDATA[Carlos]]></name><lastname><![CDATA[González Martín]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[70]]></attendee_id><normalized_name><![CDATA[A. Sedeño Noda]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Sedeño Noda]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[250]]></id><title><![CDATA[MyUniversity - Toma de decisiones para un Espacio Europeo de Educación Superior Unificado]]></title><text><![CDATA[La plataforma MyUniversity-URJC, sistema de apoyo a la toma de  Decisiones de cualquier índole dentro del entorno universitario y en particular en lo que respecta a las estrategias de definición de la universidad dentro del Espacio Europeo de Educación Superior, es así que, uno de sus principales  objetivos es  estimular el crecimiento inteligente, sostenible e incluyente acelerando la aplicación más amplia y mejor uso de innovadoras tecnologías digitales y el contenido de los ciudadanos, gobiernos y empresas. Su misión se considera enmarcada dentro de la agenda digital europea.  La plataforma reúne un conjunto de programas y herramientas dentro del ámbito de las TICs, que permiten obtener oportunamente la información requerida durante procesos de la toma de decisiones, que van desde el diseño, implementación y validez de una determinada solución, obteniendo  la  mayor cantidad de información relevante en el menor tiempo posible, con la finalidad de llegar a la decisión mas adecuada.]]></text><keywords><![CDATA[toma de decisiones, gestión, dato, información, análisis de información.]]></keywords><authors/></element><element><id><![CDATA[13]]></id><title><![CDATA[Aplicaciones de la Estadística y la I.O. a las tecnologías móviles ]]></title><text><![CDATA[Las tecnologías móviles han invadido el mercado en forma de pequeños dispositivos con capacidad de procesamiento, conexión a Internet y funciones específicas que ejecutan pequeñas aplicaciones software. Su gran facilidad de uso para los desarrolladores de software ha propiciado una rápida evolución de los Markets. La aplicación de técnicas estadísticas, así como todo tipo de algoritmos de optimización en el desarrollo de nuevas aplicaciones móviles no sólo está justificada sino que es una realidad en crecimiento constante cada día. Una gran parte de las aplicaciones disponibles en los Markets trabaja con datos dinámicos o estáticos correspondientes a todo tipo de variables medibles cuyo valor es de interés para el desarrollo de alguna nueva funcionalidad demandada por la sociedad. En este trabajo se exponen cuatro ejemplos desarrollados como proyectos fin de carrera por alumnos de la Facultad de Informática de la UCM dentro del marco de las Tecnologías Móviles.]]></text><keywords><![CDATA[estadística,tecnologías móviles, android, google]]></keywords><authors><element><attendee_id><![CDATA[100]]></attendee_id><normalized_name><![CDATA[V. López]]></normalized_name><name><![CDATA[Victoria]]></name><lastname><![CDATA[López ]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Baez]]></normalized_name><name><![CDATA[Manuel]]></name><lastname><![CDATA[Baez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Rodríquez de LLera]]></normalized_name><name><![CDATA[José ]]></name><lastname><![CDATA[Rodríquez de LLera]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[D. Sanz]]></normalized_name><name><![CDATA[Daniel]]></name><lastname><![CDATA[Sanz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Saucedo]]></normalized_name><name><![CDATA[Mariam ]]></name><lastname><![CDATA[Saucedo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[P. Torralbo]]></normalized_name><name><![CDATA[Pilar]]></name><lastname><![CDATA[Torralbo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Zapata]]></normalized_name><name><![CDATA[Alvaro]]></name><lastname><![CDATA[Zapata]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[437]]></attendee_id><normalized_name><![CDATA[J. Tejada]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[Tejada]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[G. Miñana Ropero]]></normalized_name><name><![CDATA[Guadalupe]]></name><lastname><![CDATA[Miñana Ropero]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Borrego]]></normalized_name><name><![CDATA[Alvaro ]]></name><lastname><![CDATA[Borrego]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Cordero]]></normalized_name><name><![CDATA[Jorge]]></name><lastname><![CDATA[Cordero]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. Cruz]]></normalized_name><name><![CDATA[Luis]]></name><lastname><![CDATA[Cruz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. González]]></normalized_name><name><![CDATA[Miguel]]></name><lastname><![CDATA[González]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Hernández]]></normalized_name><name><![CDATA[Francisco]]></name><lastname><![CDATA[Hernández]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[D. Palomero]]></normalized_name><name><![CDATA[David]]></name><lastname><![CDATA[Palomero]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[56]]></id><title><![CDATA[Optimización de procesos en terminales portuarias por técnicas de simulación]]></title><text><![CDATA[En las terminales portuarias, la oferta de servicios ha de hacer frente a la solución de los problemas de capacidad de las líneas de atraque, siendo necesario recurrir a técnicas de simulación que optimicen la operativa. La metodología propuesta se ha utilizado en la modelización de diversas terminales portuarias españolas, dentro de una línea de investigación abierta en el Departamento de Ingeniería Civil. Transportes de la UPM. La modelización de las líneas de espera en las terminales utiliza los inputs básicos de la teoría de colas, es decir, las distribuciones de llegadas y servicios a buques y el número de servidores o puestos de atraque. Una vez construido el modelo, las simulaciones proporcionan información relevante sobre los grados de ocupación y eficiencia en los muelles y sobre las esperas relativas de los buques, permitiendo optimizar la gestión estratégica de las terminales.]]></text><keywords><![CDATA[colas, logística, terminales]]></keywords><authors><element><attendee_id><![CDATA[82]]></attendee_id><normalized_name><![CDATA[I. López Ansorena]]></normalized_name><name><![CDATA[Iñigo]]></name><lastname><![CDATA[López Ansorena]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Camarero Orive]]></normalized_name><name><![CDATA[Alberto ]]></name><lastname><![CDATA[Camarero Orive]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[N. González Cancelas]]></normalized_name><name><![CDATA[Nicoletta ]]></name><lastname><![CDATA[González Cancelas]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[75]]></attendee_id><normalized_name><![CDATA[F. Soler Flores]]></normalized_name><name><![CDATA[Francisco ]]></name><lastname><![CDATA[Soler Flores]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[235]]></id><title><![CDATA[A 0-1 programming model for designing the lines of a rapid transit network]]></title><text><![CDATA[Given the station locations of a rapid transit network and the links between them, in this work we tackle the problem of designing the set of lines for the network, minimizing an estimation of the total number of transfers that should be made by the users to arrive at their destinations, so that the number of lines going to each station is as small as possible. It is assumed that whichever two stations are linked by one line at most, and the users choose routes of minimum length for taking their trips. A greedy heuristic procedure for dealing with this problem can be found in the literature. It explicitly determines the shortest routes for those origin-destination pairs of locations whose users are expected to utilize the rapid transit network. We present a 0-1 programming model for solving such problem, and we also report some computational experience on several instances considered in the literature.]]></text><keywords><![CDATA[line designing, transfer, degree of a node]]></keywords><authors/></element><element><id><![CDATA[205]]></id><title><![CDATA[El modelo de asignación de vacantes con doble lista de preferencias]]></title><text><![CDATA[Se presenta una extensión del Problema del matrimonio estable, con los elementos fundamentales de su versión básica, dos conjuntos de agentes y sus respectivas listas de preferencias. Los dos conjuntos de agentes (vacantes y peticionarios) se particionan en grupos, estableciéndose una asociación entre ellos. Los peticionarios establecen sus preferencias en sus respectivas listas, incluyendo vacantes, algunas de las cuales, en función del grupo de la partición al que pertenecen, pueden estar vetadas para ciertos peticionarios. Las listas de preferencias de las vacantes se basan en las listas maestras, (escalafones). Un elemento diferenciador respecto al modelo básico, es que dados dos peticionarios del mismo grupo, están sometidos a dos órdenes diferentes, no siempre coherentes. Las hipótesis establecidas en este modelo, originan tres variantes: JE1, JE2 y JE3. La variante JE3 es la que permite percibir todas las consecuencia del doble escalafonamiento y la no coherencia del mismo.]]></text><keywords><![CDATA[problema del matrimonio estable, algoritmos]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Ramos Méndez]]></normalized_name><name><![CDATA[Eduardo]]></name><lastname><![CDATA[Ramos Méndez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[15]]></id><title><![CDATA[Consideraciones sobre funciones fuzzy preinvex]]></title><text><![CDATA[En el artículo, On characterizations of preinvex fuzzy mappings, Computers and Mathematics with Applications 59 (2010) 933-940, los autores J. Li, M. A. Noor, demostraban algunas caracterizaciones de funciones fuzzy preinvex. No obstante, algunos resultados de ese artículo no están correctos. Nosotros demostramos este hecho con ejemplos. Además, introducimos condiciones adicionales bajo las cuales estos resultados son válidos.]]></text><keywords><![CDATA[invexidad, optimización, fuzzy]]></keywords><authors><element><attendee_id><![CDATA[106]]></attendee_id><normalized_name><![CDATA[G. Ruiz-Garzón]]></normalized_name><name><![CDATA[Gabriel]]></name><lastname><![CDATA[Ruiz-Garzón]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[Y. Chalco-Cano]]></normalized_name><name><![CDATA[Yurilev]]></name><lastname><![CDATA[Chalco-Cano]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[544]]></attendee_id><normalized_name><![CDATA[A. Rufián-Lizana]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Rufián-Lizana]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Osuna-Gómez]]></normalized_name><name><![CDATA[Rafaela]]></name><lastname><![CDATA[Osuna-Gómez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[299]]></id><title><![CDATA[Una implementación eficiente del método épsilon-restricción para problemas de programación entera bi-objetivo]]></title><text><![CDATA[En este trabajo se considera el problema de programación entera bi-objetivo. Se analizan, desde  el punto de vista de la complejidad computacional, algunos métodos conocidos que permiten encontrar todos los puntos eficientes en el espacio objetivo. Los algoritmos con menor complejidad computacional son variantes del método clásico de epsilon-restricción, y fueron desarrollados por Neumayer y Schweigert (1994) y Mavrotas (2009). Suponiendo que haya N puntos eficientes, estas variantes requieren resolver N+3 subproblemas. En este trabajo se desarrolla una nueva variante del método epsilon-restricción que requiere resolver únicamente N+1 subproblemas. ]]></text><keywords><![CDATA[programación entera bi-objetivo, método épsilon-restricción, optimización lexicográfica]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Sáez Aguado]]></normalized_name><name><![CDATA[Jesús]]></name><lastname><![CDATA[Sáez Aguado]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[119]]></id><title><![CDATA[Optimización multiobjetivo en multidimensional scaling]]></title><text><![CDATA[En el problema de clasificación de los objetos de un conjunto, se necesita conocer una desemejanza definida sobre los pares de objetos de dicho conjunto. En general, las clases obtenidas por los métodos usuales de clasificación suelen resultar complejas y, por tanto, de difícil interpretación. El problema que se aborda es la construcción de una función definida sobre el conjunto de objetos dado, con valores en el conjunto de los números reales positivos, de forma que se minimice una función multiobjetivo. En el trabajo que se presenta, se estudia el problema cuando los objetos están ordenados y la desemejanza cumple la propiedad de ser ordenable, obteniéndose resultados que ponen de relieve la importancia del concepto de camino de máximo exceso en la obtención de la solución del problema.]]></text><keywords><![CDATA[optimización multiobjetivo, multidimensional scaling, desemejanza ordenable, camino de máximo exceso]]></keywords><authors><element><attendee_id><![CDATA[152]]></attendee_id><normalized_name><![CDATA[M. I. Sobrón Fernández]]></normalized_name><name><![CDATA[María Inés]]></name><lastname><![CDATA[Sobrón Fernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[494]]></attendee_id><normalized_name><![CDATA[N. Martínez Arjona]]></normalized_name><name><![CDATA[Nuria]]></name><lastname><![CDATA[Martínez Arjona]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[47]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Reunión Grupo SEIO Decisión Multicriterio]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[13:30:00]]></start><end><![CDATA[14:15:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[487]]></id><normalized_name><![CDATA[B. Vitoriano Villanueva]]></normalized_name><name><![CDATA[Begoña]]></name><lastname><![CDATA[Vitoriano Villanueva]]></lastname></chairperson><papers/></element><element><id><![CDATA[59]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Reunión Grupo SEIO Análisis de Datos Funcionales]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[13:30:00]]></start><end><![CDATA[14:15:00]]></end><location><id><![CDATA[10]]></id><name><![CDATA[Sala Viena]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[119]]></id><normalized_name><![CDATA[A. M. Aguilera del Pino]]></normalized_name><name><![CDATA[Ana María]]></name><lastname><![CDATA[Aguilera del Pino]]></lastname></chairperson><papers/></element><element><id><![CDATA[57]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Reunión Grupo SEIO Enseñanza de la Estadística y la Investigación Operativa]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[13:30:00]]></start><end><![CDATA[14:15:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[208]]></id><normalized_name><![CDATA[M. J. García-Ligero Ramírez]]></normalized_name><name><![CDATA[Maria Jesús]]></name><lastname><![CDATA[García-Ligero Ramírez]]></lastname></chairperson><papers/></element><element><id><![CDATA[42]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Traslado a los museos]]></name><description><![CDATA[<p>Los autobuses saldrán con destino a los distintos museos desde la sede del congrreso a las 15:40</p>]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:15:00]]></start><end><![CDATA[16:15:00]]></end><location><![CDATA[]]></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[40]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Visita Museo Thyssen-Bornemisza]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[16:15:00]]></start><end><![CDATA[18:00:00]]></end><location><![CDATA[]]></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[126]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Visita Museo del Prado]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[16:15:00]]></start><end><![CDATA[18:00:00]]></end><location><![CDATA[]]></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[127]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Visita Museo Reina Sofia]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[16:15:00]]></start><end><![CDATA[18:00:00]]></end><location><![CDATA[]]></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[39]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Vino / recepción]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[19:30:00]]></start><end><![CDATA[20:30:00]]></end><location><id><![CDATA[18]]></id><name><![CDATA[Restaurante Samarkanda (Estación Puerta de Atocha)]]></name><venue><![CDATA[Restaurante Samarkanda Puerta de Atocha]]></venue><gps_coords><![CDATA[40.406446,-3.690687]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element></sessions></element><element><date><![CDATA[2012-04-19]]></date><papers/><sessions><element><id><![CDATA[24]]></id><identifier><![CDATA[JA1a]]></identifier><name><![CDATA[JEP-Inauguración Jornadas Estadística Pública]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[09:20:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[50]]></id><normalized_name><![CDATA[A. Alonso-Ayuso]]></normalized_name><name><![CDATA[Antonio ]]></name><lastname><![CDATA[Alonso-Ayuso]]></lastname></chairperson><papers/></element><element><id><![CDATA[25]]></id><identifier><![CDATA[JA1b]]></identifier><name><![CDATA[Conferencia plenaria]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:20:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[518]]></id><normalized_name><![CDATA[A. Cañada]]></normalized_name><name><![CDATA[Agustin]]></name><lastname><![CDATA[Cañada]]></lastname></chairperson><papers><element><id><![CDATA[324]]></id><title><![CDATA[Visión de Eurostat sobre la producción de estadísticas en la próxima década y aplicación en el campo de las estadísticas de empresas]]></title><text><![CDATA[La conferencia versará sobre las tendencias recientes de la producción estadística para la producción de agregados comunitarios, y sobre la visión de Eurostat para la próxima década. En un contexto donde la demanda de estadísticas comunitarias no va a disminuir, y los recursos para la producción estadística no van a aumentar presumiblemente, Eurostat plantea la necesidad de tomar medidas para mejorar tanto la eficiencia como la eficacia de la producción en el marco del sistema estadístico europeo. La presentación cubrirá asimismo las tendencias más recientes en el tema de estadísticas de empresas a nivel europeo.]]></text><keywords><![CDATA[Eurostat, agregados comunitarios estadísticas de empresas]]></keywords><authors/></element></papers></element><element><id><![CDATA[16]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Pausa]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:20:00]]></start><end><![CDATA[10:30:00]]></end><location><![CDATA[]]></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[76]]></id><identifier><![CDATA[JB1]]></identifier><name><![CDATA[JEP-Estimación de pequeñas áreas 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[464]]></id><normalized_name><![CDATA[I. Molina]]></normalized_name><name><![CDATA[Isabel]]></name><lastname><![CDATA[Molina]]></lastname></chairperson><papers><element><id><![CDATA[296]]></id><title><![CDATA[Evaluación de estimadores Dual-Frame: Aplicación a la encuesta de tecnologías de  información y comunicación en hogares en la comunidad autónoma de Canarias]]></title><text><![CDATA[La metodología Dual-Frame se adapta a las exigencias requeridas en una encuesta donde se combinan múltiples escenarios con la intención de abarcar a la población total y rebajar los costes de ejecución. La combinación de información obtenida de forma presencial y la obtenida de forma telefónica suele llevar aparejada la definición de dos escenarios, uno asociado al censo o padrón de la población, y otro al listín teléfono. La aplicación de esta metodología a las encuestas de disponibilidad o uso de tecnologías en los hogares, donde existen variables objetivo de la encuesta que pueden coincidir, tener diferentes grado de asociación, o ser independientes con los escenarios definidos, son especialmente de interés en este trabajo. Diferentes estimadores Dual Frame son evaluados sobre una encuesta simulada con características similares a la encuesta de Tecnologías de Información y Comunicación en Hogares en Canarias generada sobre una población artificial a partir del Censo 2001.]]></text><keywords><![CDATA[dual-frame, encuestas TIC, errores cuadráticos, sesgo]]></keywords><authors><element><attendee_id><![CDATA[470]]></attendee_id><normalized_name><![CDATA[E. González-Dávila]]></normalized_name><name><![CDATA[Enrique]]></name><lastname><![CDATA[González-Dávila]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. A. González-Yanes]]></normalized_name><name><![CDATA[Jeús Alberto]]></name><lastname><![CDATA[González-Yanes]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[242]]></id><title><![CDATA[Estimación multivariante de pequeña área: una aplicación a la estimación de actividad TIC]]></title><text><![CDATA[Un modelo factorial jerárquico de dos niveles nos permite una estimación  de pequeña área que permite el ``borrowing stregth'' no sólo de las áreas vecinas sino también de la información multivariante de los datos. El estimador del parámetro de pequeña área será un estimador Bayesiano empírico que surge de la estimación del modelo multivariante. La metodología se ilustrará utilizando datos de  la encuesta territorial de TIC de los hogares en Cataluña.  Se efectuará una la estimación de un índice de actividad TIC a nivel de pequeña área, las 41 comarcas catalanas. El estudio se complementará con una evaluación de la metodología mediante simulación de Monte Carlo. ]]></text><keywords><![CDATA[estimación de pequeña área, Bayes empírico, modelos factoriales, modelo jerárquico, TIC]]></keywords><authors><element><attendee_id><![CDATA[458]]></attendee_id><normalized_name><![CDATA[A. Satorra Brucart]]></normalized_name><name><![CDATA[Albert ]]></name><lastname><![CDATA[Satorra Brucart ]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[431]]></attendee_id><normalized_name><![CDATA[E. Ventura Colera]]></normalized_name><name><![CDATA[Eva]]></name><lastname><![CDATA[Ventura Colera]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Rovira]]></normalized_name><name><![CDATA[Cristina ]]></name><lastname><![CDATA[Rovira]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. García]]></normalized_name><name><![CDATA[Maribel]]></name><lastname><![CDATA[García]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Pardal]]></normalized_name><name><![CDATA[Marcos]]></name><lastname><![CDATA[Pardal]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[287]]></id><title><![CDATA[Hierarchical Bayes small area estimation of poverty indicators]]></title><text><![CDATA[A Hierarchical Bayes (HB) procedure is proposed for estimation of general non linear parameters in small areas. An unconventional way of applying HB methods is applied, which does not require the use of Markov Chain Monte Carlo (MCMC) methods. This fastens considerably the HB procedure and avoids convergence problems of the Monte Carlo chains. Only non-informative priors are considered for model parameters. The frequencial validity of this Bayesian method is checked through simulation studies conducted under the frequencial framework, in which the performance of empirical Bayes (EB) and HB methods is compared for specific poverty indicators. The method is applied to the estimation of poverty indicators in Spanish provinces, using data from the Survey on Income and Living Conditions.]]></text><keywords><![CDATA[hierarchical Bayes, linear mixed models, poverty indicators, small area estimation]]></keywords><authors><element><attendee_id><![CDATA[464]]></attendee_id><normalized_name><![CDATA[I. Molina]]></normalized_name><name><![CDATA[Isabel]]></name><lastname><![CDATA[Molina]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[B. Nandram]]></normalized_name><name><![CDATA[Balgobin]]></name><lastname><![CDATA[Nandram]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Rao]]></normalized_name><name><![CDATA[J.N.K.]]></name><lastname><![CDATA[Rao]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[75]]></id><identifier><![CDATA[JB2]]></identifier><name><![CDATA[Decisión multicriterio 4]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[172]]></id><normalized_name><![CDATA[C. Maroto Álvarez]]></normalized_name><name><![CDATA[Concepción]]></name><lastname><![CDATA[Maroto Álvarez]]></lastname></chairperson><papers><element><id><![CDATA[180]]></id><title><![CDATA[Optimización del diseño de plantas solares con tecnología de torre. Un enfoque biobjetivo.]]></title><text><![CDATA[En el diseño de una planta solar con tecnología de torre aparecen variables ligadas al diseño de la torre (altura, dimensión del receptor de cavidad, etc.) y otras relacionadas con el campo de heliostatos (número de heliostatos, localización de los mismos). Las variables están sometidas a múltiples restricciones, cuyo origen puede ser muy diverso: limitaciones físicas o mecánicas, mantenimiento de las instalaciones, etc. Se consideran dos criterios, no lineales y no convexos en las variables del problema: la minimización del coste de construcción de la planta y la maximización de la energía generada. En este trabajo se propone la construcción de una aproximación al conjunto de soluciones eficientes del correspondiente problema de optimización biobjetivo.]]></text><keywords><![CDATA[optimización biobjetivo, optimización global,  soluciones eficientes, plantas solares]]></keywords><authors><element><attendee_id><![CDATA[299]]></attendee_id><normalized_name><![CDATA[E. Carrizosa]]></normalized_name><name><![CDATA[Emilio]]></name><lastname><![CDATA[Carrizosa]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[155]]></attendee_id><normalized_name><![CDATA[C. Domínguez Bravo]]></normalized_name><name><![CDATA[Carmen-Ana]]></name><lastname><![CDATA[Domínguez Bravo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Fernández Cara]]></normalized_name><name><![CDATA[Enrique]]></name><lastname><![CDATA[Fernández Cara]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Quero García]]></normalized_name><name><![CDATA[Manuel]]></name><lastname><![CDATA[Quero García]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[188]]></id><title><![CDATA[Ayuda a la decisión multiobjetivo en la gestión del río Kwanza]]></title><text><![CDATA[La gestión del agua se ha convertido en un desafío, sobre todo en países en vías de desarrollo, debido a numerosas causas, como la creciente escasez de agua potable; una explosión demográfica, seguida de una rápida urbanización e industrialización; y el consiguiente aumento en la demanda de energía y agua para consumo humano y agrícola. El río Kwanza (Angola) es un caso paradigmático, ya que es una de las fuentes principales de riqueza del país. Muchas personas basan, directamente o indirectamente, su modo de vida en sus aguas, y muchas actividades económicas, incluyendo la producción de energía, dependen también de su corriente. En este trabajo, proporcionamos un modelo para la gestión multiobjetivo del río Kwanza. El problema es complicado debido a la incertidumbre inherente en varios procesos relacionados, la planificación a largo plazo, y la presencia de interesses contrapuestos. Describimos también un sistema de ayuda a la decisión que implementa nuestro modelo.]]></text><keywords><![CDATA[Gestión multiobjetivo, utilidad esperada, predicción, análisis de decisión multiobjetivo, sistema de ayuda de decisión]]></keywords><authors><element><attendee_id><![CDATA[353]]></attendee_id><normalized_name><![CDATA[K. J. Marie]]></normalized_name><name><![CDATA[Kiombo Jean]]></name><lastname><![CDATA[Marie]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[266]]></attendee_id><normalized_name><![CDATA[J. Cano Cancela]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Cano Cancela]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[446]]></attendee_id><normalized_name><![CDATA[D. Ríos Insua]]></normalized_name><name><![CDATA[David]]></name><lastname><![CDATA[Ríos Insua]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[83]]></id><title><![CDATA[Un modelo de gestión sostenible del monte mediterráneo: agregación de preferencias mediante programación por metas y AHP]]></title><text><![CDATA[Los modelos de gestión sostenible del monte mediterráneo deben diseñarse en un contexto multicriterio, debido a su carácter multifuncional y escasa rentabilidad. En este trabajo hemos desarrollado un modelo de gestión estratégica para el monte valenciano, que tiene en cuenta criterios económicos, sociales y medioambientales, en el que han intervenido expertos y “stakeholders”. Se ha realizado un estudio empírico para priorizar las estrategias de gestión que reflejen las preferencias de la sociedad. Como herramientas de agregación de preferencias hemos utilizado modelos de programación por metas y el método AHP, comparando los resultados obtenidos y analizando las ventajas e inconvenientes de cada una de estas técnicas. Los resultados del estudio revelan que los criterios medioambientales y sociales son más importantes que los criterios económicos. La prevención y extinción de incendios, junto con la reforestación y selvicultura son las estrategias prioritarias. ]]></text><keywords><![CDATA[técnicas multicriterio, programación por metas, AHP]]></keywords><authors><element><attendee_id><![CDATA[172]]></attendee_id><normalized_name><![CDATA[C. Maroto Álvarez]]></normalized_name><name><![CDATA[Concepción]]></name><lastname><![CDATA[Maroto Álvarez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[284]]></attendee_id><normalized_name><![CDATA[M. Segura Maroto]]></normalized_name><name><![CDATA[Marina]]></name><lastname><![CDATA[Segura Maroto]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Ginestar Peiró]]></normalized_name><name><![CDATA[Concepción]]></name><lastname><![CDATA[Ginestar Peiró]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Uriol Batuecas]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[Uriol Batuecas]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[B. Segura García del Río]]></normalized_name><name><![CDATA[Baldomero]]></name><lastname><![CDATA[Segura García del Río]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[70]]></id><identifier><![CDATA[JB3]]></identifier><name><![CDATA[Clasificación y análisis multivariante 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[8]]></id><name><![CDATA[Sala Londres]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[85]]></id><normalized_name><![CDATA[L. F. Rivera Galicia]]></normalized_name><name><![CDATA[Luis F.]]></name><lastname><![CDATA[Rivera Galicia]]></lastname></chairperson><papers><element><id><![CDATA[212]]></id><title><![CDATA[Análisis discriminante lineal jerárquico]]></title><text><![CDATA[En este trabajo se obtienen resultados que permiten identificar las situaciones en las que una regla de clasificación cuadrática puede sustituirse sin apenas pérdida por una regla lineal más simple o, al menos, por una regla lineal a trozos. Tal identificación únicamente requiere calcular los autovectores y autovalores de una matriz por lo que su aplicación práctica es sencilla desde un punto de vista computacional. El método propuesto proporciona una sucesión de hiperplanos (ordenados de mayor capacidad discriminante a menor) que puede utilizarse para construir una sucesión de reglas de clasificación lineales a trozos que aproximan la regla cuadrática. Dado que los primeros hiperplanos de la sucesión son a veces suficientes para alcanzar resultados similares a los que se obtendrían con la regla cuadrática, el método podría utilizarse como técnica de reducción de la dimensión en problemas de clasificación. Esta aplicación y otras se encuentran actualmente bajo estudio.]]></text><keywords><![CDATA[clasificación, análisis discriminante lineal, análisis discriminante cuadrático, reducción de la dimensión]]></keywords><authors><element><attendee_id><![CDATA[405]]></attendee_id><normalized_name><![CDATA[J. R. Berrendero Díaz]]></normalized_name><name><![CDATA[José Ramón]]></name><lastname><![CDATA[Berrendero Díaz]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[418]]></attendee_id><normalized_name><![CDATA[J. Cárcamo Urtiaga]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Cárcamo Urtiaga]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[301]]></id><title><![CDATA[Partición y recombinación de grupos en datos multivariantes]]></title><text><![CDATA[Este trabajo presenta una nueva metodología de clustering que, mediante sucesivas particiones y recombinaciones de la muestra original, permite reconstruir la estructura subyacente de los datos.  El proceso de partición está basado en la función de discriminación desarrollada por Peña, Rodriguez y Tiao en 2009, en que dos observaciones se clasifican en el mismo grupo si tienen un discriminador común: Una observación $x_i$ será un discriminador de $x_j$ si el máximo cambio en la predicción de $x_j$ se obtiene cuando se elimina a $x_i$ de la muestra. Este tipo de partición lleva generalmente a una mayor cantidad de grupos que los realmente presentes en la muestra, por lo que se requiere un método de recombinación. Este proceso se lleva a cabo iterativamente mediante una razón de verosimilitudes en que se sopesa si es más probable la existencia de las particiones o si por el contrario, deben conformar un sólo grupo.]]></text><keywords><![CDATA[clustering, particiones, SAR]]></keywords><authors><element><attendee_id><![CDATA[127]]></attendee_id><normalized_name><![CDATA[A. Alvarez Pinto]]></normalized_name><name><![CDATA[Adolfo]]></name><lastname><![CDATA[Alvarez Pinto]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[D. Peña Sánchez de Rivera]]></normalized_name><name><![CDATA[Daniel]]></name><lastname><![CDATA[Peña Sánchez de Rivera]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[94]]></id><title><![CDATA[Un método para la determinación y visualización de la estructura de grupos]]></title><text><![CDATA[El análisis de conglomerados es una técnica muy popular de clasificación no supervisada que trata de encontrar un número k de grupos de elementos homogéneos dentro de un conjunto de datos, según las similaridades existentes entre ellos. Se han propuesto diferentes métodos de análisis de conglomerados que persiguen conseguir este objetivo en la literatura. Sin embargo, el problema fundamental al que se enfrentan muchos de ellos es el establecimiento del número real de grupos en el conjunto de datos. En este trabajo se presenta un nuevo método de agrupación, basado en la teoría de grafos, que permite determinar el número de grupos que se pueden encontrar en un conjunto de datos y realizar la clasificación de los elementos en estos grupos, así como la visualización de dicha clasificación. Para analizar su utilidad, se ha aplicado este método a algunos conjuntos de datos, y se han examinado los resultados obtenidos.]]></text><keywords><![CDATA[clasificación, número de clusters, visualización]]></keywords><authors/></element></papers></element><element><id><![CDATA[83]]></id><identifier><![CDATA[JB4]]></identifier><name><![CDATA[Problemas de localización 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[9]]></id><name><![CDATA[Sala París]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[395]]></id><normalized_name><![CDATA[Á. Marín Gracia]]></normalized_name><name><![CDATA[Ángel]]></name><lastname><![CDATA[Marín Gracia]]></lastname></chairperson><papers><element><id><![CDATA[175]]></id><title><![CDATA[The ring star problem as a bilevel program]]></title><text><![CDATA[This research addresses the ring star problem (RSP) which consists of locating a simple cycle through a subset of nodes of a graph and assigning the nodes not in the cycle to their closest vertex on the cycle. In this work, we assume that there is also a cost for placing a facility in the nodes of the ring, so that the total cost of locating the ring, assigning the nodes not in the ring and placing the facilities must be minimized. The RSP is approached as a hierarchical decision process with two decision levels and formulated as a bilevel problem with two decision makers in the lower level. An algorithm which combines different techniques is developed. In the upper level, an evolutionary algorithm is used to select the nodes in the ring. In the lower level, a GRASP algorithm is used to solve the TSP faced by the first decision maker, while the second decision maker optimally solves the problem of assigning nodes not in the ring.]]></text><keywords><![CDATA[ring star problem, bilevel programming, evolutionary algorithm]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[H. I. Calvete]]></normalized_name><name><![CDATA[Herminia I.]]></name><lastname><![CDATA[Calvete]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Galé]]></normalized_name><name><![CDATA[Carmen]]></name><lastname><![CDATA[Galé]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[298]]></id><title><![CDATA[Aceleración de la convergencia para el problema de localización minisum con normas lp ]]></title><text><![CDATA[Este trabajo presenta un procedimiento para acelerar la convergencia del algoritmo Weiszfeld en el problema de localización minisum o problema de Weber, cuando las distancias están medidas con una norma lp. Para ello, se combinan los métodos de aceleración basados en la transformación del algoritmo Weiszfeld al introducir un factor de salto función de p, con el método de Steffesen, un esquema de aceleración genérico aplicado a los procesos iterativos para resolver ecuaciones de punto fijo. Se analiza la convergencia de la metodología propuesta y las condiciones bajo las cuales ésta  garantizada.  Además se realiza un análisis computacional que ilustra la eficiencia del procedimiento de resolución propuesto.]]></text><keywords><![CDATA[minisum, convergencia, aceleración, normas lp, Weiszfeld]]></keywords><authors><element><attendee_id><![CDATA[342]]></attendee_id><normalized_name><![CDATA[C. Valero Franco]]></normalized_name><name><![CDATA[Concepción ]]></name><lastname><![CDATA[Valero Franco]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[522]]></attendee_id><normalized_name><![CDATA[A. M. Rodríguez Chía]]></normalized_name><name><![CDATA[Antonio Manuel ]]></name><lastname><![CDATA[Rodríguez Chía]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[I. Espejo Miranda]]></normalized_name><name><![CDATA[Inmaculada]]></name><lastname><![CDATA[Espejo Miranda]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[201]]></id><title><![CDATA[Robustez recuperable en problemas de diseño y logística de redes de transporte]]></title><text><![CDATA[El diseño robusto de redes y servicios de transporte permite optimizar la red y los servicios a construir para atender el conjunto de escenarios en los que se pueden presentar incidentes o siniestros, no obstante su construcción puede ser muy costosa y posteriormente no verse justificada la inversión para una operación normal de la red y de su logística. La recuperación de los sistemas frente a las incidencias frecuentes en el uso de los mismos es otro problema que puede ser objeto de estudio por la investigación de operaciones. La robustez recuperable trata de establecer la robustez del sistema teniendo en cuenta las desviaciones que puedan producirse como consecuencia de la recuperabilidad de los incidentes mas usuales, de esta combinación  resulta un diseño robusto mas económico para el sistema. El modelo resultante puede ser resuelto con ayuda de métodos de descomposición. Con datos reales proporcionados por Renfe se demuestra la utilidad en redes de metro y de cercanías.]]></text><keywords><![CDATA[diseño de redes, gestión de incidentes, logística de servicios, recuperabilidad, robustez, robustez recuperable]]></keywords><authors><element><attendee_id><![CDATA[395]]></attendee_id><normalized_name><![CDATA[Á. Marín Gracia]]></normalized_name><name><![CDATA[Ángel]]></name><lastname><![CDATA[Marín Gracia]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. Cadarso Morga]]></normalized_name><name><![CDATA[Luís]]></name><lastname><![CDATA[Cadarso Morga]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[49]]></id><identifier><![CDATA[JB6]]></identifier><name><![CDATA[Optimización matemática]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[479]]></id><normalized_name><![CDATA[M. A. Goberna Torrent]]></normalized_name><name><![CDATA[Miguel A.]]></name><lastname><![CDATA[Goberna Torrent]]></lastname></chairperson><papers><element><id><![CDATA[167]]></id><title><![CDATA[Direcciones de curvatura negativa mejoradas para problemas sin restricciones]]></title><text><![CDATA[Describimos en este trabajo la implementación eficiente de un algoritmo de punto interior para problemas no lineales no convexos sin restricciones. El método hace uso de procedimientos de bajo coste computacional para implementar las direcciones de curvatura negativa calculadas a partir de una factorización directa de la matriz Hessiana. Estas direcciones mejoran la eficiencia computacional del procedimiento y aseguran la convergencia a puntos KKT de segundo orden, sin necesidad de requerir complementariedad estricta. El buen comportamiento práctico de nuestra propuesta se comprueba en problemas simulados y de la colección CUTEr.]]></text><keywords><![CDATA[optimización no convexa, curvatura negativa, métodos de punto]]></keywords><authors><element><attendee_id><![CDATA[266]]></attendee_id><normalized_name><![CDATA[J. Cano Cancela]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Cano Cancela]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[554]]></attendee_id><normalized_name><![CDATA[J. Martínez Moguerza]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Martínez Moguerza]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. J. Prieto Fernández]]></normalized_name><name><![CDATA[Francisco Javier]]></name><lastname><![CDATA[Prieto Fernández]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[31]]></id><title><![CDATA[The analytic center feasibility pump]]></title><text><![CDATA[The feasibility pump (FP) of Fischetti, Glover and Lodi  has proved to be a successful heuristic for finding feasible solutions of MILPs. Briefly, FP alternates between two sequences of points: one of feasible solutions for the relaxed problem (but not integer), and another of integer points (but not feasible for the relaxed problem). Integer points are obtained from the feasible ones by some rounding procedure. This work extends FP, such that the integer point is obtained by rounding a point on the (feasible) segment between the computed feasible point and the analytic center for the relaxed linear problem. When the selected point to be rounded is one particular endpoint of the segment, this analytic center FP (AC-FP) variant behaves as the standard FP. AC-FP is also compared with the recent analytic center feasibility method (ACFM). Computational results show that AC-FP may outperform FP and ACFM in some MILP instances, either in time or quality of the solution.]]></text><keywords><![CDATA[analytic center, interior-point methods , mixed-integer linear programming ,  feasibility problem , primal heuristics]]></keywords><authors><element><attendee_id><![CDATA[207]]></attendee_id><normalized_name><![CDATA[D. Baena Mirabete]]></normalized_name><name><![CDATA[Daniel ]]></name><lastname><![CDATA[Baena Mirabete]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[206]]></attendee_id><normalized_name><![CDATA[J. Castro Pérez]]></normalized_name><name><![CDATA[Jordi]]></name><lastname><![CDATA[Castro Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[320]]></id><title><![CDATA[Calificación de restricciones en optimización vectorial lineal semi-infinita]]></title><text><![CDATA[El objetivo del trabajo, en colaboración con F. Guerra-Vazquez y M.I. Todorov (UDLA, Puebla, MX), es caracterizar las soluciones débilmente eficientes, eficientes, propiamente eficientes y fuertemente eficientes de problemas consistentes en la minimización simultánea de finitas funciones lineales sujetas a infinitas restricciones asimismo lineales. Tales caracterizaciones se formulan en términos de conos dependientes de los datos y de la existencia de multiplicadores de Karursh-Kuhn-Tucker.]]></text><keywords><![CDATA[optimización semi-infinita, optimización vectorial, optimización lineal]]></keywords><authors/></element></papers></element><element><id><![CDATA[98]]></id><identifier><![CDATA[JB7]]></identifier><name><![CDATA[Procesos estocásticos 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[12]]></id><name><![CDATA[Sala Roma II]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[64]]></id><normalized_name><![CDATA[M. Molina Fernández]]></normalized_name><name><![CDATA[Manuel]]></name><lastname><![CDATA[Molina Fernández]]></lastname></chairperson><papers><element><id><![CDATA[58]]></id><title><![CDATA[El problema de la extinción en procesos de ramificación bisexuales: estudio comparativo]]></title><text><![CDATA[La teoría sobre procesos de ramificación  proporciona modelos para la descripción del comportamiento de sistemas cuyas componentes, tras cierto periodo de existencia,  son reemplazadas por otras de similar o diferente tipo.  Constituye una importante área de investigación tanto por su interés teórico como por sus aplicaciones. En particular,  han suscitado un creciente interés los denominados procesos de ramificación bisexuales,  orientados para describir el comportamiento de poblaciones con reproducción sexual.  En el este trabajo,  consideramos la clase de  procesos  bisexuales dependientes del número de parejas en la población. Centramos la  atención en el estudio de condiciones necesarias y/o suficientes que garantizan la extinción casi segura de la población. Realizamos un estudio comparativo entre las  probabilidades de extinción de los distintos procesos bisexuales introducidos en dicha clase. Presentamos algunos ejemplos en el campo de la dinámica de poblaciones.]]></text><keywords><![CDATA[procesos de ramificación, procesos bisexuales, probabilidad de extinción, dinámica de poblaciones ]]></keywords><authors><element><attendee_id><![CDATA[64]]></attendee_id><normalized_name><![CDATA[M. Molina Fernández]]></normalized_name><name><![CDATA[Manuel]]></name><lastname><![CDATA[Molina Fernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Ma]]></normalized_name><name><![CDATA[Shixia]]></name><lastname><![CDATA[Ma]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[Y. Xing]]></normalized_name><name><![CDATA[Yongsheng]]></name><lastname><![CDATA[Xing]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[96]]></id><title><![CDATA[Extinction conditions for Y-linked mutant-alleles through two-sex branching processes with blind mating structure]]></title><text><![CDATA[The genetic causes of infertility in males or the history of paternal lineages are some relevant problems directly related to mutations in Y-linked genes. The interest of how these genes and their mutations evolve in a population leads us to introduce a new two-sex two-type branching process to model the evolution of the number of carriers of an allele (and its mutations) of a Y-linked gene. It is assumed a population where females and males coexist and mate without the gene having influence on the mating process. In this work it is proved that the key to determine conditions for the extinction/survival of such allele is given by the probability of an offspring to be female, the rate of mutation and the mean number of offspring per couple. Also, it is shown that the fate of its mutations in the population depends on the survival/extinction of the original allele. Finally, the theoretical results are illustrated by means of simulated examples.]]></text><keywords><![CDATA[Y-linked genes, sex-linked inheritance, two-sex branching processes, allelic mutation, extinction vs survival]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. González Velasco]]></normalized_name><name><![CDATA[Miguel]]></name><lastname><![CDATA[González Velasco]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[102]]></attendee_id><normalized_name><![CDATA[C. Gutiérrez Pérez]]></normalized_name><name><![CDATA[Cristina]]></name><lastname><![CDATA[Gutiérrez Pérez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Martínez Quintana]]></normalized_name><name><![CDATA[Rodrigo]]></name><lastname><![CDATA[Martínez Quintana]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[178]]></id><title><![CDATA[Urna de Klein]]></title><text><![CDATA[La urna de Ehrenfest es un modelo que ha tenido muchas aplicaciones y generalizaciones.  Una de ellas contempla la posibilidad de que la composición de la  urna no cambie en algunos pasos. Este modelo fue estudiado inicialmente por Klein. Nos interesa utilizar el modelo de urna de Klein para el diseño de ensayos clínicos aleatorizados, de forma que el tipo de la bola indique el tratamiento a aplicar en cada instante. Por tanto, querremos saber el comportamiento de algunos procesos asociados. En particular, la proporción de bolas de cada color en cada instante, o la proporción de veces que cada uno de los tipos de bola ha sido extraído de la urna. Este último proceso representa el número de veces que cada tratamiento ha sido aplicado. Obtenemos resultados sobre las características de estos dos procesos en cada instante de la evolución de la urna, así como resultados asintóticos.]]></text><keywords><![CDATA[urna de Ehrenfest, leyes fuertes, teorema central]]></keywords><authors><element><attendee_id><![CDATA[311]]></attendee_id><normalized_name><![CDATA[A. Galbete Jiménez]]></normalized_name><name><![CDATA[Arkaitz]]></name><lastname><![CDATA[Galbete Jiménez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. A. Moler Cuiral]]></normalized_name><name><![CDATA[José Antonio ]]></name><lastname><![CDATA[Moler Cuiral]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Plo Alastrué]]></normalized_name><name><![CDATA[Fernando]]></name><lastname><![CDATA[Plo Alastrué]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[8]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Pausa - Café]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[11:30:00]]></start><end><![CDATA[12:00:00]]></end><location><id><![CDATA[17]]></id><name><![CDATA[Hall Plaza Mayor]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[82]]></id><identifier><![CDATA[JC1]]></identifier><name><![CDATA[JEP-Investigación metodológica en estadística pública 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[273]]></id><normalized_name><![CDATA[A. Arroyo]]></normalized_name><name><![CDATA[Andrés]]></name><lastname><![CDATA[Arroyo]]></lastname></chairperson><papers><element><id><![CDATA[319]]></id><title><![CDATA[La importancia de la asistencia técnica en estadística en los países en desarrollo: un reto para los profesionales de la Estadística]]></title><text><![CDATA[El seguimiento de iniciativas globales, como los Objetivos de Desarrollo del Milenio, y la demanda del sector privado genera una gran presión en los países en desarrollo. Sus sistemas estadísticos sufren de falta de infraestructura humana, técnica y estadística, de coordinación entre administraciones, limitado presupuesto para mantener encuestas regulares e inexistencia de orientación al usuario. En esta comunicación se describen algunas necesidades de información ya mencionadas. Comentaremos también los problemas más frecuentes, e iniciativas globales que pretenden mejorar la situación (como el Plan de Acción de Marrakech), así como la tipología de empresas y organizaciones que intervienen en este mercado. Como ejemplo se discutirá el caso de DevStat, y – a partir de la experiencia de los autores - las dificultades que se plantean y las necesidades en materia de formación y habilidades de los expertos que deciden encaminar su carrera a esta cooperación al desarrollo.]]></text><keywords><![CDATA[países en desarrollo, sistemas estadísticos nacionales, asistencia técnica]]></keywords><authors><element><attendee_id><![CDATA[528]]></attendee_id><normalized_name><![CDATA[J. L. Cervera Ferri]]></normalized_name><name><![CDATA[Jose Luis]]></name><lastname><![CDATA[Cervera Ferri]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Vila]]></normalized_name><name><![CDATA[José]]></name><lastname><![CDATA[Vila]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Bergamini]]></normalized_name><name><![CDATA[Mónica]]></name><lastname><![CDATA[Bergamini]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[277]]></id><title><![CDATA[Elaboración de una cuenta satélite de las TIC en España. Años 2005-2009]]></title><text><![CDATA[El trabajo que se propone versa sobre la elaboración de la Cuenta Satélite de las Tecnologías de la Información y Comunicaciones (CS-TIC) en España para el periodo 2005-2009, que permitirá la realización de análisis detallados y modelos de simulación sobre el sector. El marco general de la CS-TIC española son las cuentas nacionales. La metodología general ha consistido en la adaptación de las tablas de origen y destino del MIO 2005, 2006 y 2007 a la definición de ramas y productos TIC (teniendo en cuenta lo establecido por la OCDE) en base a las fuentes estadísticas disponibles: Encuestas Industriales, Encuesta de Servicios, Encuesta de Comercio, estadísticas laborales, encuestas de presupuestos familiares, datos de comercio exterior, series de FBCF del IVIE, directorios, etc., proyectando los datos a 2008 y 2009; elaborando asimismo tablas auxiliares sobre el nº de empresas TIC según tamaño y rama, número de usuarios de los distintos productos según tipo (hogares, empresas, AAPP), etc.]]></text><keywords><![CDATA[contabilidad nacional, tecnologías de la información y comunicación, cuenta satélite, economía, marco Input-Output]]></keywords><authors><element><attendee_id><![CDATA[440]]></attendee_id><normalized_name><![CDATA[J. A. Vicente Vírseda]]></normalized_name><name><![CDATA[Juan Antonio]]></name><lastname><![CDATA[Vicente Vírseda]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. L. Zofío Prieto]]></normalized_name><name><![CDATA[José Luis]]></name><lastname><![CDATA[Zofío Prieto]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[292]]></id><title><![CDATA[El Índice de confianza empresarial armonizado y el panel de opinión de actualidad]]></title><text><![CDATA[Las encuestas de clima económico son encuestas de carácter cualitativo que recogen las opiniones de empresarios sobre la tendencia de una serie de variables, que además numerosos organismos utilizan como indicador adelantado a la evolución de la actividad económica. Con el fin de facilitar la comparabilidad internacional, y de acuerdo con prestigiosos índices, como el Tankan de Japón o el IFO alemán, el INE publica este año un Índice de Confianza Empresarial (ICE) trimestral a partir de la metodología acordada en un grupo de trabajo INE-institutos de estadística regional. Se presenta el ICE armonizado, su diseño y el caso particular del Clima empresarial de Cataluña elaborado por el Idescat y la Cámara de Comercio de Barcelona. Conjuntamente al ICE se desarrolla el panel de opinión de actualidad que permite cubrir necesidades de información de actualidad económica, de una forma rápida y eficaz lo que supone un gran avance en la estadística oficial económica dirigida a establecimientos.]]></text><keywords><![CDATA[índice de confianza empresarial, panel de opinión de actualidad, expectativas, clima empresarial, coyuntura]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Cortina García]]></normalized_name><name><![CDATA[Fernando]]></name><lastname><![CDATA[Cortina García]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Costa]]></normalized_name><name><![CDATA[Alejandro]]></name><lastname><![CDATA[Costa]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[B. González Olmos]]></normalized_name><name><![CDATA[Belén]]></name><lastname><![CDATA[González Olmos]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[505]]></attendee_id><normalized_name><![CDATA[M. García Gil]]></normalized_name><name><![CDATA[Maribel]]></name><lastname><![CDATA[García Gil]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Pardal Martín]]></normalized_name><name><![CDATA[Marcos]]></name><lastname><![CDATA[Pardal Martín]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[89]]></id><title><![CDATA[Valoración de las actividades productivas no de mercado de los hogares españoles en 2010]]></title><text><![CDATA[El objetivo de este trabajo es obtener una valoración adecuada de las actividades productivas no de mercado de los hogares españoles en 2010, mediante la utilización de la información que proporciona la Encuesta de Empleo del Tiempo (EET) 2009-2010. La estimación se puede realizar aplicando a las horas dedicadas a estas actividades obtenidas en la EET los salarios autodeclarados por el personal ocupado en servicio doméstico, tal y como se hizo en 2003, o bien hacer uso de la información de un nuevo módulo introducido en la encuesta de 2010, en el que los hogares que disponen de servicio doméstico declaran lo que pagan a estas personas. Dependiendo del salario elegido, los resultados varían notablemente. De las dos posibilidades barajadas, la manera óptima es utilizar el segundo método pues las personas encuestadas tienden a declarar un salario menor al que realmente perciben. De ahí la importancia de incorporar este módulo de servicio doméstico en la próxima EET que se lleve a cabo.]]></text><keywords><![CDATA[encuesta de empleo del tiempo, cuenta satélite de producción de los hogares]]></keywords><authors><element><attendee_id><![CDATA[262]]></attendee_id><normalized_name><![CDATA[R. del Val García]]></normalized_name><name><![CDATA[Raquel]]></name><lastname><![CDATA[del Val García]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[77]]></id><title><![CDATA[Estimación estadística de poblaciones municipales, para todos los municipios andaluces, con desagregación por sexo y edad, congruentes con las estimaciones de población actual provinciales del INE ]]></title><text><![CDATA[El trabajo fue encargado por el Instituto de Estadística y Cartografía de Andalucía a la Universidad de Sevilla y desarrollado por personal de ambos organismos. Consiste en realizar estimaciones de población municipales, por edades simples y sexo a través de la ecuación compensatoria y mecanismos de ajuste tales que las cifras de los municipios de cada provincia totalicen, globalmente, en sexo y edades simples, los correspondientes a la provincia a la que pertenecen.  A través de la información censal municipal de 2001 y los acontecimientos elementales sobre defunciones, nacimientos y variaciones residenciales desde el 2000 se obtuvieron las poblaciones a uno de enero de 2002 para los 770 municipios andaluces y a partir de aquí las de uno de enero de los años siguientes.]]></text><keywords><![CDATA[estadistica pública, demografía]]></keywords><authors><element><attendee_id><![CDATA[273]]></attendee_id><normalized_name><![CDATA[A. Arroyo]]></normalized_name><name><![CDATA[Andrés]]></name><lastname><![CDATA[Arroyo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. A. Hernandez Rodriguez]]></normalized_name><name><![CDATA[Juan Antonio]]></name><lastname><![CDATA[Hernandez Rodriguez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[456]]></attendee_id><normalized_name><![CDATA[S. Bermudez Parrado]]></normalized_name><name><![CDATA[Silvia]]></name><lastname><![CDATA[Bermudez Parrado]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Planelles Romero]]></normalized_name><name><![CDATA[Joaquín]]></name><lastname><![CDATA[Planelles Romero]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[27]]></id><identifier><![CDATA[JC2]]></identifier><name><![CDATA[Teoría de juegos 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[97]]></id><normalized_name><![CDATA[A. Meca Martínez]]></normalized_name><name><![CDATA[Ana]]></name><lastname><![CDATA[Meca Martínez]]></lastname></chairperson><papers><element><id><![CDATA[37]]></id><title><![CDATA[A geometric characterization of the nucleolus of the assignment game]]></title><text><![CDATA[Maschler et al. (1979) provide a geometrical characterization forvthe intersection of the kernel with the core of a coalitional game, showing that those allocations that lie in both sets are always the midpoint of certain bargaining range between each pair of players. In the case of the assignment game, this means that the kernel can be determined as those core allocations where the maximum amount, that can be transferred without getting outside the core, from one agent to his/her optimally matched partner equals the maximum amount that he/she can receive from this partner, also remaining inside the core (Rochford, 1984). We now prove that the nucleolus of the assignment game can be characterized by requiring this bisection property be satisfied not only for optimally matched pairs but also for optimally matched coalitions.]]></text><keywords><![CDATA[cooperative games, assignment game, core, kernel, nucleolus]]></keywords><authors><element><attendee_id><![CDATA[222]]></attendee_id><normalized_name><![CDATA[F. Llerena]]></normalized_name><name><![CDATA[Francesc]]></name><lastname><![CDATA[Llerena]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[221]]></attendee_id><normalized_name><![CDATA[M. Núñez Oliva]]></normalized_name><name><![CDATA[Marina]]></name><lastname><![CDATA[Núñez Oliva]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[42]]></id><title><![CDATA[A cost allocation rule for k-hop minimum cost spanning tree problems]]></title><text><![CDATA[In this paper we consider k-hop minimum cost spanning tree problems where each node needs to be connected to the source through a path involving at most k links. We prove that the core of a k-hop minimum cost spanning tree problem could be empty. We also introduce and characterize a cost sharing rule based on bankruptcy problems which satisfies meaningful properties in this setting.]]></text><keywords><![CDATA[k-hop minimum cost spanning tree problems, bankruptcy problems, cea]]></keywords><authors><element><attendee_id><![CDATA[210]]></attendee_id><normalized_name><![CDATA[G. Bergantiños Cid]]></normalized_name><name><![CDATA[Gustavo]]></name><lastname><![CDATA[Bergantiños Cid]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[289]]></attendee_id><normalized_name><![CDATA[M. Gómez-Rua]]></normalized_name><name><![CDATA[María]]></name><lastname><![CDATA[Gómez-Rua]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[229]]></attendee_id><normalized_name><![CDATA[N. Llorca-Pascual]]></normalized_name><name><![CDATA[Natividad ]]></name><lastname><![CDATA[Llorca-Pascual]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[361]]></attendee_id><normalized_name><![CDATA[M. Pulido Cayuela]]></normalized_name><name><![CDATA[Manuel ]]></name><lastname><![CDATA[Pulido Cayuela]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[79]]></attendee_id><normalized_name><![CDATA[J. Sánchez Soriano]]></normalized_name><name><![CDATA[Joaquín]]></name><lastname><![CDATA[Sánchez Soriano]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[68]]></id><title><![CDATA[Stable coalition structures for additive cost functions with critical players]]></title><text><![CDATA[In this talk, we present some special classes of cost games that satisfy k-additivity and possess players who contribute to cost reduction of all members of the alliance that they belong to (which we call critical players). This type of games can be found in knowledge-sharing games, inventory games, holding cost games, etc. While papers analyzing these games study specific examples of k-additive cost functions and analyze how players can reduce their cost through cooperation, our goal is to provide an analysis of stability for more general classes of k-additive games with critical players.  ]]></text><keywords><![CDATA[stable coalition structures, cost games, k-additivity, critical players]]></keywords><authors><element><attendee_id><![CDATA[97]]></attendee_id><normalized_name><![CDATA[A. Meca Martínez]]></normalized_name><name><![CDATA[Ana]]></name><lastname><![CDATA[Meca Martínez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[G. Sosic]]></normalized_name><name><![CDATA[Greys ]]></name><lastname><![CDATA[Sosic]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[45]]></id><title><![CDATA[Minimum cost Steiner tree problems]]></title><text><![CDATA[Consider a group of agents located at different geographical places that are interested in some resource that can only be provided by a common supplier. Agents can be served directly from the supplier or indirectly through other agents or some public switches. The connection between two agents, an agent and the source, an agent and a switch, or a switch and the source entail some cost. The first problem that we need to solve is how to provide all the agents with the resource with a minimal total cost. This problem is known as the Steiner tree problem and it has been proved to be NP-hard. So heuristics need to be applied. Assume that using some software, we obtain a tree that connects all the agents with the source that might use some public switches. This kind of problems generalize the classical minimum cost spanning tree problem where no public nodes are allowed. Given this situation, we address the problem of allocating the total cost among the agents in a stable way.]]></text><keywords><![CDATA[OR games,minimum cost spanning tree problems, Steiner trees, core selection]]></keywords><authors><element><attendee_id><![CDATA[210]]></attendee_id><normalized_name><![CDATA[G. Bergantiños Cid]]></normalized_name><name><![CDATA[Gustavo]]></name><lastname><![CDATA[Bergantiños Cid]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[232]]></attendee_id><normalized_name><![CDATA[L. Lorenzo Picado]]></normalized_name><name><![CDATA[Leticia]]></name><lastname><![CDATA[Lorenzo Picado]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[281]]></attendee_id><normalized_name><![CDATA[S. Lorenzo Freire]]></normalized_name><name><![CDATA[Silvia]]></name><lastname><![CDATA[Lorenzo Freire]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. J. Vidal Puga]]></normalized_name><name><![CDATA[Juan José]]></name><lastname><![CDATA[Vidal Puga]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[117]]></id><identifier><![CDATA[JC3]]></identifier><name><![CDATA[Clasificación y análisis multivariante 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[8]]></id><name><![CDATA[Sala Londres]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[105]]></id><normalized_name><![CDATA[A. Berihuete]]></normalized_name><name><![CDATA[Angel]]></name><lastname><![CDATA[Berihuete]]></lastname></chairperson><papers><element><id><![CDATA[312]]></id><title><![CDATA[Logistic biplots for categorical data]]></title><text><![CDATA[Classical Biplot methods allow for the simultaneous representation of individuals and continuous variables in a given data matrix. When variables are binary, categorical or ordinal, a classical linear biplot representation is not suitable. We propose a linear biplot representation based on logistic response models. The coordinates of individuals and variables are computed to have logistic responses along the biplot dimensions. The method is related to logistic regression in the same way that Classical Biplot Analysis (CBA) is related to linear regression. Thus we refer to the method as Logistic Biplot (LB).  In the same way as Linear Biplots are related to Principal Components Analysis, Logistic Biplots are related to Latent Trait Analysis or Item Response Theory. The geometry of those kinds of biplots is studied and their usefulness in Data Mining is illustrated using data on SNPs (Single Nucleotide Polymorphisms) from the HAPMAP project.]]></text><keywords><![CDATA[logistic biplot, categorical data, regression biplots]]></keywords><authors/></element><element><id><![CDATA[162]]></id><title><![CDATA[Biplots with correlations that are linear in the angle]]></title><text><![CDATA[There exist many ways to create a graphical representation of a correlation matrix. Often correlations between variables are graphically approximated by the cosines of the angles between vectors. The relationship between cosines and correlations follows directly from multivariate sample geometry, and is widely used in practice in the interpretation of biplots obtained by principal component analysis. However, in the latter biplots the approximation by cosines is suboptimal in the least squares sense. Moreover, it is difficult to reliably infer the sample correlations by eye from these biplots. By developing plots that have correlations that are linear in the angle, both these aspects can be improved. In the examination of a set of data matrices the cosine based plots typically gave the poorest approximation, plots with a linear interpretation rule for the angle improved the fit, and the best fit was generally obtained by principal factor analysis and using scalar products.]]></text><keywords><![CDATA[biplot, scalar product, interpretation function]]></keywords><authors/></element><element><id><![CDATA[134]]></id><title><![CDATA[Aplicación a catálogos estelares de técnicas estadísticas de reducción de la dimensión y clasificación]]></title><text><![CDATA[El concepto catálogo estelar suele asignarse a bases de datos que contienen medidas físicas de diferente índole para un conjunto determinado de objetos celestes. Uno de los retos estadísticos que presentan dichos catálogos estelares concierne a la selección de aquellas técnicas de reducción de la dimensión y clasificación, que ofrezcan un alto rendimiento en la selección de variables con un mínimo coste de pérdida de información. Utilizando el catálogo estelar JHC mostraremos que: (i) existe una relación directa entre la temperatura de una estrella y los momentos centrales de su espectro físico. (ii) Los métodos de clasificación basados en núcleos aplicados a los momentos centrales muestran un comportamiento heterogéneo, pudiendo decidir qué núcleo ofrece mejores resultados en éste tipo de catálogos.  (iii) Las redes neuronales artificiales de Kohonen son susceptibles de realizar una clasificación estelar mediante aprendizajes supervisados y no supervisados.]]></text><keywords><![CDATA[reducción de la dimensión, clasificación, redes de Kohonen, catálogo estelar]]></keywords><authors><element><attendee_id><![CDATA[105]]></attendee_id><normalized_name><![CDATA[A. Berihuete]]></normalized_name><name><![CDATA[Angel]]></name><lastname><![CDATA[Berihuete]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[104]]></attendee_id><normalized_name><![CDATA[A. Jimenez Jimenez]]></normalized_name><name><![CDATA[Andres]]></name><lastname><![CDATA[Jimenez Jimenez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Álvarez González]]></normalized_name><name><![CDATA[Francisco]]></name><lastname><![CDATA[Álvarez González]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[73]]></id><title><![CDATA[Detección de interacciones relevantes para el problema de clasificación binaria en conjuntos de datos de alta dimensión]]></title><text><![CDATA[Para el problema de clasificación binaria en conjuntos de datos de alta dimensión,  este trabajo presenta un procedimiento orientado a la detección de interacciones genéticas bivariantes con gran capacidad discriminante, pero con distribuciones marginales irrelevantes desde el punto de vista predictivo. Los procedimientos basados en la búsqueda secuencial, como el conocido Varsel, suelen perder este tipo de patrones bidimensionales debido a la propia naturaleza del método. Otras soluciones, como los indicadores TSP y CorScore, asumen una forma determinada para la interacción bidimensional subyacente. Para abordar el problema, se propone un nuevo método basado en la división por bloques del espacio de variables predictoras y el uso de técnicas de clasificación diversas como motores de la búsqueda. El procedimiento se aplica tanto a datos artificiales como a datos reales procedentes de microarrays de ADN mostrando sus ventajas e inconvenientes. ]]></text><keywords><![CDATA[algoritmos de clasificación, interacciones bivariantes, datos de alta dimensión]]></keywords><authors><element><attendee_id><![CDATA[269]]></attendee_id><normalized_name><![CDATA[J. Martín Arevalillo]]></normalized_name><name><![CDATA[Jorge]]></name><lastname><![CDATA[Martín Arevalillo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[546]]></attendee_id><normalized_name><![CDATA[H. Navarro Veguillas]]></normalized_name><name><![CDATA[Hilario]]></name><lastname><![CDATA[Navarro Veguillas]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[121]]></id><identifier><![CDATA[JC4]]></identifier><name><![CDATA[Premio Ramiro Melendreras]]></name><description><![CDATA[Exposición de los trabajos presentados al Premio Ramiro Melendreras. La entrega del premio tendrá lugar el viernes, en la Asamblea de la SEIO]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[9]]></id><name><![CDATA[Sala París]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[79]]></id><normalized_name><![CDATA[J. Sánchez Soriano]]></normalized_name><name><![CDATA[Joaquín]]></name><lastname><![CDATA[Sánchez Soriano]]></lastname></chairperson><papers><element><id><![CDATA[224]]></id><title><![CDATA[Decision analysis services: A framework for distributed decision making over the Web]]></title><text><![CDATA[There has been an increase in the desire to participate in governmental decisions by citizens in recent years. This has motivated the emergence of hundreds of participatory instruments to facilitate the transmission of citizen concerns and desires. Similarly, there has been an increased use of new technologies allowing citizens to contact and communicate their preferences to the political class. We develop here an architecture to support distributed decision making, allowing to construct and implement most participatory processes. It is based on a standard that enables information exchange among various phases of the process, using XML and Web services.]]></text><keywords><![CDATA[group decision making, decision support, decision analysis, e-democracy, e-participation, configurable software, XML, SOA, Web Services]]></keywords><authors/></element><element><id><![CDATA[322]]></id><title><![CDATA[Modeling and implementing an emotional based decision agent]]></title><text><![CDATA[We provide a model that supports the decision making process of an autonomous agent which interacts with several users and is influenced by affective mechanisms. The approach has a decision analytic flavor and includes models forecasting the users' behavior. The implementation has been sketched with an eduitainment robot.]]></text><keywords><![CDATA[agentes autónomos, computación afectiva, teoría de juegos, análisis de decisiones]]></keywords><authors/></element><element><id><![CDATA[174]]></id><title><![CDATA[On solving the collision avoidance problem by mixed 0–1 nonlinear optimization and an approximate sequential mixed 0–1 linear optimization]]></title><text><![CDATA[A Mixed Integer Nonlinear Optimization (MINLO) model for the Collision Avoidance problem in Air Traffic Management is presented. The problem consists of deciding the best strategy for an arbitrary aircraft configuration such that all conflicts in the airspace are avoided. A conflict situation occurs if two or more aircraft lose the minimum safety distance that they have to keep during their flight plans. The MINLO model is based on geometric constructions. The objective is the minimization of the angle variations, such that all conflicts are solved. A computational comparison is performed by considering a state-of-the-art MINLO solver and a linear approximation by discretizing the possible angles of motion is used in order to approximate the optimal solution by a Sequential Mixed Integer Linear Optimization (SMILO) models in an iterative way. Since the problem has to be solved in almost real-time, the approximate SMILO approach is favored due to its small computing time and solution’s quality, and the astonishing small time required for obtaining the incumbent solution.]]></text><keywords><![CDATA[collision avoidance, air traffic management, mixed 0-1 non-linear optimization, heuristics]]></keywords><authors/></element><element><id><![CDATA[328]]></id><title><![CDATA[Comparison of more than two random variables by means of the statistical preference]]></title><text><![CDATA[Stochastic dominance and statistical preference are two important methods for comparing pairs of random variables. However, as pairwise methods they are not fully adequate when the choice must be made between more than two alternatives. In this work, we introduce an extension of statistical preference that is able to handle more than two variables, and investigate its relationship with the classical notions of stochastic dominance and statistical preference.]]></text><keywords><![CDATA[stochastic dominance, probabilistic relation, statistical preference, copula, archimedean copula]]></keywords><authors/></element></papers></element><element><id><![CDATA[102]]></id><identifier><![CDATA[JC5]]></identifier><name><![CDATA[Series temporales 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[10]]></id><name><![CDATA[Sala Viena]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[183]]></id><normalized_name><![CDATA[S. Sotoca López]]></normalized_name><name><![CDATA[Sonia]]></name><lastname><![CDATA[Sotoca López]]></lastname></chairperson><papers><element><id><![CDATA[179]]></id><title><![CDATA[Robust functional classification for time series]]></title><text><![CDATA[We propose using the integrated periodogram to classify time series. The method assigns a new time series to the group that minimizes the distance between the time series integrated periodogram and the group mean of integrated periodograms. Local computation of these periodograms allows to apply this approach to nonstationary time series. Since the integrated periodograms are curves, we apply functional data depth-based techniques to make the classification robust. The method provides small error rates with both simulated and real geological data, improving on existing approaches, and presents good computational behavior.]]></text><keywords><![CDATA[time series, classification, integrated periodogram, functional data depth]]></keywords><authors><element><attendee_id><![CDATA[146]]></attendee_id><normalized_name><![CDATA[A. M. Alonso Fernandez]]></normalized_name><name><![CDATA[Andres M.]]></name><lastname><![CDATA[Alonso Fernandez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[536]]></attendee_id><normalized_name><![CDATA[D. Casado de Lucas]]></normalized_name><name><![CDATA[David]]></name><lastname><![CDATA[Casado de Lucas]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Lopez]]></normalized_name><name><![CDATA[Sara]]></name><lastname><![CDATA[Lopez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Romo]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[Romo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[236]]></id><title><![CDATA[Subsampling inference for the autocovariances and autocorrelations of long-memory time series]]></title><text><![CDATA[We provide a self-normalization for the sample acvs and acs of a linear,  long-memory time series with innovations that have either finite 4th moment or are heavy-tailed with tail index $2<\alpha<4$.  In the asymptotic distribution of the sample acv there are three rates of convergence that depend on the interplay between the memory parameter d and alpha, and which consequently lead to three different limit distributions; for the sample ac the limit distribution only depends on d. We introduce a self-normalized sample acv statistic, which is computable without knowledge of alpha or d, and which converges to a nondegenerate distribution. We also treat self-normalization of the acs.  The sampling distributions can then be approximated nonparametrically by  subsampling, as the asymptotic distribution is still parameter-dependent. The subsampling-based confidence intervals for the process acvs and acs are shown to have satisfactory empirical coverage rates in a simulation study.]]></text><keywords><![CDATA[linear time series, parameter-dependent convergence rates, self-normalization, subsampling confidence intervals]]></keywords><authors><element><attendee_id><![CDATA[420]]></attendee_id><normalized_name><![CDATA[A. Jach]]></normalized_name><name><![CDATA[Agnieszka]]></name><lastname><![CDATA[Jach]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[T. McElroy]]></normalized_name><name><![CDATA[Tucker]]></name><lastname><![CDATA[McElroy]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[152]]></id><title><![CDATA[Simulation tools for statistical model comparison: an application to unobserved component models versus dynamic  regression models]]></title><text><![CDATA[This paper has been developed with the purpose of applying simulation tools to model comparison. Two dynamic statistical models related to road accidents and involving vans have been chosen: Demand for road use, accidents and their gravity (DRAG), developed by Gaudry (1984) and Gaudry and Lasarre (2000)  and Unobserved Components Models (UCM) with intervention, proposed by Harvey and Durbin (1986) and further developed by Hermans et al. (2005) and Bijleveld et al. (2008, 2010). The main difference between the two models lies on the fact that, unlike DRAG, the UCM includes specific terms for both trend and seasonal components, which are assumed unobserved, with their corresponding state equations. The central idea is to assume that one of the models is the true one, and study the effect of estimating  the other one on parameter interpretation, goodness of fit and prediction accuracy.]]></text><keywords><![CDATA[DRAG, unobserved components model, traffic accident,simulation]]></keywords><authors><element><attendee_id><![CDATA[257]]></attendee_id><normalized_name><![CDATA[B. Dadashova]]></normalized_name><name><![CDATA[Bahar]]></name><lastname><![CDATA[Dadashova]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[B. Arenas]]></normalized_name><name><![CDATA[Blanca]]></name><lastname><![CDATA[Arenas]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. M. Mira]]></normalized_name><name><![CDATA[Jose Manuel]]></name><lastname><![CDATA[Mira]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Aparicio Izquierdo]]></normalized_name><name><![CDATA[Francisco ]]></name><lastname><![CDATA[Aparicio Izquierdo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[19]]></id><title><![CDATA[Minimally conditioned likelihood for a nonstationary state space model]]></title><text><![CDATA[Computing the gaussian likelihood for a nonstationary state-space model is a difficult problem which has been tackled within the literature using two strategies: data transformation and diffuse likelihood. The data transformation approach is cumbersome, as it requires nonstandard filtering. On the other hand, in some nontrivial cases the diffuse likelihood value depends on the scale of the diffuse states, so one can obtain different likelihood values corresponding to different observationally equivalent models. In this paper we discuss the properties of the minimally-conditioned likelihood function, as well as two efficient methods to compute its terms with computational advantages for specific models. Three convenient features of the minimally-conditioned likelihood are: (a) it can be computed with standard Kalman filters, (b) it is scale-free, and (c) its values are coherent with those resulting from differencing, this being the most popular approach to deal with nonstationary data.]]></text><keywords><![CDATA[state-space models, conditional likelihood, diffuse likelihood, diffuse initial conditions, kalman filter, nonstationarity]]></keywords><authors><element><attendee_id><![CDATA[183]]></attendee_id><normalized_name><![CDATA[S. Sotoca López]]></normalized_name><name><![CDATA[Sonia]]></name><lastname><![CDATA[Sotoca López]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[478]]></attendee_id><normalized_name><![CDATA[M. Jerez Méndez]]></normalized_name><name><![CDATA[Miguel]]></name><lastname><![CDATA[Jerez Méndez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Casals Carro]]></normalized_name><name><![CDATA[José]]></name><lastname><![CDATA[Casals Carro]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. García Hiernaux]]></normalized_name><name><![CDATA[Alfredo]]></name><lastname><![CDATA[García Hiernaux]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[44]]></id><identifier><![CDATA[JC6]]></identifier><name><![CDATA[Aplicaciones de la investigación operativa 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[196]]></id><normalized_name><![CDATA[C. Azcárate Camio]]></normalized_name><name><![CDATA[Cristina]]></name><lastname><![CDATA[Azcárate Camio]]></lastname></chairperson><papers><element><id><![CDATA[111]]></id><title><![CDATA[Un modelo EOQ con demanda dependiente del nivel del inventario y coste de almacenamiento no lineal en el tiempo y la cantidad]]></title><text><![CDATA[En este trabajo se estudia un sistema de inventario en el que se considera que la demanda depende del nivel del inventario y el coste de almacenamiento es simultáneamente no lineal en el tiempo y en el nivel de stock. Más concretamente, se asume que la tasa de demanda es una función potencial cóncava del nivel de inventario, el coste de almacenamiento es potencial en el tiempo y la cantidad, y no se permite rotura del stock. Bajo estas hipótesis formulamos un modelo EOQ cuyo objetivo es la maximización de beneficios, obteniendo algunas propiedades generales y desarrollando un procedimiento para calcular el tamaño óptimo de pedido y el máximo beneficio por unidad de tiempo. Como casos particulares se obtienen diversos modelos considerados en la literatura sobre el tema.]]></text><keywords><![CDATA[modelos EOQ, costes de almacenamiento no lineales, demanda dependiente del nivel de inventario, maximización de beneficios]]></keywords><authors><element><attendee_id><![CDATA[107]]></attendee_id><normalized_name><![CDATA[V. Pando Fernández]]></normalized_name><name><![CDATA[Valentín]]></name><lastname><![CDATA[Pando Fernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[128]]></attendee_id><normalized_name><![CDATA[L. A. San José Nieto]]></normalized_name><name><![CDATA[Luis Augusto]]></name><lastname><![CDATA[San José Nieto]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[191]]></attendee_id><normalized_name><![CDATA[J. García Laguna]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[García Laguna]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[197]]></attendee_id><normalized_name><![CDATA[J. Sicilia Rodríguez]]></normalized_name><name><![CDATA[Joaquín]]></name><lastname><![CDATA[Sicilia Rodríguez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[309]]></id><title><![CDATA[Incorporación de las decisiones médicas en un modelo de simulación de una unidad de cuidados intensivos.]]></title><text><![CDATA[En trabajos previos hemos mostrado la necesidad de incorporar las decisiones médicas para construir un modelo de simulación válido que represente el funcionamiento de una unidad de cuidados intensivos. Para ello, nuestro  modelo de simulación incluye un conjunto de reglas de decisión que dependen de parámetros cuyo valor se estima mediante la resolución de un problema de optimización.  En este trabajo presentamos un enfoque multiobjetivo al problema de optimización que incorpora las opiniones de los médicos.]]></text><keywords><![CDATA[simulación, optimización, decisiones médicas, unidad de cuidados intensivos]]></keywords><authors><element><attendee_id><![CDATA[196]]></attendee_id><normalized_name><![CDATA[C. Azcárate Camio]]></normalized_name><name><![CDATA[Cristina]]></name><lastname><![CDATA[Azcárate Camio]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Mallor Giménez]]></normalized_name><name><![CDATA[Fermín]]></name><lastname><![CDATA[Mallor Giménez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Barado Hualde]]></normalized_name><name><![CDATA[Julio]]></name><lastname><![CDATA[Barado Hualde]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[170]]></id><title><![CDATA[Modelado y simulación dinámica del traslado interurbano de combustible]]></title><text><![CDATA[Una actividad didáctica experimental  que expandirá el conocimiento profesional de los participantes, ya sean nuevos o versados en el tema de simulación. Muestra las bondades del software actual para modelar sistemas de manufactura y servicios.  La dinámica de transporte de combustible fue simulada  utilizando lenguajes especializados como Arena, Flexsim y Simio. Se enfatiza el proceso de modelado para imitar el transporte de gasolina desde una planta de llenado hasta una ciudad fronteriza. El estudio inicia con la definición de  entidades, actividades, flujos, procesos e interrelaciones inherentes al sistema. El objetivo principal es determinar la cantidad mínima de camiones cisternas para lograr transportar un determinado volumen diario de combustible. Se describe los procesos de recolección y modelado de datos de entrada hasta validación estadística de resultados. Se mostrará aspectos básicos de teoría de muestreo  para definir la longitud y diseño del experimento de simulación.]]></text><keywords><![CDATA[simulación, modelo, validación, muestreo ]]></keywords><authors/></element></papers></element><element><id><![CDATA[96]]></id><identifier><![CDATA[JC7]]></identifier><name><![CDATA[Procesos estocásticos 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[12]]></id><name><![CDATA[Sala Roma II]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[91]]></id><normalized_name><![CDATA[G. Sanz Sáiz]]></normalized_name><name><![CDATA[Gerardo]]></name><lastname><![CDATA[Sanz Sáiz]]></lastname></chairperson><papers><element><id><![CDATA[169]]></id><title><![CDATA[Optimal investment policies]]></title><text><![CDATA[In this work we derive the optimal investment policy regarding the launching of a new and more appealing product. Moreover, we assume that a company is producing and selling an established product, but the company is ready to put a new product into the market, which will compete with the original one.In a previous work (Calaim (2011)), the author derives the optimal policy in a real options context, assuming that the uncertainty process (related with the demand)  follows a geometric brownian motion, and that price, quantity and demand are related by a linear demand function. Here we assume other demand functions; in particular we assume an isoelastic demand function with multiplicative factors.  For this case we derive the optimal investment policy, and show numerical values. We also compare the results, seeking for a kind of robustness in the optimal investment policy. Bibliography: N. Calaim, Optimal Investment policy in competitive products.]]></text><keywords><![CDATA[optimal stopping, real options, geometric brownian motion, first passage time]]></keywords><authors><element><attendee_id><![CDATA[329]]></attendee_id><normalized_name><![CDATA[F. Macedo]]></normalized_name><name><![CDATA[Francisco]]></name><lastname><![CDATA[Macedo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Nunes]]></normalized_name><name><![CDATA[Cláudia]]></name><lastname><![CDATA[Nunes]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[P. Kort]]></normalized_name><name><![CDATA[Peter]]></name><lastname><![CDATA[Kort]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[V. Hagspiel]]></normalized_name><name><![CDATA[Verena]]></name><lastname><![CDATA[Hagspiel]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[274]]></id><title><![CDATA[Optimal portfolio selection through rotations]]></title><text><![CDATA[A typical problem in portfolio theory is the determination of the portfolio weights that maximize an expected utility.  In 1971 Hadar and Russel proved that if the risky assets are i.i.d , the maximal diversification gives the maximal expected utility . The result was generalized by Ma (2000) replacing the assumption of independence with the assumption exchangeability.  We study the case in which an agent has to allocate his capital in different but not independent risky assets and we find an optimal solution based on rotations of the risky assets (random variables) such that the maximal diversification in the rotated vector gives the maximal expected utility.]]></text><keywords><![CDATA[portfolio selection, expected utility]]></keywords><authors><element><attendee_id><![CDATA[442]]></attendee_id><normalized_name><![CDATA[H. Laniado]]></normalized_name><name><![CDATA[Henry]]></name><lastname><![CDATA[Laniado]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. E. Lillo]]></normalized_name><name><![CDATA[Rosa E.]]></name><lastname><![CDATA[Lillo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Pellerey]]></normalized_name><name><![CDATA[Franco]]></name><lastname><![CDATA[Pellerey]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Romo]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[Romo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[291]]></id><title><![CDATA[Una propiedad aditiva de records débiles procedentes de una distribución Geométrica]]></title><text><![CDATA[Consideramos una sucesión de records débiles, W(m),  procedentes de una variable aleatoria discreta, X, que toma valores en los enteros no negativos. El objetivo de este trabajo es proporcionar una nueva caracterización de las distribuciones Geométricas basadas en una propiedad aditiva de records débiles, i.e. X sigue una distribución Geométrica si y solo si para ciertos enteros n, s mayores que 1, se verifica la siguiente igualdad en distribución W(n+s)=W(n)+W’(s), con W’(s) independiente de W(n) y W’(s) igualmente distribuido que W(s).  Para ello se planteará la igualdad en distribución  y se utilizarán argumentos combinatorios. Este resultado extiende a records no consecutivos el obtenido por Hijab and Ahsanullah (2006) para el caso consecutivo.]]></text><keywords><![CDATA[records débiles, distribución Geométrica, caracterización de distribuciones]]></keywords><authors><element><attendee_id><![CDATA[453]]></attendee_id><normalized_name><![CDATA[A. Castaño Martínez]]></normalized_name><name><![CDATA[Antonia]]></name><lastname><![CDATA[Castaño Martínez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[545]]></attendee_id><normalized_name><![CDATA[F. López Blázquez]]></normalized_name><name><![CDATA[Fernando]]></name><lastname><![CDATA[López Blázquez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[B. Salamanca Miño]]></normalized_name><name><![CDATA[Begoña]]></name><lastname><![CDATA[Salamanca Miño]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[276]]></id><title><![CDATA[Geometric records and paralyzable counters in particle physics]]></title><text><![CDATA[Given a parameter $k > 1$, the nth observation of a sequence of nonnegative observations is a geometric record if $X_n > k max(X_1, dots, X_{n-1})$, that is, if $X_n$ is k times greater than all preceding observations. We study the number of geometric records, $N_n$, among the first $n$ observations in a sequence of independent and identically distributed random variables with distribution $F$. We show that $N_n$ increases to a finite random limit for ligth-tailed $F$. For medium and heavy-tailed distributions, we prove that $N_n$ diverges to infinity. In this case, we prove a law of large numbers and provide conditions for asymptotic normality. When we consider the values of geometric records, we find an unexpected relationship with models of paralyzable counters in particle physics. Examples of applications to common families of distributions are also provided.]]></text><keywords><![CDATA[geometric records, asymptotic normality, paralyzable counters]]></keywords><authors><element><attendee_id><![CDATA[91]]></attendee_id><normalized_name><![CDATA[G. Sanz Sáiz]]></normalized_name><name><![CDATA[Gerardo]]></name><lastname><![CDATA[Sanz Sáiz]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Gouet]]></normalized_name><name><![CDATA[Raúl]]></name><lastname><![CDATA[Gouet]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. J. López]]></normalized_name><name><![CDATA[F. Javier]]></name><lastname><![CDATA[López]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[122]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Reunión Jurado Premio Ramiro Melendreras]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[13:30:00]]></start><end><![CDATA[14:30:00]]></end><location><id><![CDATA[19]]></id><name><![CDATA[Sala Magerit]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[370]]></id><normalized_name><![CDATA[L. Ugarte Martínez]]></normalized_name><name><![CDATA[Lola]]></name><lastname><![CDATA[Ugarte Martínez]]></lastname></chairperson><papers/></element><element><id><![CDATA[13]]></id><identifier><![CDATA[JD1]]></identifier><name><![CDATA[Conferencia plenaria]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[370]]></id><normalized_name><![CDATA[L. Ugarte Martínez]]></normalized_name><name><![CDATA[Lola]]></name><lastname><![CDATA[Ugarte Martínez]]></lastname></chairperson><papers><element><id><![CDATA[209]]></id><title><![CDATA[Deconvolution and Classification]]></title><text><![CDATA[In a series of papers on Lidar data, magically good classification rates are claimed once data are deconvolved and a dimension reduction technique applied. The latter can certainly be useful, but it is not clear a priori that deconvolution is a good idea in this context. After all, deconvolution adds noise, and added noise leads to lower classification accuracy. I will give a more or less formal argument that in a closely related class of deconvolution problems, what statisticians call ``Measurement Error Models", deconvolution typically leads to increased classification error rates. An empirical example in a more classical deconvolution context illustrates the results, and new methods and results relevant to the Lidar data will be discussed.]]></text><keywords><![CDATA[deconvolution, classification]]></keywords><authors/></element></papers></element><element><id><![CDATA[12]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Pausa - Café]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[16:30:00]]></start><end><![CDATA[17:00:00]]></end><location><id><![CDATA[17]]></id><name><![CDATA[Hall Plaza Mayor]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[128]]></id><identifier><![CDATA[JE1]]></identifier><name><![CDATA[IV conferencia interuniversitaria sobre grados y másteres en Estadística]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[17:00:00]]></start><end><![CDATA[20:00:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[370]]></id><normalized_name><![CDATA[L. Ugarte Martínez]]></normalized_name><name><![CDATA[Lola]]></name><lastname><![CDATA[Ugarte Martínez]]></lastname></chairperson><papers/></element><element><id><![CDATA[114]]></id><identifier><![CDATA[JE2]]></identifier><name><![CDATA[Teoría de juegos 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[17:00:00]]></start><end><![CDATA[18:20:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[210]]></id><normalized_name><![CDATA[G. Bergantiños Cid]]></normalized_name><name><![CDATA[Gustavo]]></name><lastname><![CDATA[Bergantiños Cid]]></lastname></chairperson><papers><element><id><![CDATA[321]]></id><title><![CDATA[Redes sociales, acción colectiva y poder de votación]]></title><text><![CDATA[Dada una Red Social en la que la interacción entre los individuos viene dada por una relación binaria (simétrica o asimétrica; ponderada o no), proponemos una medida del poder que un grupo tiene para conseguir que la sociedad adopte su estándar de comportamiento, considerando el tiempo que tarda en conseguir que ``toda'' la sociedad cambie de opinión, si es que tiene poder suficiente como para conseguirlo. Del mismo modo, en aquellos contextos en los es suficiente con conseguir un cierto apoyo (en un movimiento revolucionario o en la adopción de innovaciones, por ejemplo, es suficiente con alcanzar una cierta masa crítica), medimos el poder de un grupo como el tiempo que tarda en alcanzar dicho nivel de apoyo. Esta aproximación nos permite analizar cuestiones relativas al poder de voto, al cuantificar el grado en que un grupo de votantes es capaz de controlar el resultado final de la votación, teniendo en cuenta las relaciones sociales en las que los individuos están inmersos. ]]></text><keywords><![CDATA[redes sociales, difusión de innovaciones, juegos de voto, centralidad]]></keywords><authors><element><attendee_id><![CDATA[58]]></attendee_id><normalized_name><![CDATA[E. Molina]]></normalized_name><name><![CDATA[Elisenda]]></name><lastname><![CDATA[Molina]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Flores]]></normalized_name><name><![CDATA[Ramón]]></name><lastname><![CDATA[Flores]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Koster]]></normalized_name><name><![CDATA[Maurice]]></name><lastname><![CDATA[Koster]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[I. Lindner]]></normalized_name><name><![CDATA[Ines]]></name><lastname><![CDATA[Lindner]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[218]]></id><title><![CDATA[Problemas de bancarrota con un estado no perfectamente divisible y acreedores con funciones de utilidad generales]]></title><text><![CDATA[En este trabajo estudiamos situaciones de bancarrota en las que el estado está compuesto por unidades homegéneas no divisibles. Asimismo, los acreedores tienen funciones de utilidad generales, es decir, la utilidad de recibir una unidad no tiene el mismo efecto en todos los acreedores, y cada unidad recibida no tiene que proporcionar la misma utilidad al acreedor. En esta situación analizamos cómo serían las reglas de bancarrota clasicas (CEA, CEL y Talmud) y proporcionamos un conjunto de propiedades razonables que tales reglas deberían satisfacer y con ellas caracterizamos las reglas adaptadas que se proponen en el trabajo.]]></text><keywords><![CDATA[problemas de bancarrota]]></keywords><authors/></element><element><id><![CDATA[105]]></id><title><![CDATA[Sharing a polluted river: The responsibility rule]]></title><text><![CDATA[Ni and Wang (2007, Games Econ Behav) model a river as a segment divided into n subsegments from upstream to downstream such that each agent is located in one of them. The agents generate some kind of pollution in the river. A central agency determines the costs of cleaning the river and distributes them among the agents. In this paper, we consider this model and we assume that the pollution is transmitted from upstream to downstream to a rate. When this rate is unknown we can estimate at least minimum and maximum limits of responsibility for each agent from the cost vector. We propose a new rule, the responsibility rule, which has into account the information derived from the limits of responsibility in order to distribute the cost. We also provide a characterization result of this rule with four properties: No Upstream Responsibility, Consistent Responsibility, Symmetry of the non-imputable pollution and Partial Independence of Position. We prove that the properties are independent.]]></text><keywords><![CDATA[cCost sharing, pollutant-cleaning cost, limits of responsibility, characterization]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Alcalde Unzu]]></normalized_name><name><![CDATA[Jorge]]></name><lastname><![CDATA[Alcalde Unzu]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[289]]></attendee_id><normalized_name><![CDATA[M. Gómez Rúa]]></normalized_name><name><![CDATA[María]]></name><lastname><![CDATA[Gómez Rúa]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Molis]]></normalized_name><name><![CDATA[Elena]]></name><lastname><![CDATA[Molis]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[32]]></id><title><![CDATA[Cost allocation in power grids]]></title><text><![CDATA[We consider a set of agents, each of them able to produce and demand a service like power. Agents can send and receive power through a tree. This tree has a maintenenance cost that should be paid by the agents. In this paper we propose, and characterize axiomatically, two rules for sharing the cost of the tree.]]></text><keywords><![CDATA[cost allocation]]></keywords><authors><element><attendee_id><![CDATA[210]]></attendee_id><normalized_name><![CDATA[G. Bergantiños Cid]]></normalized_name><name><![CDATA[Gustavo]]></name><lastname><![CDATA[Bergantiños Cid]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Martínez]]></normalized_name><name><![CDATA[Ricardo]]></name><lastname><![CDATA[Martínez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[113]]></id><identifier><![CDATA[JE3]]></identifier><name><![CDATA[Clasificación y Análisis Multivariante 3]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[17:00:00]]></start><end><![CDATA[18:20:00]]></end><location><id><![CDATA[8]]></id><name><![CDATA[Sala Londres]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[452]]></id><normalized_name><![CDATA[M. Beltrán Pascual]]></normalized_name><name><![CDATA[Mauricio]]></name><lastname><![CDATA[Beltrán Pascual]]></lastname></chairperson><papers><element><id><![CDATA[220]]></id><title><![CDATA[Clasificación de imágenes por su contenido: paisajes y no-paisajes]]></title><text><![CDATA[En este trabajo los autores presentan un enfoque para la clasificación de imágenes digitales basadas en su contenido, específicamente se clasifican escenas de paisajes y no-paisajes. Se proponen tres variables para realizar la clasificación en ambos grupos. La varianza efectiva, utilizada para explicar la variabilidad dentro de una imagen, la variabilidad local utilizada para describir la dependencia espacial de los pixeles en la imagen y la correlación espacial para representar la correlación entre un pixel y sus vecinos. Se trabaja con dos bases de imágenes heterogéneas, una de ellas especialmente recolectada para la investigación. Se utilizan dos métodos de clasificación para realizar la asignación en el grupo de paisajes y no-paisajes: el método de vecinos más próximos y el discriminante lineal de Fisher.  Ambos procedimientos generan similares resultados, mejorando los niveles de clasificación alcanzados por otros autores que han trabajado problemas semejantes de clasificación.]]></text><keywords><![CDATA[clasificación, imágenes]]></keywords><authors><element><attendee_id><![CDATA[367]]></attendee_id><normalized_name><![CDATA[M. A. Giuliodori]]></normalized_name><name><![CDATA[María Andrea ]]></name><lastname><![CDATA[Giuliodori]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. E. Lillo]]></normalized_name><name><![CDATA[Rosa Elvira]]></name><lastname><![CDATA[Lillo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[D. Peña]]></normalized_name><name><![CDATA[Daniel]]></name><lastname><![CDATA[Peña]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[234]]></id><title><![CDATA[El clasificador tangente]]></title><text><![CDATA[Dada una regla de clasificación, describimos un método general para construir un clasificador lineal muy simple. Esta nueva regla, que denominamos clasificador tangente, se obtiene calculando el hiperplano tangente a la curva que separa los grupos (generada por el clasificador inicial) en un cierto punto. En regiones cuadráticas el clasificador tangente se expresa de forma cerrada y sencilla. Discutimos varios ejemplos en los que se muestra que el clasificador tangente puede ser casi óptimo y espectacularmente distinto de la conocida regla lineal de Fisher. También analizamos mediante algunas simulaciones el comportamiento de este nuevo clasificador lineal en dos situaciones en las que las reglas usuales fallan: cuando hay una fracción de datos atípicos en la muestra de entrenamiento y cuando la dimensión de los datos es muy alta en comparación con el tamaño muestral.]]></text><keywords><![CDATA[clasificación, análisis discriminante lineal, análisis discriminante cuadrático]]></keywords><authors><element><attendee_id><![CDATA[418]]></attendee_id><normalized_name><![CDATA[J. Cárcamo Urtiaga]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Cárcamo Urtiaga]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[405]]></attendee_id><normalized_name><![CDATA[J. R. Berrendero Díaz]]></normalized_name><name><![CDATA[José Ramón]]></name><lastname><![CDATA[Berrendero Díaz]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[251]]></id><title><![CDATA[Una propuesta para clasificar curvas no alineadas horizontalmente de forma robusta ]]></title><text><![CDATA[En muchas aplicaciones biomédicas se registran datos que tienen la forma de datos funcionales. Este tipo de datos son tales que cada observación individual corresponde a una función real del tiempo. Una cuestión importante en el análisis de estos datos es su clasificación en subgrupos homogéneos. Debido a variaciones fruto de translaciones en el tiempo en las diferentes curvas, un paso necesario para el análisis es la alineación de los mismos con el objeto de obtener una mejor representación de la función subyacente (``time warping'' ó ``curve registration''). En este trabajo proponemos un procedimiento para tratar con el problema de clasificación de curvas teniendo en cuenta la presencia de outliers cuando las curvas están desalineadas sin llevar a cabo dos pasos por separado (alineamiento y clasificación) y utilizando recortes para eliminar la contaminación. Presentamos el procedimiento para datos simulados y una aplicación a datos reales.]]></text><keywords><![CDATA[clasiﬁcación de curvas, alineamiento de curvas, robustez ]]></keywords><authors><element><attendee_id><![CDATA[403]]></attendee_id><normalized_name><![CDATA[M. T. Gonzalez  Arteaga]]></normalized_name><name><![CDATA[María Teresa]]></name><lastname><![CDATA[Gonzalez  Arteaga]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. A. García Escudero]]></normalized_name><name><![CDATA[Luis Angel]]></name><lastname><![CDATA[García Escudero]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Mayo Iscar]]></normalized_name><name><![CDATA[Agustín]]></name><lastname><![CDATA[Mayo Iscar]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[293]]></id><title><![CDATA[Un nuevo clasificador de préstamos bancarios a través de la minería de datos]]></title><text><![CDATA[En este artículo se muestra la forma de implementar eficientemente un nuevo clasificador de préstamos bancarios a través de la minería de datos. Los modelos de credit scoring ayudan en un primer momento a la toma de decisión a los gerentes de los bancos. La metodología propuesta es la combinación de modelos. Los multiclasificadores son una excelente forma de integrar la información de diferentes fuentes. Esta combinación de dos o más clasificadores, en general, proporciona estimaciones más robustas y eficientes que cuando se utiliza un único clasificador. También se utilizan porque resuelven el problema de sobreadaptación (overfitting) y es posible obtener buenos resultados con pocos datos. Se describen los principales métodos de combinación de clasificadores utilizados en minería de datos: Bagging, Boosting, Stacking, Cascading, \dots y se aplican a los datos de clientes bancarios obteniéndose unos excelentes resultados comparados con los modelos y algoritmos utilizados individualmente.]]></text><keywords><![CDATA[minería de datos, multiclasificadores, credit scoring, curva ROC]]></keywords><authors><element><attendee_id><![CDATA[452]]></attendee_id><normalized_name><![CDATA[M. Beltrán Pascual]]></normalized_name><name><![CDATA[Mauricio]]></name><lastname><![CDATA[Beltrán Pascual]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[Á. Muñoz Alamillos]]></normalized_name><name><![CDATA[Ángel ]]></name><lastname><![CDATA[Muñoz Alamillos]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Muñoz Martínez]]></normalized_name><name><![CDATA[Azahara]]></name><lastname><![CDATA[Muñoz Martínez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[80]]></id><identifier><![CDATA[JE4]]></identifier><name><![CDATA[Problemas de localización 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[17:00:00]]></start><end><![CDATA[18:20:00]]></end><location><id><![CDATA[9]]></id><name><![CDATA[Sala París]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[240]]></id><normalized_name><![CDATA[J. Alcaraz Soria]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Alcaraz Soria]]></lastname></chairperson><papers><element><id><![CDATA[282]]></id><title><![CDATA[Localización multiobjetivo-multifacilidad en grafos]]></title><text><![CDATA[La Teoría de la Localización consiste básicamente en encontrar la mejor ubicación para uno o más servicios de manera que se optimice una función objetivo. Muchas aplicaciones reales conllevan localizar los servicios dentro de una red (de carreteras, calles, telecomunicaciones, etc) donde el criterio a optimizar es una función de la distancia entre los servicios  y los puntos de demanda. En este trabajo se considera el problema de localizar p servicios en una red en presencia de k objetivos tipo p-mediana, representados por un conjunto de pesos para cada uno de los objetivos. Se analiza el caso en el que cada peso puede ser tanto positivo (atractivo) como negativo (repulsivo) y se presenta un algoritmo para determinar el conjunto no dominado de soluciones.]]></text><keywords><![CDATA[localización, multicriterio, p-mediana]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Kalcsics]]></normalized_name><name><![CDATA[Jörg]]></name><lastname><![CDATA[Kalcsics]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Nickel]]></normalized_name><name><![CDATA[Stefan]]></name><lastname><![CDATA[Nickel]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[451]]></attendee_id><normalized_name><![CDATA[M. A. Pozo Montaño]]></normalized_name><name><![CDATA[Miguel A.]]></name><lastname><![CDATA[Pozo Montaño]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[65]]></attendee_id><normalized_name><![CDATA[J. Puerto]]></normalized_name><name><![CDATA[Justo]]></name><lastname><![CDATA[Puerto]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[522]]></attendee_id><normalized_name><![CDATA[A. M. Rodríguez-Chía]]></normalized_name><name><![CDATA[Antonio M.]]></name><lastname><![CDATA[Rodríguez-Chía]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[237]]></id><title><![CDATA[Capacitated delocation models for closing and resizing redundant facilities]]></title><text><![CDATA[During restructuring processes due to mergers and/or acquisitions, firms frequently face the problem of having redundant facilities competing with each other for the same group of customers or clients. The problem of closing down facilities in such a network has not been fully addressed in the literature, and, whenever it has been analysed, it has been orientated to shrinking services as a response to shifts in demand or to changing market conditions. In this paper we introduce a new facility closing and resizing model based on the capacitated facility location problem. The model considers both, closing down and long term operation costs, and addresses the problem of resizing open facilities in order to accommodate customers displaced from those closed. We motivate the problem with an example from the banking sector and compare this to minor adaptations of standard location models to illustrate the advantages of our approach.]]></text><keywords><![CDATA[facility location, delocation, network restructuring, integer programming]]></keywords><authors><element><attendee_id><![CDATA[421]]></attendee_id><normalized_name><![CDATA[D. Ruiz-Hernández]]></normalized_name><name><![CDATA[Diego]]></name><lastname><![CDATA[Ruiz-Hernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. López Pascual]]></normalized_name><name><![CDATA[Joaquín]]></name><lastname><![CDATA[López Pascual]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[87]]></id><title><![CDATA[Diseño de técnicas metaheurísticas para el problema de la p-mediana con fiabilidad]]></title><text><![CDATA[En el problema de la p-mediana se asume que, una vez se abren los centros, no pueden fallar. Sin embargo, en la práctica pasa a menudo que dichos centros quedan temporalmente fuera de servicio, con lo que los clientes deben reasignarse a otros que les den servicio, con el consiguiente incremento del coste. Teniendo en cuenta esto, quizá sea preferible una solución más cara, pero que sea más fiable. Este doble objetivo es considerado en este problema. Se trata de un problema NP-duro en el que las técnicas exactas fallan para problemas de tamaño medio. Presentamos diferentes configuraciones de dos metaheurísticas, un algoritmo genético y una técnica “scatter search” para resolver el problema, las comparamos y comparamos su eficiencia con las técnicas exactas a través de un extenso estudio computacional en el que utilizamos instancias de las librerías más conocidas. Los resultados muestran el excelente comportamiento de las técnicas metaheurísticas para resolver este problema.]]></text><keywords><![CDATA[técnicas metaheurísticas, problema p-mediana, algoritmos genéticos, scatter search]]></keywords><authors><element><attendee_id><![CDATA[240]]></attendee_id><normalized_name><![CDATA[J. Alcaraz Soria]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Alcaraz Soria]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[302]]></attendee_id><normalized_name><![CDATA[M. Landete Ruíz]]></normalized_name><name><![CDATA[Mercedes]]></name><lastname><![CDATA[Landete Ruíz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[380]]></attendee_id><normalized_name><![CDATA[J. F. Monge Ivars]]></normalized_name><name><![CDATA[Juan Francisco ]]></name><lastname><![CDATA[Monge Ivars]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[105]]></id><identifier><![CDATA[JE5]]></identifier><name><![CDATA[Series temporales 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[17:00:00]]></start><end><![CDATA[18:20:00]]></end><location><id><![CDATA[10]]></id><name><![CDATA[Sala Viena]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[459]]></id><normalized_name><![CDATA[E. Senra]]></normalized_name><name><![CDATA[Eva]]></name><lastname><![CDATA[Senra]]></lastname></chairperson><papers><element><id><![CDATA[271]]></id><title><![CDATA[Multiple break detection in the correlation structure of financial returns]]></title><text><![CDATA[Correlations between asset returns play an important role in financial analysis. More precisely, accurate estimates of the correlation between financial returns are crucial in portfolio management. In particular, in periods of financial crisis, extreme movements in asset prices are found to be more highly correlated than small movements. It is precisely under these conditions that investors are extremely concerned about changes on correlations. We propose a sequential procedure to detect the number and position of multiple change points in the correlation structure of financial returns. It is shown analytically that the proposed algorithm asymptotically gives the correct number of change points and the changes in points are consistently estimated. It is also shown by simulation studies and by an empirical application that the algorithm yields reasonable results.]]></text><keywords><![CDATA[correlations, CUSUM statistics, financial returns, multiple change point detection, sequential procedure]]></keywords><authors><element><attendee_id><![CDATA[429]]></attendee_id><normalized_name><![CDATA[P. Galeano San Miguel]]></normalized_name><name><![CDATA[Pedro]]></name><lastname><![CDATA[Galeano San Miguel]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[D. Wied]]></normalized_name><name><![CDATA[Dominik]]></name><lastname><![CDATA[Wied]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[88]]></id><title><![CDATA[Un enfoque alternativo para la proyección de los flujos migratorios]]></title><text><![CDATA[Las proyecciones demográficas son un factor clave tanto en las decisiones de política económica, como en la elaboración de un escenario macroeconómico y en la estimación de los factores de elevación en encuestas oficiales. En el caso de la población española, su evolución ha venido marcada por la variación de los flujos migratorios. Entre 2002-2007 esta variable superó 600 mil personas al año, en 2010 fue de 62.156 y para 2011 el Instituto Nacional de Estadística (INE) estima una variación de -130.850. El INE realiza un minucioso ejercicio de proyección con hipótesis basadas en los datos más recientes, tanto para los flujos de entrada como de salida. La fuerte dependencia de las últimas observaciones en esta metodología está llevando a inestabilidad en los últimos ejercicios de proyección publicados. En esta aplicación se propone la estimación de los flujos migratorios netos incorporando, además de la información más reciente como hace el INE, variables de carácter económico y social.]]></text><keywords><![CDATA[proyección demográfica, flujos migratorios, series temporales]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. I. Conde-Ruiz]]></normalized_name><name><![CDATA[J. Ignacio]]></name><lastname><![CDATA[Conde-Ruiz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[274]]></attendee_id><normalized_name><![CDATA[C. I. Gonzalez]]></normalized_name><name><![CDATA[Clara I.]]></name><lastname><![CDATA[Gonzalez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[459]]></attendee_id><normalized_name><![CDATA[E. Senra]]></normalized_name><name><![CDATA[Eva]]></name><lastname><![CDATA[Senra]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[256]]></id><title><![CDATA[Análisis de la variabilidad de la componente estacional en series afectadas por cambios estructurales.]]></title><text><![CDATA[La crisis económica iniciada en 2008 ha hecho que muchas series sufran cambios estructurales. En consecuencia, el Banco Central Europeo plantea dos opciones para desestacionalizar: el Ajuste Concurrente Parcial, en el que los efectos de la crisis son tratados como datos atípicos; y el Ajuste Concurrente Controlado, que utiliza predicciones de la estacionalidad y del efecto calendario. Recientes aplicaciones sugieren el empleo de Efectos Rampa sobre la tendencia (Maravall y Pérez, 2011), sobrentendiéndose que la estacionalidad se mantiene invariable. En este artículo se estudia la variabilidad de la componente estacional obtenida mediante modelos Reg-ARIMA en las series del Índice de Producción Industrial de Alemania, Francia, España, Reino Unido y EEUU. Los resultados indican que la estacionalidad es variable en momentos de cambios estructurales. Se concluye que el tratamiento de éstos exige la consideración de Cambios de Nivel Estacionales (Kaiser, 2000) y Efectos Rampa Estacionales.]]></text><keywords><![CDATA[modelos Reg-ARIMA, descomposición de series, datos atípicos, cambios estructurales]]></keywords><authors><element><attendee_id><![CDATA[385]]></attendee_id><normalized_name><![CDATA[N. Quintana Mazariego]]></normalized_name><name><![CDATA[Noé]]></name><lastname><![CDATA[Quintana Mazariego]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[437]]></attendee_id><normalized_name><![CDATA[J. Tejada Cazorla]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[Tejada Cazorla]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[459]]></attendee_id><normalized_name><![CDATA[E. Senra Díaz]]></normalized_name><name><![CDATA[Eva]]></name><lastname><![CDATA[Senra Díaz]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[160]]></id><title><![CDATA[Factores comunes en los precios de las materias primas e inflación en la Euro área y sus principales economías]]></title><text><![CDATA[Las fluctuaciones internacionales del precio del petróleo han sido ampliamente estudiadas como una de las principales causas de variación en las variables macroeconómicas, especialmente en el crecimiento del PIB y en la inflación. Sin embargo, los precios internacionales de otras materias primas, como las alimenticias o industriales se mueven de forma correlacionada en el corto o largo plazo, debido a que sufren presiones comunes en los mercados internacionales. En esta investigación pretendemos, a través del uso de análisis factorial dinámico, extraer el factor común que domina los precios internacionales de las materias primas a la vez que establecer los movimientos idiosincráticos de cada una de las variables. Posteriormente, con el uso de funciones de transferencia multivariadas, determinar los efectos que tienen el factor común y los elementos idiosincráticos obtenidos en diferentes niveles de agregación de la inflación (no administrada) de la euro área y sus  principales economías.]]></text><keywords><![CDATA[inflación, factor común, agregación, función de transferencia]]></keywords><authors><element><attendee_id><![CDATA[347]]></attendee_id><normalized_name><![CDATA[C. Castro Rozo]]></normalized_name><name><![CDATA[César ]]></name><lastname><![CDATA[Castro Rozo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[P. Poncela]]></normalized_name><name><![CDATA[Pilar]]></name><lastname><![CDATA[Poncela]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[67]]></id><identifier><![CDATA[JE6]]></identifier><name><![CDATA[Aplicaciones de la Investigación Operativa 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[17:00:00]]></start><end><![CDATA[18:20:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[67]]></id><normalized_name><![CDATA[C. Beltrán-Royo]]></normalized_name><name><![CDATA[César]]></name><lastname><![CDATA[Beltrán-Royo]]></lastname></chairperson><papers><element><id><![CDATA[57]]></id><title><![CDATA[Un método de asignación de tráfico que permite adelantamientos]]></title><text><![CDATA[La asignación de tráfico es un problema clásico de la ingeniería de tráfico. Conocidos los flujos de usuarios entre los pares origen-destino, se busca determinar cómo se distribuyen dichos flujos entre los arcos y rutas de la red a partir de un problema de optimización. Tradicionalmente se ha impuesto la regla FIFO, es decir, no se permiten adelantamientos. En este trabajo se elimina esta restricción considerando el caso asintótico: forzando a que bajo altas congestiones los adelantamientos sean imposibles. También se estudia el caso de vehículos que quedan afectados de forma desigual con la congestión, como es el caso de las motos. Se presentan dos problemas de asignación de tráfico equivalentes (con y sin enumeración de rutas) y se proponen dos nuevos problemas de optimización alternativos basados en las condiciones de KKT evitando la integración de las funciones de coste. Se utiliza una colección de ejemplos (incluyendo el caso de Ciudad Real) para ilustrar el método propuesto.]]></text><keywords><![CDATA[adelantamiento, equilibrio de Wardrop, enumeración de rutas, condiciones KKT, funciones BPR]]></keywords><authors><element><attendee_id><![CDATA[190]]></attendee_id><normalized_name><![CDATA[A. Calviño Martínez]]></normalized_name><name><![CDATA[Aida]]></name><lastname><![CDATA[Calviño Martínez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Castillo Ron]]></normalized_name><name><![CDATA[Enrique]]></name><lastname><![CDATA[Castillo Ron]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Sánchez-Cambronero]]></normalized_name><name><![CDATA[Santos]]></name><lastname><![CDATA[Sánchez-Cambronero]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[H. K. Lo]]></normalized_name><name><![CDATA[Hong K.]]></name><lastname><![CDATA[Lo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[11]]></id><title><![CDATA[Optimización de redes de distribución de productos de consumo masivo en condiciones de riesgo]]></title><text><![CDATA[Este paper presenta un resumen del proyecto “Modelo de diseño de redes de distribución de gran escala de productos  de consumo masivo con parámetros estocásticos”. La problemática central radica en la determinación de las decisiones de contracción de los centros de distribución de una red, teniendo en cuenta la variabilidad de la demanda. La estrategia de solución adoptada para el modelo estocástico es conocida como Sample Average Approximation (SAA). Dicha metodología utiliza un esquema de aproximación mediante Simulación Montecarlo al problema de optimización de modelos matemáticos que incluyen parámetros estocásticos. En la literatura revisada, se evidencia por primera vez la adaptación de la estrategia algorítmica SAA para la solución de un modelo de diseño de redes de gran escala para una compañía multinacional que tiene operación en Colombia. Los resultados computacionales de la implementación del SAA reflejan la importancia y eficiencia de la metodología propuesta.]]></text><keywords><![CDATA[diseño de redes de suministro, programación estocástica, simulación montecarlo, sample average approximation (SAA)]]></keywords><authors><element><attendee_id><![CDATA[89]]></attendee_id><normalized_name><![CDATA[J. W. Escobar Velasquez]]></normalized_name><name><![CDATA[John Willmer ]]></name><lastname><![CDATA[Escobar Velasquez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. J. Bravo]]></normalized_name><name><![CDATA[Juan Jose]]></name><lastname><![CDATA[Bravo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. J. Vidal]]></normalized_name><name><![CDATA[Carlos Julio]]></name><lastname><![CDATA[Vidal ]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[186]]></id><title><![CDATA[Plataforma de software para la creación de aplicaciones de decisión: IBM ILOG ODME y CPLEX]]></title><text><![CDATA[Al implementar una solución empresarial de decisión basada en técnicas analíticas, y particularmente en IO, hay tres aspectos que se han de tener en cuenta desde el inicio si se desea el éxito: la integración, la usabilidad y la evolución futura. El descuido en aspectos como la plataforma o el lenguaje, la interfaz de usuario o la flexibilidad para modificaciones futuras puede llevar a que un brillante esfuerzo de modelado sufra un fuerte rechazo por parte de los usuarios o de los responsables de tecnología, bien por incomodidades de uso o bien porque la integración con el resto del ecosistema informático no sea adecuada al estándar de la organización. Cuando se produce este tipo de rechazo, sus consecuencias llegan más allá del mero abandono del proyecto: La imagen de la disciplina analítica queda dañada, siendo tachada de oscura o marginal, y se crea desconfianza hacia las técnicas empleadas. Se pierden oportunidades reales de obtención de ahorros y de creación de nuevo valor.]]></text><keywords><![CDATA[IBM, ILOG, CPLEX, ODME, software, aplicaciones, empresa, flexibilidad, proyectos]]></keywords><authors/></element><element><id><![CDATA[159]]></id><title><![CDATA[An effective market optimization model for advertising budget allocation]]></title><text><![CDATA[Market response models allow to estimate the effect that marketing mix variables have on performance measures, such as sales or market share. Market optimization models (MOM) combine utility functions with market response models in order to find an optimal marketing mix. In this paper we present a  MOM to allocate the annual advertising budget in a multi-sage setting. We analyze the convexity properties of this (non-linear optimization) model and present some numerical examples that show the effectiveness  of the model to be used in the advertising industry.]]></text><keywords><![CDATA[non-linear optimization,  advertising budget allocation]]></keywords><authors><element><attendee_id><![CDATA[67]]></attendee_id><normalized_name><![CDATA[C. Beltrán-Royo]]></normalized_name><name><![CDATA[César]]></name><lastname><![CDATA[Beltrán-Royo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[H. Zhang]]></normalized_name><name><![CDATA[Huizhen]]></name><lastname><![CDATA[Zhang]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. A. Blanco]]></normalized_name><name><![CDATA[Luis A.]]></name><lastname><![CDATA[Blanco]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Almagro]]></normalized_name><name><![CDATA[José ]]></name><lastname><![CDATA[Almagro]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[91]]></id><identifier><![CDATA[JE7]]></identifier><name><![CDATA[Modelos de probabilidad]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[17:00:00]]></start><end><![CDATA[18:20:00]]></end><location><id><![CDATA[12]]></id><name><![CDATA[Sala Roma II]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[230]]></id><normalized_name><![CDATA[G. Mateu-Figueras]]></normalized_name><name><![CDATA[Glòria]]></name><lastname><![CDATA[Mateu-Figueras]]></lastname></chairperson><papers><element><id><![CDATA[244]]></id><title><![CDATA[Ajuste de datos bivariantes con una nueva distribución discreta.]]></title><text><![CDATA[En este trabajo, proponemos una distribución bivariante discreta cuyas marginales, a su vez, son distribuciones binomial negativas y que presenta una estructura de correlación flexible. Por tanto, la nueva distribución puede usarse para ajustar datos cuando existe sobredispersión marginal. Asimismo, se presenta el vector de medias, la matriz de covarianzas y una fórmula para el cálculo de las probabilidades multivariantes. El nuevo modelo se ha obtenido a partir de una cópula a través de la familia de distribuciones de Sarmanov. Por último, se analizan varios métodos de estimación y se realiza una aplicación en el campo de seguros de automóviles.]]></text><keywords><![CDATA[Distribución discreta bivariante, Covarianzas, Seguro de automóviles.]]></keywords><authors><element><attendee_id><![CDATA[516]]></attendee_id><normalized_name><![CDATA[E. Gómez Déniz]]></normalized_name><name><![CDATA[Emilio]]></name><lastname><![CDATA[Gómez Déniz]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[319]]></attendee_id><normalized_name><![CDATA[J. M. Pérez Sánchez]]></normalized_name><name><![CDATA[José María]]></name><lastname><![CDATA[Pérez Sánchez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Calderín Ojeda]]></normalized_name><name><![CDATA[Enrique]]></name><lastname><![CDATA[Calderín Ojeda]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[318]]></id><title><![CDATA[Sobre la Lp distancia entre una distribución de probabilidad y su distorsión]]></title><text><![CDATA[La Lp distancia entre distribuciones de probabilidad se utiliza frecuentemente en Teoría Actuarial para evaluar la calidad de una aproximación, en particular cuando el actuario reemplaza la distribución original por otra distribución más simple. En el contexto de la hipótesis de la Esperanza Distorsionada, el actuario reemplaza la distribución de probabilidad original por una probabilidad distorsionada, por lo que tiene sentido considerar la Lp distancia entre ambas. En este trabajo mostramos que dicha distancia es una característica de variabilidad de la variable asociada a la distribución original, estudiamos sus propiedades y damos algunas aplicaciones. ]]></text><keywords><![CDATA[probabilidad distorsionada, variabilidad]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. López Díaz]]></normalized_name><name><![CDATA[Miguel ]]></name><lastname><![CDATA[López Díaz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[408]]></attendee_id><normalized_name><![CDATA[M. A. Sordo Díaz]]></normalized_name><name><![CDATA[Miguel Angel]]></name><lastname><![CDATA[Sordo Díaz]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[321]]></attendee_id><normalized_name><![CDATA[A. Suárez Llorens]]></normalized_name><name><![CDATA[Alfonso]]></name><lastname><![CDATA[Suárez Llorens]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[143]]></id><title><![CDATA[La distribución Shifted-scaled Dirichlet, una generalización natural de la distribución de Dirichlet]]></title><text><![CDATA[Presentamos una generalización de la distribución de Dirichlet clásica sobre el símplex. En particular estudiamos la distribución resultado de aplicar las operaciones perturbación y potencia a una composición aleatoria con distribución de Dirichlet. Estas dos operaciones  dotan al símplex de estructura de espacio vectorial, y juegan el mismo papel que la suma y el producto por escalares en el espacio real. Se estudia la distribución resultante desde un punto de vista probabilístico, se presenta la función de densidad, se obtienen diferentes medidas características y se discute la pertenencia a una familia exponencial. Se compara la expresión de la función de densidad con respecto a la medida de Lebesgue habitual con la densidad con respecto a la medida de Aitchison en el símplex. Finalmente se revisan las distribuciones de Dirichlet y Dirichlet escalada que resultan ser casos particulares. La distribución de Dirichlet escalada se obtiene por perturbación de una densidad de Dirichlet.]]></text><keywords><![CDATA[Dirichlet, Dirichlet escalada, símplex, medida Aitchison]]></keywords><authors><element><attendee_id><![CDATA[230]]></attendee_id><normalized_name><![CDATA[G. Mateu-Figueras]]></normalized_name><name><![CDATA[Glòria]]></name><lastname><![CDATA[Mateu-Figueras]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[G. S. Monti]]></normalized_name><name><![CDATA[Gianna S.]]></name><lastname><![CDATA[Monti]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[223]]></attendee_id><normalized_name><![CDATA[V. Pawlowsky-Glahn]]></normalized_name><name><![CDATA[Vera]]></name><lastname><![CDATA[Pawlowsky-Glahn]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. J. Egozcue]]></normalized_name><name><![CDATA[Juan José]]></name><lastname><![CDATA[Egozcue]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[46]]></id><identifier><![CDATA[JF2]]></identifier><name><![CDATA[Reunión Grupo SEIO Teoría de Juegos]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[18:20:00]]></start><end><![CDATA[19:30:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[232]]></id><normalized_name><![CDATA[L. Lorenzo Picado]]></normalized_name><name><![CDATA[Leticia]]></name><lastname><![CDATA[Lorenzo Picado]]></lastname></chairperson><papers/></element><element><id><![CDATA[60]]></id><identifier><![CDATA[JF3]]></identifier><name><![CDATA[Reunión Grupo SEIO Clasificación y Análisis Multivariante]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[18:20:00]]></start><end><![CDATA[19:30:00]]></end><location><id><![CDATA[8]]></id><name><![CDATA[Sala Londres]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[233]]></id><normalized_name><![CDATA[C. M. Cuadras Avellanas]]></normalized_name><name><![CDATA[Carles M]]></name><lastname><![CDATA[Cuadras Avellanas]]></lastname></chairperson><papers/></element><element><id><![CDATA[55]]></id><identifier><![CDATA[JF4]]></identifier><name><![CDATA[Reunión Grupo SEIO Localización]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[18:20:00]]></start><end><![CDATA[19:30:00]]></end><location><id><![CDATA[9]]></id><name><![CDATA[Sala París]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[135]]></id><normalized_name><![CDATA[J. A. Mesa López-Colmenar]]></normalized_name><name><![CDATA[Juan Antonio]]></name><lastname><![CDATA[Mesa López-Colmenar]]></lastname></chairperson><papers/></element><element><id><![CDATA[129]]></id><identifier><![CDATA[JF5]]></identifier><name><![CDATA[Reunión Consejo Editorial TEST]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[18:20:00]]></start><end><![CDATA[19:30:00]]></end><location><id><![CDATA[10]]></id><name><![CDATA[Sala Viena]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[159]]></id><normalized_name><![CDATA[D. Morales González]]></normalized_name><name><![CDATA[Domingo]]></name><lastname><![CDATA[Morales González]]></lastname></chairperson><papers/></element><element><id><![CDATA[125]]></id><identifier><![CDATA[JG2]]></identifier><name><![CDATA[Reunión Coordinadores Grupos de Trabajo SEIO]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[19:30:00]]></start><end><![CDATA[20:00:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[134]]></id><identifier><![CDATA[JG6]]></identifier><name><![CDATA[Reunión Consejo Editorial BEIO]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[19:30:00]]></start><end><![CDATA[20:00:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[129]]></id><normalized_name><![CDATA[M. D. C. Pardo Llorente]]></normalized_name><name><![CDATA[Maria del Carmen]]></name><lastname><![CDATA[Pardo Llorente]]></lastname></chairperson><papers/></element></sessions></element><element><date><![CDATA[2012-04-20]]></date><papers/><sessions><element><id><![CDATA[26]]></id><identifier><![CDATA[VA1]]></identifier><name><![CDATA[JEP-Investigación metodológica en estadística pública 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[364]]></id><normalized_name><![CDATA[J. Orche Galindo]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Orche Galindo]]></lastname></chairperson><papers><element><id><![CDATA[278]]></id><title><![CDATA[Desagregación de la población mediante técnicas de programación matemática]]></title><text><![CDATA[En España, como en otros países de nuestro entorno, las series de valores de la población por sexo y edad están disponibles a partir de distintas operaciones estadísticas, pudiendo presentar distintos niveles de desagregación la variable edad. Disponer de datos de población desagregados por edad simple es una necesidad en la Estadística Pública, motivada por el cálculo de indicadores demográficos, cifras de población extranjera desagregada por edad simple, etc. En este trabajo presentamos una solución novedosa que da respuesta a esta necesidad. La desagregación de los datos de población se llevará a cabo usando técnicas de Programación Matemática, que permitirán obtener, a partir de la resolución de problemas de optimización convenientemente formulados, un reparto poblacional coherente con la información agrupada de la que se dispone, y que proporcione transiciones suaves entre edades consecutivas, tanto dentro del mismo año de calendario como entre años consecutivos.]]></text><keywords><![CDATA[población, edad simple, desagregación, programación matemática]]></keywords><authors><element><attendee_id><![CDATA[456]]></attendee_id><normalized_name><![CDATA[S. Bermúdez]]></normalized_name><name><![CDATA[Silvia]]></name><lastname><![CDATA[Bermúdez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[435]]></attendee_id><normalized_name><![CDATA[R. Blanquero Bravo]]></normalized_name><name><![CDATA[Rafael]]></name><lastname><![CDATA[Blanquero Bravo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[222]]></id><title><![CDATA[Depuración selectiva como un problema de optimización combinatoria]]></title><text><![CDATA[La depuración de datos es una etapa crucial en la producción de encuestas por muestreo. La depuración selectiva es una modalidad que surgió en los años 90 con el objetivo de optimizar recursos priorizando los cuestionarios cuyo error a priori presenta mayor impacto en las estimaciones. Presentamos una formalización de la depuración selectiva como un problema de optimización combinatoria que persigue minimizar los costes de depuración en términos del número de cuestionarios a depurar manteniendo el control sobre la acuracidad de las estimaciones. El problema resultante tiene una función objetivo lineal y restricciones cuadráticas. Proporcionamos un algoritmo voraz para la resolución del problema y discutimos brevemente su aplicación en la producción de estadísticas oficiales.]]></text><keywords><![CDATA[depuración selectiva, optimización combinatoria]]></keywords><authors><element><attendee_id><![CDATA[410]]></attendee_id><normalized_name><![CDATA[I. Arbués Lombardía]]></normalized_name><name><![CDATA[Ignacio]]></name><lastname><![CDATA[Arbués Lombardía]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. E. Esteban Segurado]]></normalized_name><name><![CDATA[M. Elisa ]]></name><lastname><![CDATA[Esteban Segurado]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[221]]></id><title><![CDATA[Contrastes de capacidad predictiva para comparar dos conjuntos de modelos]]></title><text><![CDATA[Hay dos contrastes muy conocidos para comparar la capacidad predictiva de un conjunto de modelos con uno de referencia: el Reality Check de White (2000) y el test de Capacidad Predictiva Superior de Hansen (2005). Aquí generalizamos estos contrastes para el caso en el que se comparan dos conjuntos de modelos. Comprobamos mediante simulación que la generalización del contraste de Hansen es más potente que la del de White. Estos contrastes se pueden usar para detectar causalidad de Granger. Para contrastar si X causa Y, tomamos el conjunto de modelos que no usan X para predecir Y y lo comparamos con los que sí emplean X. La hipótesis nula es que el mejor modelo del primer conjunto es al menos tan bueno para predecir como el mejor del segundo. Aplicamos esto a las relaciones entre el desempleo y la inflación y entre los pedidos industriales y la producción. Así vemos que el contraste de Hansen generalizado indica causalidad para los datos de EEUU, pero no para Francia y España.]]></text><keywords><![CDATA[series temporales, contrastes de capacidad predictiva, bootstrap]]></keywords><authors><element><attendee_id><![CDATA[410]]></attendee_id><normalized_name><![CDATA[I. Arbués Lombardía]]></normalized_name><name><![CDATA[Ignacio]]></name><lastname><![CDATA[Arbués Lombardía]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Casaseca Polo]]></normalized_name><name><![CDATA[Cristina]]></name><lastname><![CDATA[Casaseca Polo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Ledo Arias]]></normalized_name><name><![CDATA[Ramiro]]></name><lastname><![CDATA[Ledo Arias]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Rama García]]></normalized_name><name><![CDATA[Silvia]]></name><lastname><![CDATA[Rama García]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[219]]></id><title><![CDATA[Proyecciones de tasas de actividad (TdAs). Metodología del INE]]></title><text><![CDATA[Las proyecciones de tasas de actividad (TdAs) parten del análisis de las series históricas en la EPA y de las proyecciones de población. Las TdAs se ajustan para que sean homogéneas en el tiempo y tengan la misma fecha que las proyecciones de población; y éstas se han adecuado al ámbito poblacional de la EPA y al periodo de proyección para las TdAs. La  proyecciones de las TdAs por grupos de edad, sexo y comunidad autónoma se hace mediante el ajuste de una función logística con un componente autorregresivo de orden determinado automáticamente “paso a paso” y una tendencia estimada por MCO. Las proyecciones en los grupos anteriores se agregan para obtener TdAs generales, siendo aquellas ponderadas por las proyecciones de población ajustadas. Con este método ascendente se podrán captar las tendencias demográficas subyacentes en las proyecciones de población en cuanto a la estructura de la población y analizar la sensibilidad de las TdAs proyectadas a diferentes estructuras demográficas.]]></text><keywords><![CDATA[proyecciones de tasas de actividad, TdAs, encuesta de población activa, EPA, proyecciones de población, modelización matemática, previsiones futuras sociales y económicas]]></keywords><authors/></element></papers></element><element><id><![CDATA[62]]></id><identifier><![CDATA[VA2]]></identifier><name><![CDATA[Teoría de juegos 3]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[61]]></id><normalized_name><![CDATA[I. Garcia Jurado]]></normalized_name><name><![CDATA[Ignacio]]></name><lastname><![CDATA[Garcia Jurado]]></lastname></chairperson><papers><element><id><![CDATA[195]]></id><title><![CDATA[El valor coalicional proporcional de Shapley para juegos con comunicación restringida]]></title><text><![CDATA[En este trabajo se considera la familia de juegos monótonos con uniones a priori en los que la cooperación entre los jugadores está restringida por un grafo de comunicación. Las componentes conexas del grafo de comunicación forman una nueva partición del conjunto de jugadores. Para esta familia de juegos se define y caracteriza axiomáticamente una solución que propone un reparto de la utilidad disponible que tiene en cuenta la función característica del juego, las uniones a priori y el grafo de comunicación. Esta solución coincide con el valor proporcional coalicional de Shapley cuando el grafo de comunicación es completo, es decir, todos los jugadores pueden comunicarse directamente, y con el valor de Myerson cuando la estructura de uniones a priori es la trivial, es decir, cada unión está constituida por un único jugador.]]></text><keywords><![CDATA[juegos cooperativos, uniones a priori, grafo de comunicación, valor coalicional proporcional de Shapley]]></keywords><authors><element><attendee_id><![CDATA[258]]></attendee_id><normalized_name><![CDATA[J. M. Alonso Meijide]]></normalized_name><name><![CDATA[José Mª.]]></name><lastname><![CDATA[Alonso Meijide]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[134]]></attendee_id><normalized_name><![CDATA[F. Carreras Escobar]]></normalized_name><name><![CDATA[Francesc]]></name><lastname><![CDATA[Carreras Escobar]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[245]]></attendee_id><normalized_name><![CDATA[J. Costa Bouzas]]></normalized_name><name><![CDATA[Julián]]></name><lastname><![CDATA[Costa Bouzas]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[61]]></attendee_id><normalized_name><![CDATA[I. Garcia Jurado]]></normalized_name><name><![CDATA[Ignacio]]></name><lastname><![CDATA[Garcia Jurado]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[127]]></id><title><![CDATA[Una expresión polinómica del valor de Owen en el juego de mantenimiento]]></title><text><![CDATA[Los juegos de mantenimiento son una clase de juegos cooperativos con utilidad transferible en los que el objetivo consiste en repartir los costes de mantenimiento de una instalación entre los agentes. En este trabajo proponemos el uso del valor de Owen para la asignación de costes en los juegos de mantenimiento con un sistema de uniones a priori y presentamos una expresión polinómica del mismo.]]></text><keywords><![CDATA[juego cooperativo, juego de mantenimiento, valor de Owen]]></keywords><authors/></element><element><id><![CDATA[91]]></id><title><![CDATA[Un valor para juegos con cotas optimistas]]></title><text><![CDATA[Un juego con cotas optimistas describe una situación cooperativa en la que resulta natural asociar a cada coalición los beneficios que puede generar por sí misma y, también, una cota superior de los beneficios que puede llegar a obtener. En este trabajo, además de presentar este modelo y de justificar su relevancia, proponemos un valor para juegos con cotas optimistas que extiende el valor de Shapley a este contexto. También obtenemos dos caracterizaciones axiomáticas del nuevo valor.]]></text><keywords><![CDATA[juegos cooperativos, valor de Shapley, cotas optimistas]]></keywords><authors><element><attendee_id><![CDATA[313]]></attendee_id><normalized_name><![CDATA[L. Carpente]]></normalized_name><name><![CDATA[Luisa]]></name><lastname><![CDATA[Carpente]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[B. Casas Méndez]]></normalized_name><name><![CDATA[Balbina]]></name><lastname><![CDATA[Casas Méndez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[61]]></attendee_id><normalized_name><![CDATA[I. Garcia Jurado]]></normalized_name><name><![CDATA[Ignacio]]></name><lastname><![CDATA[Garcia Jurado]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. van den Nouweland]]></normalized_name><name><![CDATA[Anne]]></name><lastname><![CDATA[van den Nouweland]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[116]]></id><identifier><![CDATA[VA3]]></identifier><name><![CDATA[Clasificación y análisis multivariante 4]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[8]]></id><name><![CDATA[Sala Londres]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[323]]></id><normalized_name><![CDATA[J. M. Gutierrez Pérez]]></normalized_name><name><![CDATA[José María]]></name><lastname><![CDATA[Gutierrez Pérez]]></lastname></chairperson><papers><element><id><![CDATA[182]]></id><title><![CDATA[Manova desde una perspectiva composicional: resultados preliminares]]></title><text><![CDATA[El símplex es el espacio muestral de los datos composicionales, datos que expresan las proporciones de las partes respecto a un todo. Es conocido que el símplex tiene estructura de espacio vectorial euclidiano, con unas operaciones propias y diferentes a las del espacio real. Esta estructura permite aplicar cualquier técnica estadística a las coordenadas de las composiciones respecto a una base ortonormal del símplex. El hecho de trabajar en coordenadas puede dificultar la interpretación de los resultados obtenidos e implica una profunda revisión de la técnica. Motivado por su aplicación a estudios medioambientales, en este trabajo nos planteamos la revisión de las técnicas MANOVA y los contrastes post-hoc para datos composicionales. En particular se analizará la independencia con respecto a la base ortonormal elegida comparándola con el uso de  las transformaciones logcocientes y la preservación de los principios composicionales:  invariancia escalar y coherencia subcomposicional.]]></text><keywords><![CDATA[Manova, simplex, logcociente, composicional]]></keywords><authors><element><attendee_id><![CDATA[278]]></attendee_id><normalized_name><![CDATA[J. Daunis-i-Estadella]]></normalized_name><name><![CDATA[Josep]]></name><lastname><![CDATA[Daunis-i-Estadella]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[246]]></attendee_id><normalized_name><![CDATA[J. A. Martín Fernández]]></normalized_name><name><![CDATA[Josep Antoni]]></name><lastname><![CDATA[Martín Fernández]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[G. Mateu-Figueras]]></normalized_name><name><![CDATA[Glòria]]></name><lastname><![CDATA[Mateu-Figueras]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[71]]></id><title><![CDATA[Mammal milk composition data analysis: fuzzy clustering approach on vectors of coordinates]]></title><text><![CDATA[A widely-used data set from Hartigan (1975) describes the percentage composition of 24 mammals' milk on the basis of 5 different constituents (water, protein, fat, lactose and ash). A 4-group solution has been usually considered as the optimal grouping of such data. Like most clustering techniques, the Fuzzy C-Means (FCM) algorithm is based upon a distance measure between objects. An appropriate distance between compositions should fulfill two main principles: scale invariance and subcompositional coherence. The Aitchison distance, which satisfies both principles, is equivalent to the usual Euclidean distance applied on coordinates of an orthonormal basis on the simplex. Note that the adequate metric is defined through log-ratio transformations and defines what is called the Aitchison geometry on the simplex. The FCM algorithm is applied on vectors of coordinates and the results suggest a grouping consistent with previous results, whilst particular features are now pointed out.]]></text><keywords><![CDATA[fuzzy, log-ratio, simplex, distance]]></keywords><authors><element><attendee_id><![CDATA[246]]></attendee_id><normalized_name><![CDATA[J. A. Martín Fernández]]></normalized_name><name><![CDATA[Josep Antoni]]></name><lastname><![CDATA[Martín Fernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Palarea Albaladejo]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Palarea Albaladejo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. A. Soto]]></normalized_name><name><![CDATA[Jesús A.]]></name><lastname><![CDATA[Soto]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[144]]></id><title><![CDATA[Modelos multivariantes de credit scoring, acordes con Basilea II]]></title><text><![CDATA[Se presenta un marco general unificado de la  mayoría de los modelos más actuales utilizados en  credit scoring,  LOGIT, PROBIT,  TREE, MARS, ANN, K-NN,  SVM,  etc., formalizando sus estructuras funcionales como expansión de base de las variables explicativas del riesgo de crédito.   Se  presentan los Modelos Logísticos Lineales Híbridos, HLLM, que permiten caracterizar la no linealidad de las variables explicativas, expandiendo la componente no lineal de Modelos Logísticos Parcialmente Lineales, LPLM, a través de combinaciones lineales de funciones de base especificas, para cada variable no lineal. Se prueba que estos modelos presentan mejor rendimiento discriminante, curvas ROC y áreas bajo la curva, AUC, y menor tasa de clasificación incorrecta, desde la óptica IRB de Basilea II,  que  las técnicas más utilizadas en los sistemas de calificación del riesgo de crédito, que contemplan la no linealidad, TREE, ANN, k-NN  y SVM. ]]></text><keywords><![CDATA[credit scoring,  probabilidad de default, modelos logísticos lineales híbridos]]></keywords><authors><element><attendee_id><![CDATA[271]]></attendee_id><normalized_name><![CDATA[F. Mallo Fernández]]></normalized_name><name><![CDATA[Fernando]]></name><lastname><![CDATA[Mallo Fernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[P. Galindo Villardón]]></normalized_name><name><![CDATA[Purificación]]></name><lastname><![CDATA[Galindo Villardón]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[171]]></id><title><![CDATA[Componentes de influencia y sus aplicaciones a la clasificación]]></title><text><![CDATA[El presente estudio plantea una generalización de la matriz de covarianza asociada a muestras supervisadas que denominamos Matriz de Dispersión Inducida. La descomposición espectral de dicha matriz es local a cada punto del espacio y  encuadra el Analisis de Componentes Principales clásico  dentro del caso particular de existencia de un único grupo.]]></text><keywords><![CDATA[componentes principales, componentes de influencia, matriz de covarianza]]></keywords><authors><element><attendee_id><![CDATA[323]]></attendee_id><normalized_name><![CDATA[J. M. Gutierrez Pérez]]></normalized_name><name><![CDATA[José María]]></name><lastname><![CDATA[Gutierrez Pérez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[104]]></attendee_id><normalized_name><![CDATA[A. Jimenez Jimenez]]></normalized_name><name><![CDATA[Andres]]></name><lastname><![CDATA[Jimenez Jimenez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Alvarez Gonzalez]]></normalized_name><name><![CDATA[Francisco]]></name><lastname><![CDATA[Alvarez Gonzalez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[81]]></id><identifier><![CDATA[VA4]]></identifier><name><![CDATA[Problemas de localización 3]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[9]]></id><name><![CDATA[Sala París]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[365]]></id><normalized_name><![CDATA[B. Pelegrin Pelegrin]]></normalized_name><name><![CDATA[Blas]]></name><lastname><![CDATA[Pelegrin Pelegrin]]></lastname></chairperson><papers><element><id><![CDATA[255]]></id><title><![CDATA[Optimización global continua en problemas de localización sobre redes]]></title><text><![CDATA[En algunos de los problemas de localización sobre redes más conocidos es posible identificar un conjunto dominante finito, por lo que su resolución se reduce a la enumeración (implícita) de un conjunto finito de puntos candidatos. En este trabajo se abordan problemas de localización sobre redes que parecen no poseer la propiedad anterior, requiriendo, por tanto, el empleo de herramientas de optimización continua para su resolución. En concreto, se consideran  problemas de localización competitiva (tipo Huff) y problemas de la mediana con demanda distribuida de forma continua sobre los arcos de la red. En ambos casos, el problema de optimización no lineal resultante puede ser escrito como un problema DC (diferencia de convexas) sobre cada arco, lo que permite diseñar un algoritmo de ramificación y acotación para la obtención de una solución óptima global. La experiencia computacional que se presenta muestra que la estrategia propuesta es adecuada sobre redes de tamaño razonable.]]></text><keywords><![CDATA[localización en redes, optimización global, optimización DC]]></keywords><authors><element><attendee_id><![CDATA[435]]></attendee_id><normalized_name><![CDATA[R. Blanquero Bravo]]></normalized_name><name><![CDATA[Rafael]]></name><lastname><![CDATA[Blanquero Bravo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[299]]></attendee_id><normalized_name><![CDATA[E. Carrizosa]]></normalized_name><name><![CDATA[Emilio]]></name><lastname><![CDATA[Carrizosa]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Nogales Gómez]]></normalized_name><name><![CDATA[Amaya]]></name><lastname><![CDATA[Nogales Gómez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Plastria]]></normalized_name><name><![CDATA[Frank]]></name><lastname><![CDATA[Plastria]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[289]]></id><title><![CDATA[Un estudio empírico de la existencia de empates con la regla de elección binaria en problemas de localización competitiva]]></title><text><![CDATA[Consideramos un modelo de localización competitiva donde los consumidores están concentrados en puntos, la demanda es inelástica y conocida, la regla de elección de los consumidores es binaria, y donde una nueva firma quiere abrir nuevos centros con el fin de maximizar su cuota de mercado. Se utiliza una función para medir la valoración de cada centro por los consumidores. Si para ciertos consumidors hay un único centro con máxima valoración, dicho centro satisfará toda su demanda. Pero si hay más de un centro con máxima valoración, ¿cuál sirve la demanda de esos consumidores? La respuesta condiciona la formulación del modelo y a su solución óptima. Si hay empates, cada uno de estos centros capturará parte de la demanda, pero ¿qué cantidad? Aquí tratamos de forma empírica de dar respuesta a la pregunta: ¿ocurren con frecuencia los casos de empate? El estudio ha sido realizado sobre datos reales de municipios de España, utilizando la distancia como función para valorar cada centro.]]></text><keywords><![CDATA[localización competitiva, regla de elección binaria]]></keywords><authors><element><attendee_id><![CDATA[460]]></attendee_id><normalized_name><![CDATA[P. Fernández Hernández]]></normalized_name><name><![CDATA[Pascual]]></name><lastname><![CDATA[Fernández Hernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[365]]></attendee_id><normalized_name><![CDATA[B. Pelegrin Pelegrin]]></normalized_name><name><![CDATA[Blas]]></name><lastname><![CDATA[Pelegrin Pelegrin]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[323]]></id><title><![CDATA[Localización de un centro de servicios en dos regiones con normas l1 y l2 usando puertas de acceso (Gates)]]></title><text><![CDATA[Proponemos en este trabajo una modificación al algoritmo presentado por Brimberg (2003) para la obtención de un centro que da servicios a dos regiones separadas por una línea recta. Suponemos que las regiones tienen las normas y, respectivamente. Ilustramos el trabajo con una comparativa entre el algoritmo modificado, utilizando el concepto de Gate, y el propuesto por Brimberg]]></text><keywords><![CDATA[localización continua, gates, localización simple]]></keywords><authors><element><attendee_id><![CDATA[495]]></attendee_id><normalized_name><![CDATA[F. Velasco Morente]]></normalized_name><name><![CDATA[Francisco]]></name><lastname><![CDATA[Velasco Morente]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[498]]></attendee_id><normalized_name><![CDATA[L. Franco Martín]]></normalized_name><name><![CDATA[Luis]]></name><lastname><![CDATA[Franco Martín]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. González Abril]]></normalized_name><name><![CDATA[Luis]]></name><lastname><![CDATA[González Abril]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[315]]></id><title><![CDATA[Localización con el criterio de cobertura de viajes en redes tipo árbol]]></title><text><![CDATA[En este trabajo se considera un problema de localización en un espacio mixto plano-red,  en el que viajar a través de la red es más rápido que a través del plano con la distancia euclídea. El objetivo es el de localizar puntos de acceso sobre la red tipo árbol de forma que se maximice el número de usuarios que utilizan la misma. En el caso de que se localicen dos puntos sobre la red se deduce un conjunto dominante finito y se diseña  un algoritmo polinomial. En el caso de localización de más de dos puntos se sugiere un algoritmo de ramificación y acotación geométrico que es evaluado numéricamente.]]></text><keywords><![CDATA[localización, cobertura, ]]></keywords><authors><element><attendee_id><![CDATA[135]]></attendee_id><normalized_name><![CDATA[J. A. Mesa López-Colmenar]]></normalized_name><name><![CDATA[Juan Antonio]]></name><lastname><![CDATA[Mesa López-Colmenar]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Körner]]></normalized_name><name><![CDATA[Mark-Christoph ]]></name><lastname><![CDATA[Körner]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[161]]></attendee_id><normalized_name><![CDATA[F. Perea Rojas-Marcos]]></normalized_name><name><![CDATA[Federico]]></name><lastname><![CDATA[Perea Rojas-Marcos]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Schöbel]]></normalized_name><name><![CDATA[Anita]]></name><lastname><![CDATA[Schöbel]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[D. Scholz]]></normalized_name><name><![CDATA[Daniel]]></name><lastname><![CDATA[Scholz]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[95]]></id><identifier><![CDATA[VA5]]></identifier><name><![CDATA[Distribuciones estadísticas 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[10]]></id><name><![CDATA[Sala Viena]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[372]]></id><normalized_name><![CDATA[M. Perez Casany]]></normalized_name><name><![CDATA[Marta]]></name><lastname><![CDATA[Perez Casany]]></lastname></chairperson><papers><element><id><![CDATA[241]]></id><title><![CDATA[Estimación de parámetros en mixturas de polinomios mediante mínimos cuadrados]]></title><text><![CDATA[Las redes bayesianas híbridas constituyen una herramienta destacada para el manejo de distribuciones conjuntas sobre variables discretas y continuas simultáneamente. Uno de los modelos más generales en este contexto es el basado en las llamadas Mixturas de Funciones Base Truncadas, casos particulares del cuál son las Mixturas de Exponenciales Truncadas (MTEs) y las Mixturas de Polinomios (MOPs). En este caso presentamos un algoritmo iterativo basado en mínimos cuadrados para estimar los parámetros de una MOPs. El método es una extensión del existente para MTEs. Se presentan los resultados de una evaluación experimental del método propuesto, usando una implementación en lenguaje R.]]></text><keywords><![CDATA[mixturas de polinomios, mínimos cuadrados, redes bayesianas]]></keywords><authors/></element><element><id><![CDATA[217]]></id><title><![CDATA[Particiones, recortes y similaridad de distribuciones]]></title><text><![CDATA[Dos distribuciones de probabilidad, $P1$ y $P2$, son similares a un determinado nivel $\alpha$ $(0\leq \alpha \leq1)$, si ambas pueden considerarse como contaminaciones de cierta probabilidad $P0: P1=(1-\alpha)P0+\alpha Q1$ y $P2=(1-\alpha)P0+\alpha Q2$ para algunas probabilidades $Q1$ y $Q2$ arbitrarias. En la exposición analizaremos, en términos muestrales, la similaridad de probabilidades recurriendo a recortes de las muestras. En particular obtendremos tasas de convergencia vinculadas al sobreajuste que se observa al recortar una muestra de forma óptima respecto a diferentes métricas probabilísticas. Los resultados se basan en la consideración de particiones adecuadas del espacio, que permiten recurrir a argumentos de colocación aleatoria de bolas en urnas.]]></text><keywords><![CDATA[similaridad, bondad de ajuste, métricas probabilísticas, recortes, tasas de convergencia, sobreajuste]]></keywords><authors><element><attendee_id><![CDATA[512]]></attendee_id><normalized_name><![CDATA[E. del Barrio Tellado]]></normalized_name><name><![CDATA[Eustasio]]></name><lastname><![CDATA[del Barrio Tellado]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[245]]></id><title><![CDATA[Caracterización de las distribuciones Poisson-stopped-sum que son Mixed Poisson]]></title><text><![CDATA[Entre las alternativas a la distribución de Poisson  más utilizadas se encuentran las mixturas Poisson (MP) y las Poisson-stopped-sum (PSS). En Maceda (1948)  se caracterizan las distribuciones que pertenecen a ambas famílias en función de las propiedades de la distribución mixtura utilizada al definir la MP. En este trabajo, se caracteriza el  mismo conjunto de distribuciones pero en base a  las propiedades de la distribución de la variable que se suma en el proceso de obtención de la PSS, conocida como segunda distribución. En particular se demuestra que cuando la segunda distribución de la PSS es mixed Poisson, la distribución resultante es también MP, pero que ésta no es una condición necesaria. El trabajo concluye con la clasificación de algunas distribuciones clásicas importantes como la Poisson, la Binomial Negativa, la Hermite o la Tweedie-Poisson  en base a si son sólo MP, sólo PSS o ambas cosas.]]></text><keywords><![CDATA[mixtura Poisson, Poisson-stopped-sum, truncamiento en el cero]]></keywords><authors><element><attendee_id><![CDATA[372]]></attendee_id><normalized_name><![CDATA[M. Perez Casany]]></normalized_name><name><![CDATA[Marta]]></name><lastname><![CDATA[Perez Casany]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Valero]]></normalized_name><name><![CDATA[Jordi]]></name><lastname><![CDATA[Valero]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Ginebra]]></normalized_name><name><![CDATA[Josep]]></name><lastname><![CDATA[Ginebra]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[30]]></id><identifier><![CDATA[VA6]]></identifier><name><![CDATA[Inferencia estadística]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[101]]></id><normalized_name><![CDATA[F. Lucambio Pérez]]></normalized_name><name><![CDATA[Fernando]]></name><lastname><![CDATA[Lucambio Pérez]]></lastname></chairperson><papers><element><id><![CDATA[30]]></id><title><![CDATA[Potencia frente a robustez en tests de hipótesis robustos]]></title><text><![CDATA[En Inferencia Estadística Robusta es habitual establecer un equilibrio entre la potencia y la robustez puesto que una aumenta a costa de disminuir la otra. Este equilibrio se expresa a través de algunos parámetros tales como la ``trimming fraction'' (cuando se utiliza la media recortada), o a través de la ``tuning constant'' (cuando se basan en el estimador de Huber). En esta comunicación se propone determinar objetivamente este parámetro de equilibrio mediante la ``p-value line'' ya que esta función recoge ambos elementos de decisión: la potencia del test y su sensibilidad. Se obtiene resultados primero para tests de localización robustos y luego para Modelos Lineales Generalizados (GLM) Robustos y Modelos Aditivos Generalizados (GAM) Robustos. La ``p-value line'' es calculada mediante el desarrollo von Mises del funcional ``Probabilidad Cola'', siguiendo argumentos semejantes a los del artículo: ``A linear approximation to the power function of a test'', García-Pérez, 2012, Metrika.]]></text><keywords><![CDATA[robustez]]></keywords><authors><element><attendee_id><![CDATA[123]]></attendee_id><normalized_name><![CDATA[A. García Pérez]]></normalized_name><name><![CDATA[Alfonso]]></name><lastname><![CDATA[García Pérez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Lorenzo Bermejo]]></normalized_name><name><![CDATA[Justo]]></name><lastname><![CDATA[Lorenzo Bermejo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[286]]></id><title><![CDATA[Inferencia basada en la función de verosimilitud para datos censurados]]></title><text><![CDATA[En este trabajo realizamos una revisión de los diversos métodos de inferencia que existen en la literatura para tratar con datos continuos de tiempos de vida. Recogemos así diversos mecanismos de censura por la derecha, que nos conducirán a distintas funciones de verosimilitud, cuyas propiedades estudiamos. Utilizaremos modelos paramétricos, tales como la distribución exponencial, Weibull, distribución de valores extremos, y distribución logaritmo normal. En ellos consideramos el problema de la estimación de los parámetros del modelo, y de distintas funciones paramétricas de interés como la función de supervivencia y cuantiles. Se incluyen ejemplos numéricos para ilustrar la ejecución y aplicabilidad de los resultados propuestos.]]></text><keywords><![CDATA[datos censurados, modelos de tiempo de vida, inferencia basada en la verosimilitud]]></keywords><authors><element><attendee_id><![CDATA[355]]></attendee_id><normalized_name><![CDATA[I. Barranco Chamorro]]></normalized_name><name><![CDATA[Inmaculada]]></name><lastname><![CDATA[Barranco Chamorro]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Osorio Baeza]]></normalized_name><name><![CDATA[Florencia]]></name><lastname><![CDATA[Osorio Baeza]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. D. Jiménez Gamero]]></normalized_name><name><![CDATA[María Dolores]]></name><lastname><![CDATA[Jiménez Gamero]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[14]]></id><title><![CDATA[Regiones de predicción mejoradas en modelos de regresión simétricos]]></title><text><![CDATA[Recientemente diversos trabajos tratan sobre intervalos de predicción en modelos paramétricos, el objetivo de esos trabajos es el mejoramiento del limite de predicción para nuevas observaciones. Una de las ideas en ese sentido es presentada en Vidoni (1998), posteriormente extendida a los modelos lineares generalizados. Esa propuesta solamente funciona en el caso de dimensión uno. Por otro lado, Barndorff-Nielsen and Cox (1996) utilizaron teoría asintótica con el mismo objetivo y obtuvieron un resultado posteriormente extendido por Corcuera and Giummolè (2006) al caso  multidimensional. En este trabajo utilizaremos el resultado en Corcuera and Giummolè (2006) para encontrar regiones de predicción mejoradas en modelos de regresión simétricos y mostraremos, a través de ejemplos, que la solución propuesta es una mejoria con relación al procedimiento padrón.]]></text><keywords><![CDATA[probabilidad de cobertura, regiones de predicción, modelos de regresión simétricos]]></keywords><authors/></element></papers></element><element><id><![CDATA[86]]></id><identifier><![CDATA[VA7]]></identifier><name><![CDATA[Estadística no paramétrica]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:00:00]]></start><end><![CDATA[10:20:00]]></end><location><id><![CDATA[12]]></id><name><![CDATA[Sala Roma II]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[212]]></id><normalized_name><![CDATA[E. García-Portugués]]></normalized_name><name><![CDATA[Eduardo]]></name><lastname><![CDATA[García-Portugués]]></lastname></chairperson><papers><element><id><![CDATA[129]]></id><title><![CDATA[Análisis de similaridad de k muestras]]></title><text><![CDATA[Consideramos un problema de k muestras $(k>2)$, dónde estamos interesados en identificar aquellas que se desvían de un patrón común formado por la mayoría de muestras. Este patrón estaría formado por componentes de las muestras con cierto grado interno de similaridad. Esta clase de problemas son de interés en múltiples situaciones. P.e., supongamos una empresa con diferentes plantas cada una con sus proveedores para los diversos componentes, que ``ensamblados'' forman el producto final. Nuestro interés estará en analizar si hay plantas cuya calidad de producción se desvíe de forma significativa del resto. En este caso la H0 de homogeneidad resulta demasiado fuerte, siendo más realista la de similaridad. Presentamos un procedimiento estadístico para detectar las muestras que son significativamente menos similares con respecto a una versión combinada de las otras. Para ello utilizamos una métrica probabilística, un procedimiento bootstrap y un algoritmo de tipo stepwise-backward. ]]></text><keywords><![CDATA[similaridad, distribuciones recortadas, recortes imparciales, métrica de Wasserstein, bootstrap]]></keywords><authors/></element><element><id><![CDATA[39]]></id><title><![CDATA[Bandwidth selection for mean shift clustering]]></title><text><![CDATA[The mean shift algorithm was introduced in Fukunaga and Hostetler (1975). It is an iterative procedure which, at every step, shifts the point obtained in the previous iteration in the direction of the estimated normalized density gradient, producing a convergent sequence that transports the initial value to the closest local maximum of the density estimate along the steepest ascent path. This algorithm induces a partition of the data in a natural way, by assigning the same cluster to all the data points that lead to the same local maximum when the convergence of the iterative procedure is reached. Notice that this methodology does not require the number of clusters to be specified in advance, and that it allows clusters of arbitrary shape to be discovered. In this communication we study the properties of this algorithm when kernel methods are used to estimate the normalized density gradient, and propose several data-driven bandwidth selectors to make this methodology fully automatic.]]></text><keywords><![CDATA[bandwidth selection, mean shift clustering, kernel methods, density gradient estimation]]></keywords><authors/></element><element><id><![CDATA[67]]></id><title><![CDATA[Directional-linear kernel density estimator]]></title><text><![CDATA[Directional statistics deal with data lying on the $q$-dimensional sphere $\Omega_q=\{\mathbf{x}\in\mathbb{R}^{q+1}:|\mathbf{x}|=1\}$, with the most common cases corresponding to the circle ($q=1$) and the sphere ($q=2$). In many applied fields, it may be interesting to assess the relation between directional and linear random variables. For instance, in environmental protection, pollutants concentration and wind direction joint structure may be used to detect emission sources. In this work, an estimator for the joint density of a directional-linear random variable $(\mathbf{X},Z)$ with support in $\Omega_q\times\mathbb{R}$ is proposed. This estimator is based on a directional-linear kernel product and expressions for bias, variance and MSE are derived. Optimal smoothing parameters in terms of the AMISE criterion is also provided. The finite sample properties of the estimator are explored throughout a simulation study. Finally, the estimator is illustrated with real data examples.]]></text><keywords><![CDATA[directional-linear, circular-linear, directional data, circular data, kernel density estimation]]></keywords><authors><element><attendee_id><![CDATA[212]]></attendee_id><normalized_name><![CDATA[E. García-Portugués]]></normalized_name><name><![CDATA[Eduardo]]></name><lastname><![CDATA[García-Portugués]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[217]]></attendee_id><normalized_name><![CDATA[R. Crujeiras Casais]]></normalized_name><name><![CDATA[Rosa ]]></name><lastname><![CDATA[Crujeiras Casais]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[449]]></attendee_id><normalized_name><![CDATA[W. González-Manteiga]]></normalized_name><name><![CDATA[Wenceslao]]></name><lastname><![CDATA[González-Manteiga]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[252]]></id><title><![CDATA[Métodos estadísticos para el análisis 3D de moléculas en forma de anillo]]></title><text><![CDATA[La superposición 3D de dos moleculas es útil para la comprensión y la interpretación de datos moleculares. Permite la exploración de asociaciones entre factores  fisioquímicos o farmaco-cinéticos que influyen la conformación 3D de la molécula. En este trabajo, proponemos un procedimiento automático para la superposición 3D de moléculas en formas de anillo, que nos permite proporcionar una medida de la distancia entre dos conformaciones geométricas. Esta medida de la distancia nos permite abordar dos problemas relevantes asociados al análisis de las conformaciones de un conjunto de moléculas: a) la clasificación, a través de procedimientos estadísticos multivariantes,  del conjunto en un número de conformaciones preferidas;  b) la estimación de  los caminos de interconversión entre una conformación tipo y otra. Este último problema se enmarca en un contexto de análisis de datos funcionales, donde los datos son objetos 3D que pueden deducirse uno de otro por una deformación contínua.]]></text><keywords><![CDATA[deformación de objetos 3d, análisis conformacional, reconstrucción de camino]]></keywords><authors><element><attendee_id><![CDATA[62]]></attendee_id><normalized_name><![CDATA[M. Kessler]]></normalized_name><name><![CDATA[Mathieu]]></name><lastname><![CDATA[Kessler]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Pérez Pérez]]></normalized_name><name><![CDATA[José]]></name><lastname><![CDATA[Pérez Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[123]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Votaciones SEIO]]></name><description><![CDATA[<p>







<p class="p1">Elecciones a Presidente, Vocales del Consejo Ejecutivo y Vocales de los Consejos Académicos</p></p>]]></description><comments><![CDATA[]]></comments><start><![CDATA[09:30:00]]></start><end><![CDATA[14:30:00]]></end><location><id><![CDATA[16]]></id><name><![CDATA[Sala Berlín]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[17]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Pausa]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:20:00]]></start><end><![CDATA[10:30:00]]></end><location><![CDATA[]]></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[79]]></id><identifier><![CDATA[VB1]]></identifier><name><![CDATA[JEP-Estimación de pequeñas áreas 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[384]]></id><normalized_name><![CDATA[A. Fernández Militino]]></normalized_name><name><![CDATA[Ana]]></name><lastname><![CDATA[Fernández Militino]]></lastname></chairperson><papers><element><id><![CDATA[146]]></id><title><![CDATA[Estimation of labour force indicators in counties of Galicia using a multinomial mixed model with time and area efects]]></title><text><![CDATA[In the context of economic crisis in which the European Union is, in Spain the impact of this crisis on the labour market has been much more intense than in most advanced economies. In this situation police makers of all levels of public administration plan and act with the aim of reducing unemployment. In general, global policy measures are not usually satisfactory for local authorities that can develop their own strategies for employment. The objective of this work is to estimate labour force indicators in counties of Galicia using small area estimation techniques. We propose a multinomial logit mixed model with time and area effects to obtain small area estimates of labour force totals and unemployment rates in Galicia. The fitted model is then used to estimate the totals of employed and unemployed people and the unemployment rates of Galician counties.We calculate, also, the mean squared error by using analytical expressions and parametric bootstrap.]]></text><keywords><![CDATA[labour force survey, small area estimation, area level models, multinomial mixed models, bootstrap, unemployment totals, unemployment rates]]></keywords><authors><element><attendee_id><![CDATA[204]]></attendee_id><normalized_name><![CDATA[E. López Vizcaíno]]></normalized_name><name><![CDATA[Esther]]></name><lastname><![CDATA[López Vizcaíno]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[480]]></attendee_id><normalized_name><![CDATA[M. J. Lombardía Cortiña]]></normalized_name><name><![CDATA[Mª José]]></name><lastname><![CDATA[Lombardía Cortiña]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[159]]></attendee_id><normalized_name><![CDATA[D. Morales González]]></normalized_name><name><![CDATA[Domingo]]></name><lastname><![CDATA[Morales González ]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[161]]></id><title><![CDATA[On the application of two-fold nested error regression models to small-area estimation]]></title><text><![CDATA[Statistical agencies produce parameter estimates for domains of different levels of aggregation. They are interested to report estimates of linear parameters of domains and subdomains in a consistent way; this is to say, with the property that the sum of the subdomains estimates match up with the corresponding estimate of its domain. The two-fold nested error regression model provides EBLUP estimates of linear parameters of domains and subdomains with this desired property. Three methods to fit the model and a closed-formula procedure to estimate the mean squared error of the EBLUP estimates are given and empirically studied. Results of three simulations studies are reported. An application to Spanish Living Conditions Survey data is given.]]></text><keywords><![CDATA[small area estimation, linear mixed models, EBLUP, mean squared error, living condition survey]]></keywords><authors><element><attendee_id><![CDATA[159]]></attendee_id><normalized_name><![CDATA[D. Morales González]]></normalized_name><name><![CDATA[Domingo]]></name><lastname><![CDATA[Morales González]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[309]]></attendee_id><normalized_name><![CDATA[A. Perez Martin]]></normalized_name><name><![CDATA[Agustin]]></name><lastname><![CDATA[Perez Martin]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. Santamaria Arana]]></normalized_name><name><![CDATA[Laureano]]></name><lastname><![CDATA[Santamaria Arana]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[257]]></id><title><![CDATA[Double logistic model for estimating in small areas]]></title><text><![CDATA[In this work, model based estimators for small area domains are developed. The results are illustrated with the Information Technology Business Survey (ITBS) of the Basque Country in 2010. After discussing pros and cons of the different alternatives, an estimator based on a double logistic model with categorical explanatory variables is chosen. Auxiliary information for population totals is taken from a Businesses Register. A model-based bootstrap procedure is also given to provide the MSE of the predictions.]]></text><keywords><![CDATA[bootstrap, logistic models, information technology business survey]]></keywords><authors><element><attendee_id><![CDATA[384]]></attendee_id><normalized_name><![CDATA[A. Fernández Militino]]></normalized_name><name><![CDATA[Ana]]></name><lastname><![CDATA[Fernández Militino]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[370]]></attendee_id><normalized_name><![CDATA[L. Ugarte Martínez]]></normalized_name><name><![CDATA[Lola]]></name><lastname><![CDATA[Ugarte Martínez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[T. Goicoa]]></normalized_name><name><![CDATA[Tomás]]></name><lastname><![CDATA[Goicoa]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[66]]></id><identifier><![CDATA[VB2]]></identifier><name><![CDATA[Teoría de juegos 4]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[466]]></id><normalized_name><![CDATA[J. Castro Cantalejo]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Castro Cantalejo]]></lastname></chairperson><papers><element><id><![CDATA[90]]></id><title><![CDATA[Acuerdos equitativos en modelos de negociación empresa-sindicato multi-escenario]]></title><text><![CDATA[Investigamos una extensión del modelo clásico de negociación entre empresa y sindicato a situaciones en las que existe incertidumbre sobre las consecuencias de los acuerdos. Para ello se consideran varios estados de la naturaleza o futuros escenarios. Si se pudieran asignar probabilidades a estos escenarios, los agentes podrían negociar aplicando los conceptos de solución clásicos para determinar un acuerdo de consenso. En el modelo que consideramos en este trabajo no se dispone de información sobre las probabilidades de ocurrencia de los distintos estados. Partimos del supuesto de que los agentes son adversos al riesgo y proponemos una solución ex ante que garantiza niveles de utilidad que son equitativos tanto para la empresa como para el sindicato. Esta solución se basa en la misma idea que subyace en la solución clásica de Kalai-Smorodinsky: la aplicación del criterio mín-max a las diferencias entre las utilidades que pueden alcanzar los agentes, y un vector de utilidades utópicas.]]></text><keywords><![CDATA[negociación. multi-escenario, conceptos de solución]]></keywords><authors><element><attendee_id><![CDATA[288]]></attendee_id><normalized_name><![CDATA[V. Rubiales Caballero]]></normalized_name><name><![CDATA[Victoriana]]></name><lastname><![CDATA[Rubiales Caballero]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[504]]></attendee_id><normalized_name><![CDATA[L. Monroy Berjillos]]></normalized_name><name><![CDATA[Luisa]]></name><lastname><![CDATA[Monroy Berjillos]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. M. Mármol Conde]]></normalized_name><name><![CDATA[Amparo M.]]></name><lastname><![CDATA[Mármol Conde]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[269]]></id><title><![CDATA[Familia de modelos de subasta de tres objetos ordenados]]></title><text><![CDATA[Nuestro trabajo analiza modelos de subasta de tres objetos que están igualmente ordenados por los potenciales compradores. Para dicho análisis definimos una familia paramétrica de modelos de subasta que contiene a tres modelos clásicos: discriminatoria, uniforme y de Vickrey. Se obtiene el equilibrio Bayesiano de Nash de cada modelo perteneciente a la familia y se demuestra un resultado de equivalencia de ingresos bajo cualquiera de los modelos de la familia. Para dotar al subastador de un criterio de elección sobre los modelos de la familia, indistinguibles en cuanto a ingreso esperado, estudiamos el Valor al Riesgo (VaR). Concluimos que existen modelos pertenecientes a la familia con menor VaR que cualquiera de los tres clásicos en determinadas circunstancias.]]></text><keywords><![CDATA[subastas, equilibrio bayesiano de Nash, VaR]]></keywords><authors><element><attendee_id><![CDATA[450]]></attendee_id><normalized_name><![CDATA[E. Alonso Pérez]]></normalized_name><name><![CDATA[Estrella]]></name><lastname><![CDATA[Alonso Pérez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[79]]></attendee_id><normalized_name><![CDATA[J. Sánchez Soriano]]></normalized_name><name><![CDATA[Joaquín]]></name><lastname><![CDATA[Sánchez Soriano]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[437]]></attendee_id><normalized_name><![CDATA[J. Tejada]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[Tejada]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[290]]></id><title><![CDATA[Una nueva subasta para objetos bimodales]]></title><text><![CDATA[En este trabajo presentamos una subasta con buen comportamiento para la venta de objetos con distribución bimodal. Algunos ejemplos de situaciones con valoración bimodal serían: objetos con valor sentimental o con posible información privilegiada de uno o varios de los pujadores. La nueva subasta ha sido estudiada bajo las condiciones del modelo de referencia (benchmark model) y se ha verificado que si la valoración de todos los pujadores sigue una distribución continua, existe un único equilibrio bayesiano de Nash, que consiste, en pujar el verdadero valor del bien. Por último, se han realizado distintas pruebas computacionales para distribuciones bimodales y se ha comprobado, que tiene mejor comportamiento para el subastador en términos de valor esperado, que las subastas incluidas en el teorema de equivalencia de ingresos y que la subasta óptima definida por Myerson.]]></text><keywords><![CDATA[teoría de juegos, subastas, Benchmark model]]></keywords><authors><element><attendee_id><![CDATA[466]]></attendee_id><normalized_name><![CDATA[J. Castro Cantalejo]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Castro Cantalejo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Espínola Vílchez]]></normalized_name><name><![CDATA[Rosa]]></name><lastname><![CDATA[Espínola Vílchez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[99]]></id><identifier><![CDATA[VB3]]></identifier><name><![CDATA[Estadística espacial y espacio-temporal 1]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[8]]></id><name><![CDATA[Sala Londres]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[264]]></id><normalized_name><![CDATA[P. Juan Verdoy]]></normalized_name><name><![CDATA[Pablo]]></name><lastname><![CDATA[Juan Verdoy]]></lastname></chairperson><papers><element><id><![CDATA[265]]></id><title><![CDATA[Estudio del  efecto de la dinámica temporal en la estructura de la situación geográfica de los epicentros de una secuencia sísmica]]></title><text><![CDATA[Se analiza la estructura temporal de la situación geográfica de los epicentros en una secuencia sísmica ocurrida entre Octubre-1988 y Mayo-1989 en Agrón, Granada. Los datos han sido recogidos y suministrados por el Instituto Andaluz de Geofísica y Desastres Sísmicos. Para estudiar el efecto de la componente instante de ocurrencia se comparan los resultados obtenidos de realizar el análisis multifractal considerando las componentes geográficas junto con: (i) la componente temporal original, (ii) reorganizaciones aleatorias de la componente temporal original y (iii) la componente temporal generada uniformemente. Las técnicas multifractales aplicadas son los espectros de dimensiones generalizadas y de singularidades.  Ambos han sido obtenidos mediante sus aproximaciones discretas dadas por los formalismos de Grassberger para el espectro de dimensiones generalizadas y de Chhabra-Jensen para el espectro de singularidades. Proyectos MTM2009-13250 SGPI y P08-FQM-3834 CICYE C.A. Andalucía.]]></text><keywords><![CDATA[análisis multifractal, dimensión generalizada, espectro de singularidades, procesos espacio-temporales]]></keywords><authors><element><attendee_id><![CDATA[394]]></attendee_id><normalized_name><![CDATA[F. J. Esquivel Sánchez]]></normalized_name><name><![CDATA[Francisco Javier]]></name><lastname><![CDATA[Esquivel Sánchez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[68]]></attendee_id><normalized_name><![CDATA[J. M. Angulo Ibáñez]]></normalized_name><name><![CDATA[José Miguel]]></name><lastname><![CDATA[Angulo Ibáñez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[81]]></id><title><![CDATA[New tests of separability for spatio-temporal marked point processes with covariates]]></title><text><![CDATA[When dealing with general multidimensional point processes containing the spatial locations, the temporal occurrence, possible marks attached to each location and finally external covariates defined in the region where the process exists, it is not only interesting but also crucial testing for the condition of separability amongst any subset of the point process components. By separability we mean a multiplicative form for the conditional intensity allowing for individual component estimation. Following previous approximations to this problem, we focus on the conditional intensity function by considering nonparametric kernel-based estimators. Our approach calculates thinning probabilities under the conditions of separability and non-separability and compares them through divergence measures. We develop the statistical properties of our tests under a variety of practical scenarios. An application on modelling the spatio-temporal first-order intensity of forest fires is also developed.]]></text><keywords><![CDATA[conditional intensity function,, multidimensional spatial point processes, separability]]></keywords><authors><element><attendee_id><![CDATA[264]]></attendee_id><normalized_name><![CDATA[P. Juan Verdoy]]></normalized_name><name><![CDATA[Pablo]]></name><lastname><![CDATA[Juan Verdoy]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Díaz-Ávalos]]></normalized_name><name><![CDATA[Carlos]]></name><lastname><![CDATA[Díaz-Ávalos]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[259]]></attendee_id><normalized_name><![CDATA[J. Mateu Mahiques]]></normalized_name><name><![CDATA[Jorge]]></name><lastname><![CDATA[Mateu Mahiques]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[177]]></id><title><![CDATA[Residual kriging for functional data]]></title><text><![CDATA[Recently several methodologies for carrying out geostatistical analysis of functional data has been proposed.All of them assume that the spatial functional process considered is stationary. However in practice often we have non-stationary functional data sets because there is spatial trend in the mean. Here we propose a methodology to extend kriging predictors for functional data to the case where the mean function is not constant through the region. We consider an approach based on the classical residual kriging method used in univariate geostatistcs. We propose a three steps procedure. Initially a functional regression model is used for detrending the mean. Posteriorly we apply some kriging method for functional data to the regression residuals for doing prediction of a residual curve on a non-data location.  Finally the prediction curve is obtained as the sum of the trend and the residual prediction.]]></text><keywords><![CDATA[functional data, kriging, stationarity]]></keywords><authors><element><attendee_id><![CDATA[117]]></attendee_id><normalized_name><![CDATA[R. Giraldo Henao]]></normalized_name><name><![CDATA[Ramón]]></name><lastname><![CDATA[Giraldo Henao]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[259]]></attendee_id><normalized_name><![CDATA[J. Mateu Mahiques]]></normalized_name><name><![CDATA[Jorge]]></name><lastname><![CDATA[Mateu Mahiques]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Reyes Lizarazo]]></normalized_name><name><![CDATA[Adriana]]></name><lastname><![CDATA[Reyes Lizarazo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[50]]></id><identifier><![CDATA[VB4]]></identifier><name><![CDATA[Problemas de rutas]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[9]]></id><name><![CDATA[Sala París]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[141]]></id><normalized_name><![CDATA[J. Riera Ledesma]]></normalized_name><name><![CDATA[Jorge]]></name><lastname><![CDATA[Riera Ledesma]]></lastname></chairperson><papers><element><id><![CDATA[303]]></id><title><![CDATA[Problema de rutas de vehículos en una flota parcialmente externalizada]]></title><text><![CDATA[Consideramos el problema de determinar las rutas óptimas de una flota de vehículos, parte los cuales son vehículos propios y tienen que retornar a la empresa (ruta cerrada) pero el resto son subcontratados y la imputación de costes finaliza cuando atienden al último cliente de su ruta (ruta abierta). Abordamos la extensión del problema con ventanas de tiempo que da lugar al COVRPTW (Close-Open Vehicle Routing Problem with Time Windows). Para la versión del VRP con todas las rutas abiertas (OVRP), propuesta ya en los 80, hay más de 10 artículos publicados en los últimos 5 años. Sin embargo del OVRPTW sólo encontramos un par de referencias de hace dos años. El COVRPTW sólo ha sido tratado por Liu y otros (2010) que proponen un modelo matemático y un Algoritmo Memético. Proponemos una formulación mejor y analizamos experimentalmente las reglas heurísticas de construcción de soluciones que constituyen un componente importante en la generalidad de las heurísticas propuestas para el VRPTW.]]></text><keywords><![CDATA[VRP, VRPTW, COVRPTW]]></keywords><authors><element><attendee_id><![CDATA[214]]></attendee_id><normalized_name><![CDATA[J. A. Moreno Pérez]]></normalized_name><name><![CDATA[José Andrés]]></name><lastname><![CDATA[Moreno Pérez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Brito Santana]]></normalized_name><name><![CDATA[Julio]]></name><lastname><![CDATA[Brito Santana]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. J. Martínez García]]></normalized_name><name><![CDATA[F. Javier]]></name><lastname><![CDATA[Martínez García]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Expósito Márquez]]></normalized_name><name><![CDATA[Airam]]></name><lastname><![CDATA[Expósito Márquez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[238]]></id><title><![CDATA[Algoritmo tabú con búsqueda granular y selección aleatoria para el problema de rutas de vehículos con entregas divididas]]></title><text><![CDATA[El problema de Rutas de Vehículos con Entregas Divididas es una variante del problema clásico de Rutas de Vehículos  donde se permite que un mismo cliente pueda ser visitado por más de un vehículo. Este trabajo presenta un algoritmo heurístico llamado Randomized Granular Tabu Search que permite la búsqueda local en vecindarios definidos sobre los arcos del grafo que presentan mayor probabilidad de pertenecer a una solución óptima. El algoritmo utiliza una selección aleatoria para elegir el movimiento a introducir en la solución, asignando a los candidatos probabilidades jerárquicas de acuerdo a la mejora en la solución que representa cada uno. Además, se permite la búsqueda local en vecindarios con soluciones infactibles en términos de capacidad del vehículo, infactibilidad que se corrige en una etapa posterior.  Los resultados computacionales muestran que el heurístico logra mejorar varias de las mejores soluciones conocidas hasta el momento con tiempos computacionales competitivos.]]></text><keywords><![CDATA[problema de rutas de vehículos, entregas divididas, nodos de parada, tabu search, vecindario granular]]></keywords><authors><element><attendee_id><![CDATA[360]]></attendee_id><normalized_name><![CDATA[L. Berbotto]]></normalized_name><name><![CDATA[Leonardo]]></name><lastname><![CDATA[Berbotto]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[346]]></attendee_id><normalized_name><![CDATA[S. García]]></normalized_name><name><![CDATA[Sergio]]></name><lastname><![CDATA[García]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. J. Nogales]]></normalized_name><name><![CDATA[Francisco J.]]></name><lastname><![CDATA[Nogales]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[123]]></id><title><![CDATA[Un algoritmo de ramificación y corte para el problema DTSPMS basado en una descomposición de Benders]]></title><text><![CDATA[El Double Travelling Salesman Problem with Multiple Stacks es un problema de recogida y entrega de mercancía en el que todo el proceso de recogida se efectúa de forma previa al proceso de entrega. El transporte de la mercancía desde el área de recogida hasta el área de entrega se lleva a cabo en un único vehículo con un contenedor organizado en varias pilas, es decir sobre estructuras con organización LIFO, y capacidad limitada. Puesto que no se puede reorganizar la mercancía dentro del contenedor, el orden de recogida repercute en el orden de entrega. El problema consiste en encontrar los dos circuitos hamiltonianos, asociados al tour de recogida y de entrega respectivamente, de menor coste, compatible con la estructura de almacenamiento asociada al contenedor. Se presenta en este trabajo un algoritmo de ramificación y corte basado en desigualdades obtenidas a partir del estudio de la descomposición de Benders de un formulación matemática previa.]]></text><keywords><![CDATA[2TSPMS, traveling salesman problem, pickup and delivery TSP, Branch-and-Cut]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. D. Batista Galván]]></normalized_name><name><![CDATA[María D.]]></name><lastname><![CDATA[Batista Galván]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[141]]></attendee_id><normalized_name><![CDATA[J. Riera Ledesma]]></normalized_name><name><![CDATA[Jorge]]></name><lastname><![CDATA[Riera Ledesma]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. J. Salazar González]]></normalized_name><name><![CDATA[Juan José]]></name><lastname><![CDATA[Salazar González]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[92]]></id><identifier><![CDATA[VB5]]></identifier><name><![CDATA[Distribuciones estadísticas 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[10]]></id><name><![CDATA[Sala Viena]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[121]]></id><normalized_name><![CDATA[J. M. Sarabia Alegría]]></normalized_name><name><![CDATA[José María]]></name><lastname><![CDATA[Sarabia Alegría]]></lastname></chairperson><papers><element><id><![CDATA[17]]></id><title><![CDATA[Superstardom modelling using an extended Yule distribution]]></title><text><![CDATA[Durante los últimos años algunos autores han considerado que la distribución de Yule es consistente con la idea de que el “fenómeno superestrella” existe entre individuos con igual talento. Sin embargo, la cuestión no es clara, ya que se han alcanzado conclusiones opuestas en el campo de la música popular, y por otra parte hay críticas hacia el hecho de que la distribución de Yule indique la existencia de superestrellas sin talento. En este trabajo presentamos una distribución biparamétrica que generaliza a la distribución de Yule, y que pertenece a la familia de distribuciones generada por la función hipergeométrica de Gauss. La introducción de un nuevo parámetro hace que el modelo ajuste mejor las distribuciones empíricas y se elimine el efecto de varianza infinita. Por último presentamos una aplicación de dicha distribución en el contexto del “fenómeno superestrella”, proporcionando una interpretación distinta basada en la partición de la varianza.]]></text><keywords><![CDATA[distribuciones hipergeométricas gaussianas, modelización estadística]]></keywords><authors><element><attendee_id><![CDATA[156]]></attendee_id><normalized_name><![CDATA[A. Conde Sánchez]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Conde Sánchez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. J. Sáez Castillo]]></normalized_name><name><![CDATA[Antonio José]]></name><lastname><![CDATA[Sáez Castillo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. M. Martínez Rodríguez]]></normalized_name><name><![CDATA[Ana Mª]]></name><lastname><![CDATA[Martínez Rodríguez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Rodríguez Avi]]></normalized_name><name><![CDATA[José]]></name><lastname><![CDATA[Rodríguez Avi]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. J. Olmo Jiménez]]></normalized_name><name><![CDATA[Mª José]]></name><lastname><![CDATA[Olmo Jiménez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[59]]></id><title><![CDATA[Sinh-arcsinh distributions: their properties and applications]]></title><text><![CDATA[The sinh-arcsinh transformation provides an attractive device with which to extend any base symmetric unimodal density, with its two parameters controlling the skewness and tailweights of the resulting sinh-arcsinhed densities. In my talk I will summarise the fundamental properties and potential applications of sinh-arcsinhed families of distributions. Their quantile-based properties are particularly appealing, and likelihood-ratio tests provide a powerful means of testing crucial hypotheses such as symmetry, normality and logisticness.]]></text><keywords><![CDATA[likelihood-ratio tests, logisticness, normality, quantile-based properties, sinh-arcsinh transformation, skewness, symmetry, tailweight]]></keywords><authors/></element><element><id><![CDATA[65]]></id><title><![CDATA[Bivariate income distributions with fisk conditionals]]></title><text><![CDATA[The Fisk distribution is a flexible family of income distributions with several practical advantages. For a fixed shape parameter, the most general bivariate distribution with Fisk conditionals is identified. The properties of the new family are studied in detail, including marginal and conditional distributions, regression functions, dependence measures, moments and inequality measures. Several reliability properties are also studied including survival and hazard bivariate functions, hazard components and the Clayton-Oakes measure. Estimation of the parameters based on maximum likelihood is considered. Multivariate extensions to higher dimensions are also provided. An application with real economic data is given.]]></text><keywords><![CDATA[fisk distribution, conditional densities, dependence measures, reliability]]></keywords><authors><element><attendee_id><![CDATA[121]]></attendee_id><normalized_name><![CDATA[J. M. Sarabia Alegría]]></normalized_name><name><![CDATA[José María]]></name><lastname><![CDATA[Sarabia Alegría]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Prieto Mendoza]]></normalized_name><name><![CDATA[Faustino ]]></name><lastname><![CDATA[Prieto Mendoza]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[251]]></attendee_id><normalized_name><![CDATA[C. Trueba]]></normalized_name><name><![CDATA[Carmen]]></name><lastname><![CDATA[Trueba]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[118]]></id><identifier><![CDATA[VB6]]></identifier><name><![CDATA[Modelos estadísticos 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[213]]></id><normalized_name><![CDATA[P. Dorta-González]]></normalized_name><name><![CDATA[Pablo]]></name><lastname><![CDATA[Dorta-González]]></lastname></chairperson><papers><element><id><![CDATA[22]]></id><title><![CDATA[Número necesario a tratar y hazard ratio en el análisis de supervivencia]]></title><text><![CDATA[El análisis de supervivencia es la técnica estadística utilizada para analizar los datos correspondientes al tiempo transcurrido desde un origen bien definido hasta la ocurrencia de un determinado evento. Dependiendo de cuáles sean las medidas de eficacia que se utilicen, los mismos resultados pueden aparecer como modestos o como muy destacados. En el análisis de supervivencia, se ha extendido la utilización del número de pacientes a tratar (NNT) como medida del beneficio de un determinado tratamiento. En este trabajo hemos llevado a cabo varios estudios de simulación, considerando cambios en la distribución, en el tamaño muestral y en las condiciones de los pacientes. Las conclusiones que obtenemos son que el número necesario a tratar (NNT) es sencillo de calcular y fácil de interpretar, pero muestra un comportamiento muy variable con el tiempo y por tanto no podemos obviar la utilización del Hazard Ratio a la hora de valorar el efecto de una intervención (HR).]]></text><keywords><![CDATA[análisis de supervivencia, número necesario a tratar, hazard ratio]]></keywords><authors><element><attendee_id><![CDATA[151]]></attendee_id><normalized_name><![CDATA[M. Cuntín González]]></normalized_name><name><![CDATA[Marta]]></name><lastname><![CDATA[Cuntín González]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[149]]></attendee_id><normalized_name><![CDATA[T. Pérez Pérez]]></normalized_name><name><![CDATA[Teresa ]]></name><lastname><![CDATA[Pérez Pérez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[33]]></id><title><![CDATA[Cómo comparar revistas de diferentes campos científicos: normalización según hábitos de publicación y citación]]></title><text><![CDATA[El indicador de impacto de revistas científicas más empleado por la comunidad científica es el Impact Factor (IF). Este IF fue desarrollado por el Institute of Scientific Information (ISI) y se publica cada año en el Journal Citation Reports (JCR) por Thomson Reuters. Como principal inconveniente, el IF no es comparable entre campos científicos diferentes debido, principalmente, a los distintos hábitos de publicación y citación. En este trabajo se presenta una descomposición del IF en términos de sus variables más significativas. Se propone un indicador normalizado según dichas variables y se hace una aplicación empírica a las 174 categorías de la edición de ciencias y las 56 categorías de la edición de ciencias sociales del JCR.]]></text><keywords><![CDATA[factor de impacto, evaluación de revistas, indicador normalizado, hábitos de citación]]></keywords><authors><element><attendee_id><![CDATA[213]]></attendee_id><normalized_name><![CDATA[P. Dorta-González]]></normalized_name><name><![CDATA[Pablo]]></name><lastname><![CDATA[Dorta-González]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. I. Dorta-González]]></normalized_name><name><![CDATA[María Isabel]]></name><lastname><![CDATA[Dorta-González]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[168]]></id><title><![CDATA[Estimación: un reto de medición a la incertidumbre]]></title><text><![CDATA[Esta investigación resume la secuencia metodológica  de pasos a seguir para realizar estimación de  parámetros poblacionales a partir de observaciones muestrales, con la finalidad de  evitar inferencias erróneas a partir de procedimientos mal aplicados. En innumerables estudios, los investigadores utilizan pruebas estadísticas sin considerar las restricciones y supuestos que éstas exigen, e ignorando el efecto real que las omisiones teóricas ocasionan en los resultados y sus posteriores decisiones. Ante esas circunstancias, valorar poblaciones mediante sondeos muéstrales constituye un reto de medición. En esta exposición se  enfatiza las causas posibles que origina la incertidumbre del proceso de  estimación y se proponen recomendaciones pertinentes para evitar consecuencias generadas por la aplicación deficiente del instrumental estadístico disponible.]]></text><keywords><![CDATA[estimacion, muestreo, precisión, población, nivel de confianza]]></keywords><authors/></element></papers></element><element><id><![CDATA[84]]></id><identifier><![CDATA[VB7]]></identifier><name><![CDATA[Probabilidad, convergencias y teoremas límite]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[10:30:00]]></start><end><![CDATA[11:30:00]]></end><location><id><![CDATA[12]]></id><name><![CDATA[Sala Roma II]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[476]]></id><normalized_name><![CDATA[M. D. Ruiz Medina]]></normalized_name><name><![CDATA[María Dolores]]></name><lastname><![CDATA[Ruiz Medina ]]></lastname></chairperson><papers><element><id><![CDATA[314]]></id><title><![CDATA[Finite time control of Lévy diffusion processes: a numerical approach.]]></title><text><![CDATA[A general Lévy diffusion process – the solution to the Lévy stochastic differential equation - is treated in a stochastic control framework. All the characteristics of the process are subject to the control variable. The objective function is maximized in a fixed finite time horizon. The value function of the stochastic control problem is approximated through randomization of the horizon and assuming piecewise constant family of controls. It is shown that the procedure is convergent and unveils not only the value function but also the corresponding optimal control. The relevance of the procedure is demonstrated in applications to the portfolio selection problem and optimal execution time of an American put option.]]></text><keywords><![CDATA[stochastic control, Lévy diffusion, numerical methods, randomization]]></keywords><authors><element><attendee_id><![CDATA[474]]></attendee_id><normalized_name><![CDATA[P. Diko]]></normalized_name><name><![CDATA[Peter]]></name><lastname><![CDATA[Diko]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Usábel]]></normalized_name><name><![CDATA[Miguel]]></name><lastname><![CDATA[Usábel]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[165]]></id><title><![CDATA[High-dimensional random geometric graphs and their clique number]]></title><text><![CDATA[We study the behavior of random geometric graphs in high dimensions. We show that as the dimension grows, the graph becomes similar to an Erdos-Rényi random graph. We pay particular attention to the clique number of such graphs and show that it is very close to that of the corre- sponding Erdo ̋s-Rényi graph when the dimension is larger than log3 n where n is the number of vertices. The problem is motivated by a statistical problem of testing dependencies.]]></text><keywords><![CDATA[clique number, dependency testing, geometric graphs, random graphs]]></keywords><authors><element><attendee_id><![CDATA[322]]></attendee_id><normalized_name><![CDATA[F. Udina Abelló]]></normalized_name><name><![CDATA[Frederic]]></name><lastname><![CDATA[Udina Abelló]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[L. Devroye]]></normalized_name><name><![CDATA[Luc]]></name><lastname><![CDATA[Devroye]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. György]]></normalized_name><name><![CDATA[András]]></name><lastname><![CDATA[György]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[G. Lugosi]]></normalized_name><name><![CDATA[Gábor]]></name><lastname><![CDATA[Lugosi]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[327]]></id><title><![CDATA[Asymtotic properties of maximum-likelihood estimators of autoregressive Hilbertian processes]]></title><text><![CDATA[The autoregressive Hilbertian time series (ARH(p) series) framework (see  Bosq, 2000; Bosq, 2010; Bosq and Blanke, 2007) provides a new perspective for deriving  models and tools in the statistical analysis of spatiotemporal data displaying weak-dependence in time (see Salmerón y Ruiz-Medina, 2009). Moment-based parameter estimation has been addressed in Bosq (2000). These results are alternatively formulated in the framework of  projection into a general orthogonal basis in Bosq and Blanke (2007). The maximum-likelihood parameter estimation problem is investigated in  Ruiz-Medina and Salmerón (2010). In this paper, we extend the asymptotic study initiated in Ruiz-Medina and Salmerón (2011) on the large-sample variance properties of these estimators, in terms of the SEM (Structural Expectation Maximization) algorithm, to the derivation of their consistency and asymptotic distributional properties.]]></text><keywords><![CDATA[ARH(p) processes, functional limit results, Hilbert-valued  processes, maximum likelihood estimation]]></keywords><authors><element><attendee_id><![CDATA[476]]></attendee_id><normalized_name><![CDATA[M. D. Ruiz Medina]]></normalized_name><name><![CDATA[María Dolores]]></name><lastname><![CDATA[Ruiz Medina ]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[317]]></attendee_id><normalized_name><![CDATA[R. Salmerón Gómez]]></normalized_name><name><![CDATA[Román]]></name><lastname><![CDATA[Salmerón Gómez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[9]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Pausa - Café]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[11:30:00]]></start><end><![CDATA[12:00:00]]></end><location><id><![CDATA[17]]></id><name><![CDATA[Hall Plaza Mayor]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[53]]></id><identifier><![CDATA[VC1]]></identifier><name><![CDATA[JEP-Mesa Redonda]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:15:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[543]]></id><normalized_name><![CDATA[F. Hernández Jiménez]]></normalized_name><name><![CDATA[Francisco]]></name><lastname><![CDATA[Hernández Jiménez]]></lastname></chairperson><papers><element><id><![CDATA[330]]></id><title><![CDATA[Uso de fuentes administrativas en la estadística pública]]></title><text><![CDATA[Las fuentes administrativas son cada vez más importantes en la producción estadística, principalmente porque con ellas se reducen tanto los costes en la producción como carga de trabajo a las unidades informantes. A estas ventajas clásicos del uso de fuentes administrativas, en los últimos años  con el desarrollo de la tecnología se ha facilitado que la estadística oficial las puedan incorporan de forma más intensiva en  su proceso, debido principalmente a una reducción en los plazos de disponibilidad de dichas fuentes, y porque cada vez esa información posee una mayor calidad y cobertura. En esta mesa redonda se analizará y debatirá los aspectos positivos que tiene el uso de las fuentes administrativas en las oficinas de estadística, los problemas o aspectos que deberían ser mejorados y los retos a los que nos enfrentamos en el corto y medio plazo en relación con el uso de las fuentes administrativas en la estadística oficial.]]></text><keywords><![CDATA[fuentes administrativs, estadistica pública]]></keywords><authors><element><attendee_id><![CDATA[538]]></attendee_id><normalized_name><![CDATA[L. E. Barbado Miguel]]></normalized_name><name><![CDATA[Luis Esteban]]></name><lastname><![CDATA[Barbado Miguel]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[539]]></attendee_id><normalized_name><![CDATA[J. A. Campo Andión]]></normalized_name><name><![CDATA[José Antonio]]></name><lastname><![CDATA[Campo Andión]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[540]]></attendee_id><normalized_name><![CDATA[F. J. Parra Rodríguez]]></normalized_name><name><![CDATA[Francisco Javier]]></name><lastname><![CDATA[Parra Rodríguez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[542]]></attendee_id><normalized_name><![CDATA[R. Mayo Moreno]]></normalized_name><name><![CDATA[Rafaela]]></name><lastname><![CDATA[Mayo Moreno]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[61]]></id><identifier><![CDATA[VC2]]></identifier><name><![CDATA[Teoría de juegos 5]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[446]]></id><normalized_name><![CDATA[D. Rios Insua]]></normalized_name><name><![CDATA[David ]]></name><lastname><![CDATA[Rios Insua]]></lastname></chairperson><papers><element><id><![CDATA[172]]></id><title><![CDATA[Un modelo de robot que percibe, siente y toma decisiones]]></title><text><![CDATA[Presentamos un modelo que describe el proceso de toma de decisiones de un agente autónomo sintético que interacciona con el usuario y está influenciado por mecanismos afectivos. Dichas emociones se simulan observando las acciones realizadas por el usuario. La toma de decisiones se fundamenta en la maximización de la utilidad esperada, empleando un modelo predictivo de las acciones del usuario y de la evolución del entorno en el que se encuentran ambos, así como mecanismos de aprendizaje. Presentamos la implementación que se ha realizado en un robot dedicado a la educación y al entretenimiento. El objetivo de este modelo, es que el robot disponga de una mejor aproximación a la toma de decisiones y sea capaz de interactuar de forma natural con los usuarios]]></text><keywords><![CDATA[análisis de riesgos adversarios, computación afectiva]]></keywords><authors><element><attendee_id><![CDATA[279]]></attendee_id><normalized_name><![CDATA[P. Gómez Esteban]]></normalized_name><name><![CDATA[Pablo]]></name><lastname><![CDATA[Gómez Esteban]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[432]]></attendee_id><normalized_name><![CDATA[J. F. Guerrero Rázuri]]></normalized_name><name><![CDATA[Javier Francisco]]></name><lastname><![CDATA[Guerrero Rázuri]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[481]]></attendee_id><normalized_name><![CDATA[A. Redondo Hernández]]></normalized_name><name><![CDATA[Alberto]]></name><lastname><![CDATA[Redondo Hernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[D. García Sánchez]]></normalized_name><name><![CDATA[Diego]]></name><lastname><![CDATA[García Sánchez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[126]]></id><title><![CDATA[Enumeraciones de sistemas de votación: sucesiones de Fibonacci y el número de oro]]></title><text><![CDATA[Los sistemas de votación son estructuras que, salvo isomorfismos, son numerables en función del número de votantes y/o de diversos parámetros adicionales. A finales del siglo XIX, Dedekin ya se planteó el problema del conteo de ciertas funciones Booleanas, y a mediados del siglo XX May enumeró a los juegos simétricos. Para ciertos  sistemas de votación se han determinado cotas para su número, sin embargo  la enumeración de algunos sistemas sigue un patrón establecido. En efecto, las sucesiones de Fibonacci aparecen asiduamente para juegos con pocos tipos de jugadores equivalentes y muchos de los conteos difieren asintóticamente por un factor multiplicativo que resulta ser el número de oro o una potencia suya. El trabajo resume conteos que siguen fórmulas cerradas en función de diversos parámetros y señala otros problemas, relacionados con valores de juegos cooperativos, en donde aparecen otras sucesiones de números combinatorios, por ejemplo los k-dimensional números Catalanes.]]></text><keywords><![CDATA[sistemas de votación, juegos cooperativos, valores, enumeraciones, sucesiones de Fibonacci]]></keywords><authors/></element><element><id><![CDATA[263]]></id><title><![CDATA[Adversarial risk analysis resource allocation models for urban security]]></title><text><![CDATA[As suggested in Lomborg (2008), security is one of the largest global problems in general and, particularly, at the urban level. In this talk we shall describe how our adversarial risk analysis framework may be used for resource allocation decisions for urban security. Essentially, we deploy a defend-attack-defend model over each cell of a map describing the city; the models are coordinated by resource constraints and neighbouring relations with security implications. We focus on how to incorporate intelligence into the model. We shall discuss limitations and extensions of the model. ]]></text><keywords><![CDATA[game theory, bayesian analysis, risk analysis, security, resource allocation]]></keywords><authors><element><attendee_id><![CDATA[446]]></attendee_id><normalized_name><![CDATA[D. Rios Insua]]></normalized_name><name><![CDATA[David ]]></name><lastname><![CDATA[Rios Insua]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Rios]]></normalized_name><name><![CDATA[Jesus]]></name><lastname><![CDATA[Rios]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Gil]]></normalized_name><name><![CDATA[Cesar]]></name><lastname><![CDATA[Gil]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[115]]></id><identifier><![CDATA[VC3]]></identifier><name><![CDATA[Clasificación y análisis multivariante 5]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[8]]></id><name><![CDATA[Sala Londres]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[233]]></id><normalized_name><![CDATA[C. M. Cuadras Avellanas]]></normalized_name><name><![CDATA[Carles M]]></name><lastname><![CDATA[Cuadras Avellanas]]></lastname></chairperson><papers><element><id><![CDATA[101]]></id><title><![CDATA[Profile identification via weighted related metric scaling: An application to dependent Spanish children]]></title><text><![CDATA[Disability and dependence (lack of autonomy in performing common everyday actions) affect health status and quality of life, therefore they are significant public health issues. The main purpose of this study is to establish the existing relationship among different variables (continuous, categorical and binary) referred to children between 3 and 6 years old and their functional dependence in basic activities of daily living. We combine different types of information via weighted related metric scaling to obtain homogeneous profiles for dependent Spanish children. The redundant information between groups of variables is modelled with an interaction parameter that can be optimized according to several criteria. In this paper, the goal is to obtain maximum explained variability in an Euclidean configuration. Data comes from the Survey about Disabilities, Personal Autonomy and Dependence Situations, EDAD 2008, (Spanish National Institute of Statistics, 2008).]]></text><keywords><![CDATA[ADL, disability, mixed-type data, public health, related metric scaling]]></keywords><authors><element><attendee_id><![CDATA[301]]></attendee_id><normalized_name><![CDATA[A. Grané Chávez]]></normalized_name><name><![CDATA[Aurea]]></name><lastname><![CDATA[Grané Chávez]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[465]]></attendee_id><normalized_name><![CDATA[I. Albarrán]]></normalized_name><name><![CDATA[Irene]]></name><lastname><![CDATA[Albarrán]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[509]]></attendee_id><normalized_name><![CDATA[P. Alonso]]></normalized_name><name><![CDATA[Pablo]]></name><lastname><![CDATA[Alonso]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[74]]></id><title><![CDATA[Clasificación y asociación de distancias para datos de contingencia a dos modos]]></title><text><![CDATA[Una de las características principales de los modelos de asociación de distancias para el análisis de una tabla IxJ de contingencia F, es la reducción del número de parámetros que describen las interacciones de primer orden en un modelo log-lineal. Estos modelos permiten la representación de las filas y de las columnas de F como puntos en un espacio de dimensión reducida, de forma que las relaciones entre las categorías de los dos conjuntos son descritas en términos de una distancia Euclídea. En este trabajo proponemos un modelo simultáneo de clasificación y asociación de distancias para datos de contingencia a dos vías. El objetivo del modelo es por tanto la partición de las filas de la tabla en T $(T<<I)$ clases, mientras que simultáneamente los T centros de los clusters junto a las J modalidades columna son representados en un espacio de dimensión baja, de modo que la relación de interacción se preserve.]]></text><keywords><![CDATA[clasificación, asociación de distancias, tablas de frecuencias]]></keywords><authors><element><attendee_id><![CDATA[225]]></attendee_id><normalized_name><![CDATA[J. F. Vera Vera]]></normalized_name><name><![CDATA[José Fernando]]></name><lastname><![CDATA[Vera Vera]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. de Rooij]]></normalized_name><name><![CDATA[Mark]]></name><lastname><![CDATA[de Rooij]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[W. J. Heiser]]></normalized_name><name><![CDATA[Willem Jan]]></name><lastname><![CDATA[Heiser]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[82]]></id><title><![CDATA[Comentarios sobre la estructura del espacio   cuadrático en análisis discriminante]]></title><text><![CDATA[Esta comunicación explora algunas propiedades de interés del espacio cuadrático (Velilla, 2008,2010,2012), una herramienta de reducción de la dimensión en análisis discriminante. Esta variedad lineal tiene una estructura compleja, e incluye en ocasiones componentes que separan a los grupos tanto en posición como en dispersión. En esta situación, postular un modelo ortogonal entre las direcciones lineales dominantes y los subespacios de dispersión es una hipótesis de utilidad para determinar, en la práctica, una representación adecuada del subespacio cuadrático. Se presentan también dos aplicaciones con datos reales.]]></text><keywords><![CDATA[reducción de la dimensión, SIR, SIRII, SAVE]]></keywords><authors/></element><element><id><![CDATA[46]]></id><title><![CDATA[Análisis multivariante de los datos de supervivencia del Titanic]]></title><text><![CDATA[En abril de 2012 se cumple el centenario del hundimiento del vapor Titanic, suceso ocurrido durante su viaje inaugural. Se analizan los datos de supervivencia, clasificados por tripulación y clase, edad y  sexo. Los métodos utilizados son: modelos log-lineales, análisis de correspondencias múltiples, representación en mosaicos y nautigramas.]]></text><keywords><![CDATA[modelos log-lineales, análisis de correspondencias, mosaicos, nautigramas]]></keywords><authors/></element></papers></element><element><id><![CDATA[63]]></id><identifier><![CDATA[VC4]]></identifier><name><![CDATA[Modelos de gestión energética]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[9]]></id><name><![CDATA[Sala París]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[283]]></id><normalized_name><![CDATA[M. Lezaun Iturralde]]></normalized_name><name><![CDATA[Miguel]]></name><lastname><![CDATA[Lezaun Iturralde]]></lastname></chairperson><papers><element><id><![CDATA[131]]></id><title><![CDATA[A strategic planning model for energy efficiency in public buildings]]></title><text><![CDATA[In this work we describe the strategic planning module of a decision-support system (DSS) for operators of energy-efficient buildings and spaces of public use.  This DSS is been developed within the EU Energy Efficiency and Risk  Management in Public Buildings (EnRiMa) project.  In particular, we focus on Symbolic Model Specification (SMS) by defining the model entities, including variables, objectives, parameters, and relations. Finally, some numerical examples are shown.]]></text><keywords><![CDATA[energy, optimization, stochastic programming]]></keywords><authors><element><attendee_id><![CDATA[57]]></attendee_id><normalized_name><![CDATA[E. L. Cano]]></normalized_name><name><![CDATA[Emilio]]></name><lastname><![CDATA[L. Cano]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[554]]></attendee_id><normalized_name><![CDATA[J. M. Moguerza]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[M. Moguerza]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[204]]></id><title><![CDATA[Internalización de externalidades del sistema eléctrico chileno]]></title><text><![CDATA[Cómo influiría sobre la competitividad de las diferentes tecnologías de generación de energía la puesta en marcha de un mercado de emisiones de carbono en Chile es la cuestión que ha motivado esta investigación. Se han planteado modelos de optimización para un conjunto de escenarios que se resuelven con programación lineal. A estos resultados se los analiza mediante técnicas de decisión multicriterio discreta. En cada uno de los escenarios diseñados se ha tenido en cuenta la participación de las tecnologías, el coste e intensidad de emisiones de carbono y el volumen de comercio de derechos de emisión. Posteriormente, asumiendo ciertos criterios y ponderaciones de los mismos, se efectúa la evaluación y comparación de escenarios alternativos. De la ordenación obtenida, se extrae una propuesta concreta para el diseño del mercado de carbono. Además, el análisis de sensibilidad proporciona información útil para la toma de decisiones en distintos aspectos de la planificación energética.]]></text><keywords><![CDATA[mitigación, cambio climático, generación eléctrica, Chile]]></keywords><authors><element><attendee_id><![CDATA[397]]></attendee_id><normalized_name><![CDATA[M. V. Román de Lara]]></normalized_name><name><![CDATA[María Victoria]]></name><lastname><![CDATA[Román de Lara]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. V. Mokotoff Miguel]]></normalized_name><name><![CDATA[Ethel V.]]></name><lastname><![CDATA[Mokotoff Miguel]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[189]]></id><title><![CDATA[Gestión óptima del consumo eléctrico mediante una política de inventivos]]></title><text><![CDATA[La implantación de energías renovables, en particular la eólica, está limitada por su dependencia de la meteorología y la dificultad de almacenar los excedentes para usarlos en los momentos de baja producción. Se han ideado varias formas de aprovechar los superávits: bombear agua a pantanos construidos en altura, insuflar aire comprimido en cavidades bajo tierra, propulsar motores que hagan rotar volantes de inercia y acumular energía en grandes baterías. Otro modo de atacar este problema es pasar de un sistema basado en que la producción eléctrica responda a los caprichos impredecibles de la demanda, a otro en el que el consumo se adapte a la producción. En esta comunicación se presenta un modelo para la gestión óptima de las cargas programables de un hogar, así como de la flexibilidad de la demanda del conjunto de clientes, ofreciendo a los usuarios incentivos puntuales precio/volumen según sean las previsiones de consumo. El objetivo final es adaptar la demanda a la producción.]]></text><keywords><![CDATA[programación entera mixta, demanda eléctrica]]></keywords><authors><element><attendee_id><![CDATA[283]]></attendee_id><normalized_name><![CDATA[M. Lezaun Iturralde]]></normalized_name><name><![CDATA[Miguel]]></name><lastname><![CDATA[Lezaun Iturralde]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[C. Gorria Corres]]></normalized_name><name><![CDATA[Carlos ]]></name><lastname><![CDATA[Gorria Corres]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Jimeno Huarte]]></normalized_name><name><![CDATA[Joseba]]></name><lastname><![CDATA[Jimeno Huarte]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[I. Laresgoiti Rementeria]]></normalized_name><name><![CDATA[Iñaki]]></name><lastname><![CDATA[Laresgoiti Rementeria]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[N. Ruiz Carames]]></normalized_name><name><![CDATA[Nerea]]></name><lastname><![CDATA[Ruiz Carames]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[85]]></id><identifier><![CDATA[VC5]]></identifier><name><![CDATA[Métodos estadísticos]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[10]]></id><name><![CDATA[Sala Viena]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[335]]></id><normalized_name><![CDATA[J. López Fidalgo]]></normalized_name><name><![CDATA[Jesús]]></name><lastname><![CDATA[López Fidalgo]]></lastname></chairperson><papers><element><id><![CDATA[215]]></id><title><![CDATA[Clasificación de instrumentos participativos mediante análisis de conglomerados]]></title><text><![CDATA[El aumento de la participación ciudadana ha hecho que el número de instrumentos de participación haya crecido. Las clasificaciones resultantes pecan en ocasiones de mostrar solo un aspecto del fenómeno participativo. Buscando una clasificación más amplia hemos utilizado análisis de conglomerados de tipo jerárquico acumulativo con tres aproximaciones: Average Linkage, Single linkage y Complete linkage. Analizaremos un primer conglomerado creado a partir de las características observados en los instrumentos más representativos. Así, se observan distintas familias en una agrupación centrada en el número de participantes y el tipo de estos. Los instrumentos se dividen en unas tareas identificadas previamente. Analizando la presencia o inexistencia de las tareas en los instrumentos, creamos el segundo conglomerado que se ordena según el modo en que se toman decisiones. Comparando ambas clasificaciones, creamos una última clasificación que combina los resultados de ambas.]]></text><keywords><![CDATA[conglomerados, participación, tareas participativas]]></keywords><authors><element><attendee_id><![CDATA[98]]></attendee_id><normalized_name><![CDATA[J. M. Lavín de la Cavada]]></normalized_name><name><![CDATA[José María]]></name><lastname><![CDATA[Lavín de la Cavada]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[72]]></attendee_id><normalized_name><![CDATA[C. Alfaro Gimeno]]></normalized_name><name><![CDATA[César]]></name><lastname><![CDATA[Alfaro Gimeno]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[73]]></attendee_id><normalized_name><![CDATA[J. Gómez Miguel]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Gómez Miguel]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[407]]></attendee_id><normalized_name><![CDATA[J. J. Molero López]]></normalized_name><name><![CDATA[Juan José]]></name><lastname><![CDATA[Molero López]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[154]]></id><title><![CDATA[Análisis del riesgo de accidentes y muertes de tráfico]]></title><text><![CDATA[El objetivo principal de este trabajo es proponer una metodología para evaluar los riesgos de accidentes y muertes en medios de transportes. Dicha metodología consta de tres fases. En la primera fase, se estima el número medio de accidentes haciendo uso de los modelos lineales generalizados, considerando las siguientes distribuciones de probabilidad: Poisson, Gamma, Binomial Negativa y Conway-Maxwell-Poisson. En la segunda fase, se calcula el número medio de muertes por accidente usando distintos métodos de ponderación, dependiendo de la fiabilidad de los datos. Por último, en la tercera fase se obtiene el número medio de muertes en accidentes de tráfico usando los resultados obtenidos en las dos fases anteriores. Los modelos ajustados nos permitirán determinar las variables sobre las que hay que actuar si queremos reducir el número medio de accidentes y/o muertes y así mejorar la seguridad. La metodología es ilustrada usando los datos de la red ferroviaria española.]]></text><keywords><![CDATA[análisis de riesgos, modelos lineales generalizados, accidentes de tráfico]]></keywords><authors><element><attendee_id><![CDATA[234]]></attendee_id><normalized_name><![CDATA[A. Mateos]]></normalized_name><name><![CDATA[Alfonso]]></name><lastname><![CDATA[Mateos]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[130]]></attendee_id><normalized_name><![CDATA[A. Jiménez Martín]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Jiménez Martín]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[135]]></id><title><![CDATA[Diseño de experimentos para modelos de ecuaciones simultáneas desde dos perspectivas]]></title><text><![CDATA[En este trabajo se obtienen diseños óptimos de experimentos para modelos de ecuaciones simultáneas. En particular se considera un modelo con dos ecuaciones donde una de las variables explicativas (exógena) de una ecuación es la variable respuesta (endógena) de la otra. En ambas ecuaciones se tiene una variable controlable para la que se obtendrán diseños óptimos. La primera vía (CR) asume que la distribución de la variable exógena/endógena es totalmente conocida, dada por un diseño para esta variable condicionado por los valores que la variable diseñable tome durante el experimento. La segunda vía (ES) asume una distribución parcialmente conocida. Se calculan y comparan los diseños óptimos de ambas vías y se realizan análisis de sensibilidad por ser un modelo no lineal (depende de los parámetros iniciales). Por último, se presenta un caso paradójico donde el necesario redondeo del diseño óptimo aproximado nunca coincidirá con el diseño óptimo exacto aunque converja a éste último.]]></text><keywords><![CDATA[diseños aproximados, matriz de información, diseños D-óptimos, ecuaciones simultáneas, diseños condicionalmente restringidos, ecuaciones estructurales]]></keywords><authors><element><attendee_id><![CDATA[276]]></attendee_id><normalized_name><![CDATA[V. M. Casero Alonso]]></normalized_name><name><![CDATA[Víctor Manuel]]></name><lastname><![CDATA[Casero Alonso]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[335]]></attendee_id><normalized_name><![CDATA[J. López Fidalgo]]></normalized_name><name><![CDATA[Jesús]]></name><lastname><![CDATA[López Fidalgo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[192]]></id><title><![CDATA[Diseños experimentales para verosimilitud parcial]]></title><text><![CDATA[En el problema de asignación de pacientes a posibles tratamientos aparece el diseño óptimo de experimentos en el campo del análisis de supervivencia. El modelo de Cox se utiliza para estudiar el efecto de una covariable en la supervivencia, siendo el principal interés estimar los coeficientes de regresión, dejando el riesgo basal sin especificar. Consideraremos un experimento en el intervalo de tiempo [0, 1] con incorporación a tiempo 0. Podremos tener censuras por abandono o por fin de estudio. Se encontraron las funciones de densidad del tiempo observado condicionadas a que dicho tiempo es un fallo o una censura. Se halló la matriz de información para este modelo, teniendo en cuenta que no siempre es adecuado trabajar con ella. Eso nos condujo al uso de una matriz de información, basada en la verosimilitud parcial, ampliamente utilizada para la estimación en el modelo de Cox. Mediante un ejemplo se comparan los diseños óptimos hallados mediante estos dos tipos de verosimilitud.]]></text><keywords><![CDATA[verosimilitud parcial, matriz de información, diseño óptimo de experimentos]]></keywords><authors><element><attendee_id><![CDATA[335]]></attendee_id><normalized_name><![CDATA[J. López Fidalgo]]></normalized_name><name><![CDATA[Jesús]]></name><lastname><![CDATA[López Fidalgo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. J. Rivas López]]></normalized_name><name><![CDATA[María Jesús]]></name><lastname><![CDATA[Rivas López]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[106]]></id><identifier><![CDATA[VC6]]></identifier><name><![CDATA[Estadística computacional]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[93]]></id><normalized_name><![CDATA[Q. Martín Martín]]></normalized_name><name><![CDATA[Quintín ]]></name><lastname><![CDATA[Martín Martín]]></lastname></chairperson><papers><element><id><![CDATA[136]]></id><title><![CDATA[Balances principales]]></title><text><![CDATA[El análisis de datos composicionales se facilita trabajando con una base ortonormal. Puede obtenerse mediante un análisis de componentes principales composicional o de una partición secuencial binaria (SBP). La primera en general es difícil de interpretar, mientras que la segunda, cuando se basa en criterios heurísticos, es interpretable, pero no tiene fundamento estadístico. Una alternativa interesante son los balances principales, definidos como bases asociadas a una SBP, cuyos coeficientes son log-cocientes entre grupos de componentes, y que maximizan sucesivamente la varianza explicada. Sin embargo, su cálculo requiere una búsqueda exhaustiva inasumible computacionalmente. Se presentan tres SBP sub-óptimas basadas en criterios distintos de aproximación de las componentes principales: a) minimización del ángulo geométrico a los vectores principales; b) maximización jerárquica de la varianza explicada; c) cluster de Ward jerárquico de las variables composicionales.]]></text><keywords><![CDATA[datos composicionales, partición secuencial binaria, base de balances, geometria de Aitchison, simplex]]></keywords><authors><element><attendee_id><![CDATA[223]]></attendee_id><normalized_name><![CDATA[V. Pawlowsky-Glahn]]></normalized_name><name><![CDATA[Vera]]></name><lastname><![CDATA[Pawlowsky-Glahn]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. J. Egozcue Rubí]]></normalized_name><name><![CDATA[Juan José]]></name><lastname><![CDATA[Egozcue Rubí]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. Tolosana Delgado]]></normalized_name><name><![CDATA[Raimon]]></name><lastname><![CDATA[Tolosana Delgado]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[272]]></id><title><![CDATA[Estimacion máxima verosímil de parámetros modales en estructuras mediante el algoritmo Expectation-Maximization]]></title><text><![CDATA[El análisis dinámico lineal de una estructura mecánica puede plantearse como un modelo en el espacio de los estados y su formulación tiene relación directa con parámetros físicos de la misma tales como masa, rigidez y amortiguamientos. Este planteamiento permite estimar modelos empíricos de la estructura a partir exclusivamente de medidas directas de su movimiento obtenidas en ensayos realizados sobre la estructura real, lo que proporciona una información muy valiosa de los parámetros físicos de la misma. En este trabajo nosotros proponemos aplicar el algoritmo Expectation-Maximization (EM) para la estimación máxima verosímil de estos modelos (y por tanto, de los parámetros físicos de la estructura) utilizando solamente las vibraciones registradas. Este método se ha aplicado a simulaciones numéricas y a datos registrados en estructuras reales, y se han analizado sus ventajas e inconvenientes.]]></text><keywords><![CDATA[estimación máxima verosímil, algoritmo EM, análisis modal operacional]]></keywords><authors><element><attendee_id><![CDATA[444]]></attendee_id><normalized_name><![CDATA[F. J. Cara Cañas]]></normalized_name><name><![CDATA[Francisco Javier]]></name><lastname><![CDATA[Cara Cañas]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Juan Ruiz]]></normalized_name><name><![CDATA[Jesús]]></name><lastname><![CDATA[Juan Ruiz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[E. Alarcon Alvarez]]></normalized_name><name><![CDATA[Enrique]]></name><lastname><![CDATA[Alarcon Alvarez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[210]]></id><title><![CDATA[Configuración experimental de un perceptron multicapa para la modelización del comportamiento de las variables climáticas]]></title><text><![CDATA[Se establece una metodología experimental para configurar los parámetros de un modelo de predicción de variables climáticas, basado en una red neuronal artificial (RNA) de tipo perceptron multicapa (Multilayer Perceptron, MLP). Para la configuración del modelo se emplean las series de datos pertenecientes a la red sinóptica y climatológica del Instituto Nacional de Meteorología (INM) de España. Para optimizar la topología de la red neuronal y su rendimiento se realiza un tratamiento de datos previo a la aplicación del modelo. El modelo resultante se aplica a las series de datos de la variable temperatura mínima media mensual observadas en las estaciones de la red sinóptica y climatológica del INM en la meseta central española, proporcionando un alto grado de ajuste entre series reales y simuladas, según indican los valores de los coeficientes de determinación (R2) y error cuadrático medio (MSE) y las gráficas de dispersión y secuencia de las series reales y simuladas.]]></text><keywords><![CDATA[modelos de pronóstico, series climáticas, redes neuronales, perceptron multicapa, retropropagación]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. L. Labajo Izquierdo]]></normalized_name><name><![CDATA[Angel Luis]]></name><lastname><![CDATA[Labajo Izquierdo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[93]]></attendee_id><normalized_name><![CDATA[Q. Martín Martín]]></normalized_name><name><![CDATA[Quintín ]]></name><lastname><![CDATA[Martín Martín]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. L. Labajo Salazar]]></normalized_name><name><![CDATA[José Luis ]]></name><lastname><![CDATA[Labajo Salazar]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[94]]></id><identifier><![CDATA[VC7]]></identifier><name><![CDATA[Aplicaciones de la probabilidad]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[12:00:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[12]]></id><name><![CDATA[Sala Roma II]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[83]]></id><normalized_name><![CDATA[F. Belzunce Torregrosa]]></normalized_name><name><![CDATA[Félix]]></name><lastname><![CDATA[Belzunce Torregrosa]]></lastname></chairperson><papers><element><id><![CDATA[109]]></id><title><![CDATA[Condiciones suficientes para los órdenes vida media residual y tiempo medio de inactividad]]></title><text><![CDATA[La ordenación en  razón de fallo de dos variables aleatorias es una condición suficiente para la ordenación de dichas variables en el orden vida media residual. Una caracterización del orden razón de fallo es la monotonía del cociente de las funciones de supervivencia de las variables, sin embargo en muchos casos este cociente no es monótono por lo que las variables no están ordenadas en el orden razón de fallo. El objetivo de este trabajo es mostrar que, en algunas de estas situaciones, la no monotonía del cociente de las funciones de supervivencia es aún suficiente para la ordenación de las variables en vida media residual bajo ciertos supuestos no muy restrictivos.  Posteriormente se establecen algunos resultados relacionados y se generaliza la condición suficiente para dar una caracterización del orden vida media residual. Por último se desarrolla un estudio similar para el orden tiempo medio de inactividad.]]></text><keywords><![CDATA[orden razón de fallo, orden razón de fallo inverso, orden vida media residual, orden tiempo medio de inactividad, unimodalidad]]></keywords><authors><element><attendee_id><![CDATA[83]]></attendee_id><normalized_name><![CDATA[F. Belzunce Torregrosa]]></normalized_name><name><![CDATA[Félix]]></name><lastname><![CDATA[Belzunce Torregrosa]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[84]]></attendee_id><normalized_name><![CDATA[C. Martínez Riquelme]]></normalized_name><name><![CDATA[Carolina]]></name><lastname><![CDATA[Martínez Riquelme]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. M. Ruiz Gómez]]></normalized_name><name><![CDATA[José M.]]></name><lastname><![CDATA[Ruiz Gómez]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[194]]></id><title><![CDATA[Global dependence stochastic orders]]></title><text><![CDATA[Two basic ideas, that give rise to global dependence stochastic orders, are introduced and studied. The similarities and diffrences between the resulting global dependence orders, and the known common positive dependence orders, are discussed. Some desirable properties that global dependence orders may expected to satisfy are listed and checked. Three particular global dependence orders, that come up from the two general ideas, are studied in detail. It is shown, among other things, how these orders can be verified. Finally, some applications in auction theory, in reliability theory, and in economics, are described.]]></text><keywords><![CDATA[positive dependence, convex order, dispersive order, increasing rearrangement, Jensen's Inequality, auction theory, reliability theory, Gini covariance, Gini correlation, absolute concentration curve]]></keywords><authors><element><attendee_id><![CDATA[321]]></attendee_id><normalized_name><![CDATA[A. Suárez Llorens]]></normalized_name><name><![CDATA[Alfonso]]></name><lastname><![CDATA[Suárez Llorens]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[408]]></attendee_id><normalized_name><![CDATA[M. Á. Sordo Díaz]]></normalized_name><name><![CDATA[Miguel Ángel]]></name><lastname><![CDATA[Sordo Díaz]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Shaked]]></normalized_name><name><![CDATA[Moshe]]></name><lastname><![CDATA[Shaked]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[113]]></id><title><![CDATA[Condiciones suficientes para el orden right-spread]]></title><text><![CDATA[En este trabajo presentamos una condición suficiente para el orden right-spread, basada en el decrecimiento, inicialmente, y posteriormente crecimiento, de la diferencia de las funciones cuantiles.]]></text><keywords><![CDATA[orden right-spread, función cuantil.]]></keywords><authors><element><attendee_id><![CDATA[83]]></attendee_id><normalized_name><![CDATA[F. Belzunce Torregrosa]]></normalized_name><name><![CDATA[Félix]]></name><lastname><![CDATA[Belzunce Torregrosa]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[84]]></attendee_id><normalized_name><![CDATA[C. Martinez Riquelme]]></normalized_name><name><![CDATA[Carolina ]]></name><lastname><![CDATA[Martinez Riquelme]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[119]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[JEP-Clausura de las Jornadas de Estadística Pública]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[13:15:00]]></start><end><![CDATA[13:30:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[50]]></id><normalized_name><![CDATA[A. Alonso-Ayuso]]></normalized_name><name><![CDATA[Antonio ]]></name><lastname><![CDATA[Alonso-Ayuso]]></lastname></chairperson><papers/></element><element><id><![CDATA[124]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Reunión del Consejo Ejecutivo de la SEIO]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[13:30:00]]></start><end><![CDATA[14:30:00]]></end><location><id><![CDATA[19]]></id><name><![CDATA[Sala Magerit]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[68]]></id><normalized_name><![CDATA[J. M. Angulo Ibáñez]]></normalized_name><name><![CDATA[José Miguel]]></name><lastname><![CDATA[Angulo Ibáñez]]></lastname></chairperson><papers/></element><element><id><![CDATA[97]]></id><identifier><![CDATA[VD2]]></identifier><name><![CDATA[Técnicas de muestreo]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[6]]></id><name><![CDATA[Sala Bruselas]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[294]]></id><normalized_name><![CDATA[M. T. Cabero Morán]]></normalized_name><name><![CDATA[María Teresa]]></name><lastname><![CDATA[Cabero Morán]]></lastname></chairperson><papers><element><id><![CDATA[139]]></id><title><![CDATA[Estimadores de calibración con datos provenientes de marcos múltiples]]></title><text><![CDATA[En la teoría clásica de muestreo en poblaciones finitas, la muestra es seleccionada utilizando un diseño muestral probabilístico a partir de un marco muestral único. Sin embargo hay muchas situaciones reales en las que las encuestas utilizan varios marcos. Los trabajos más importantes en en la estimación de marcos múltiples son los de Hartley (1962) y Fuller y Burmeister (1972). En ambos casos los pesos de cada unidad dependen de  varianzas y covarianzas que deben ser estimadas a partir de los datos muestrales lo cual puede dar lugar a incoherencias entre las estimaciones. La finalidad de este trabajo es extender algunos procedimientos  importantes de estimación indirecta al caso de que los datos provengan de encuestas de marcos múltiples.  Se desarrollan estimadores de calibración utilizando el método de marco único (Kalton y Anderson, 1986).]]></text><keywords><![CDATA[multiple frames, calibration,  Fuller y Burmeister estimator]]></keywords><authors><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Arcos]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Arcos]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[164]]></id><title><![CDATA[Aplicación de la metodología bootstrap para la estimación de la movilidad de furgonetas]]></title><text><![CDATA[En este trabajo se muestran los resultados de la aplicación de la metodología  bootstrap a datos de 3369 encuestas realizadas en 2009 a nivel nacional entre conductores de furgonetas, para obtener datos de movilidad interurbana y total, según  edad de los vehículos, uso, conductores y otras  características de este tipo de vehículo. Se obtienen estimaciones puntuales e intervalos de confianza para la movilidad total de furgonetas, así como para los cuatro tipos de furgonetas según la clasificación realizada en el proyecto de referencia. Se comparan los resultados obtenidos con estimaciones alternativas realizadas con otras fuentes de datos para el mismo colectivo (encuestas realizadas en inspecciones en carretera realizadas por la ATGC de la DGT e inspecciones en ITV) y datos publicados por fuentes oficiales. Estos resultados de movilidad (en término de vehículo-kilómetro) se usarán para la estimación de ratios de accidentalidad en un estudio comparado con otros colectivos de vehículos.]]></text><keywords><![CDATA[técnicas de remuestreo (bootstrap), vehículo-kilómetro, movilidad, encuestas, furgonetas, accidentes]]></keywords><authors><element><attendee_id><![CDATA[187]]></attendee_id><normalized_name><![CDATA[E. Gallego Tellechea]]></normalized_name><name><![CDATA[Elisa]]></name><lastname><![CDATA[Gallego Tellechea]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Mira McWilliams]]></normalized_name><name><![CDATA[José]]></name><lastname><![CDATA[Mira McWilliams]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[F. Aparicio Izquierdo]]></normalized_name><name><![CDATA[Francisco]]></name><lastname><![CDATA[Aparicio Izquierdo]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[B. Arenas Ramínez]]></normalized_name><name><![CDATA[Blanca]]></name><lastname><![CDATA[Arenas Ramínez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Páez Ayuso]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Páez Ayuso]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[106]]></id><title><![CDATA[CALnYES 3.0: programa informático que calcula tamaños de muestra y estima]]></title><text><![CDATA[CALnYES 3.0 es un programa informático que completa y mejora la versión anterior para calcular tamaños de muestra en muestreo aleatorio simple, estratificado, muestreo por conglomerados, por conglomerados mezclado con estratificado, con las distintas posibilidades de afijaciones por estratos. Además, incluye el cálculo de tamaños de muestra en muestreo directo e inverso para la estimación de tamaños de población. A la segunda parte, en la que se hacía estimaciones puntuales y por intervalos a partir de la confianza elegida por el usuario en los dos primeros tipos de muestreo mencionados, se añade la estimación en conglomerados y del tamaño de la población. La aplicación ofrece las posibilidades necesarias para los distintos casos tanto para calcular el tamaño de muestra como para estimar. En definitiva presenta una forma sencilla, rápida y cómoda de hacer los cálculos indicados. La optimización está asegurada sin tener que invertir mucho tiempo con operaciones y fórmulas.]]></text><keywords><![CDATA[tamaño de muestra, estimación]]></keywords><authors><element><attendee_id><![CDATA[294]]></attendee_id><normalized_name><![CDATA[M. T. Cabero Morán]]></normalized_name><name><![CDATA[María Teresa]]></name><lastname><![CDATA[Cabero Morán]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Mecoleta Finó]]></normalized_name><name><![CDATA[Santiago]]></name><lastname><![CDATA[Mecoleta Finó]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[312]]></attendee_id><normalized_name><![CDATA[M. García Martín]]></normalized_name><name><![CDATA[Martín]]></name><lastname><![CDATA[García Martín]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[100]]></id><identifier><![CDATA[VD3]]></identifier><name><![CDATA[Estadística espacial y espacio-temporal 2]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[8]]></id><name><![CDATA[Sala Londres]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[399]]></id><normalized_name><![CDATA[M. Ferrán Aranaz]]></normalized_name><name><![CDATA[Magdalena]]></name><lastname><![CDATA[Ferrán Aranaz]]></lastname></chairperson><papers><element><id><![CDATA[191]]></id><title><![CDATA[Alternative models to smooth risks in space-time disease mapping]]></title><text><![CDATA[Lately, alternative models are been used to smooth risks (rates)  in space-time disease mapping. The more classical models are temporal extensions of the well-known conditional autoregressive (CAR) model (Besag et al., 1991). Spatio-temporal models including penalized splines have been also considered (Ugarte et al., 2010). In this work, we aim at analyzing temporal trends and geographical inequalities of colorectal cancer mortality in the provinces of Spain during the period (1975-2008) by age-groups and gender using alternative models. This particular data set will be used for discussing different features of these models. The interaction between random regions effects and time will be also discussed.]]></text><keywords><![CDATA[spatio-temporal patterns, CAR models, P-spline models, colorectal cancer]]></keywords><authors><element><attendee_id><![CDATA[366]]></attendee_id><normalized_name><![CDATA[J. Etxeberria Andueza]]></normalized_name><name><![CDATA[Jaione]]></name><lastname><![CDATA[Etxeberria Andueza]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[370]]></attendee_id><normalized_name><![CDATA[M. D. Ugarte Martínez]]></normalized_name><name><![CDATA[María Dolores ]]></name><lastname><![CDATA[Ugarte Martínez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[T. Goicoa Mangado]]></normalized_name><name><![CDATA[Tomás]]></name><lastname><![CDATA[Goicoa Mangado]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[384]]></attendee_id><normalized_name><![CDATA[A. Fernández Militino]]></normalized_name><name><![CDATA[Ana]]></name><lastname><![CDATA[Fernández Militino]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[249]]></id><title><![CDATA[Agrupación de series temporales geográficas: Una metodología para la construcción de los centroides iniciales del algoritmo de las k-medias ]]></title><text><![CDATA[En este trabajo se presenta una metodología para la comparación de series temporales geográficas. Para ilustrarla realizaremos una aplicación al Sector de la Construcción Residencial, siendo el objetivo el de agrupar las series temporales provinciales de oferta de vivienda nueva. La metodología que se propone, a la que denominaremos Metodología del haz de rectas, consiste básicamente en construir K series resumen que se utilizarán como centroides iniciales del Algoritmo de las k-medias para un Análisis Cluster de Series Temporales. La solución obtenida permitirá interpretar las similitudes y diferencias entre las distintas series temporales provinciales de oferta de vivienda nueva, aspecto de gran utilidad como paso previo a la aplicación de cualquier modelo estadístico o económico que persiga objetivos tanto de tipo explicativo como de tipo predictivo.]]></text><keywords><![CDATA[series temporales geográficas, análisis cluster, algoritmo de las k-medias, centroides iniciales]]></keywords><authors/></element><element><id><![CDATA[124]]></id><title><![CDATA[Vigilancia epidemiológica mediante modelos jerárquicos Bayesianos espacio-temporales]]></title><text><![CDATA[La capacidad de detectar rápidamente el inicio de epidemias es fundamental para llevar a cabo una intervención eficaz y mitigar así los efectos socio-económicos derivados de brotes epidémicos. En este trabajo desarrollamos una metodología de vigilancia epidemiológica on-line para la detección temprana de cambios en la incidencia de enfermedades. Dentro del marco de los modelos jerárquicos bayesianos espacio-temporales, mostramos como la ordenada predictiva condicional (CPO), medida bayesiana de diagnóstico que permite detectar observaciones discrepantes, puede ser adaptada en un contexto de vigilancia para detectar zonas geográficas donde el número total de casos observados es significativamente mayor al número de casos esperados. La metodología propuesta es aplicada a datos mensuales de intoxicación por Salmonella en los diferentes condados de Carolina del Sur (Estados Unidos).]]></text><keywords><![CDATA[vigilancia epidemiológica, datos espacio-temporales, modelos bayesianos jerárquicos, ordenada predictiva condicional]]></keywords><authors><element><attendee_id><![CDATA[327]]></attendee_id><normalized_name><![CDATA[A. Corberán Vallet]]></normalized_name><name><![CDATA[Ana]]></name><lastname><![CDATA[Corberán Vallet]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. B. Lawson]]></normalized_name><name><![CDATA[Andrew B ]]></name><lastname><![CDATA[Lawson]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[43]]></id><identifier><![CDATA[VD4]]></identifier><name><![CDATA[Análisis envolvente de datos]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[9]]></id><name><![CDATA[Sala París]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[63]]></id><normalized_name><![CDATA[C. Simon de Blas]]></normalized_name><name><![CDATA[Clara]]></name><lastname><![CDATA[Simon de Blas]]></lastname></chairperson><papers><element><id><![CDATA[78]]></id><title><![CDATA[Analyzing technical efficiency: A new directional non-parametrical utility function approach]]></title><text><![CDATA[The efficiency in production has been often analysed in the field of technical efficiency through the production frontier function. As far as we known, efficiency scores are usually based on distances to the frontier in an m+s dimensional space, where m inputs produce s outputs. And efficiency improvements regard to the total consumption of each input. However, in many cases, each input is detached in its own stages and trade–off among them is possible. If the firms have this common framework, it can be used for computing efficiency. Such analysis also provides the most efficient assignment in each stage. This paper studies technical efficiency with this focusing. A non–parametrical methodology and an input oriented Multicriteria Linear Programming model (MLP) are proposed. The analysis is detailed to global, input and stage levels; defining the satisfaction achieved at each level for each firm about its utility function. Thus, MLP offers detailed information for better helping firms.]]></text><keywords><![CDATA[multicriteria and linear programming models, DEA models, efficiency and production processes]]></keywords><authors><element><attendee_id><![CDATA[252]]></attendee_id><normalized_name><![CDATA[D. Alcaide López de Pablo]]></normalized_name><name><![CDATA[David]]></name><lastname><![CDATA[Alcaide López de Pablo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[280]]></attendee_id><normalized_name><![CDATA[R. Dios-Palomares]]></normalized_name><name><![CDATA[Rafaela]]></name><lastname><![CDATA[Dios-Palomares]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[Á. M. Prieto]]></normalized_name><name><![CDATA[Ángel M.]]></name><lastname><![CDATA[Prieto]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[141]]></id><title><![CDATA[Una medida de eficiencia técnica bien definida en DEA asociada a la proyección eficiente más próxima]]></title><text><![CDATA[El problema de determinar la proyección eficiente más próxima a una unidad  técnicamente ineficiente dada ha sido uno de los temas más relevantes en los últimos tiempos en la literatura asociada al Análisis Envolvente de Datos (DEA en inglés). Uno de los retos relacionados con este tema es el de hallar una medida de eficiencia técnica ``bien definida''. En términos generales eso significa que la medida debería satisfacer una serie de propiedades, entre ellas la monotonía fuerte. Así, una cuestión todavía sin solución es si existe o no una medida de eficiencia en DEA bien definida asociada a la proyección eficiente más próxima. En este artículo, mostramos una solución parcial para medidas orientadas al output basada en la medida de Russell.]]></text><keywords><![CDATA[análisis envolvente de datos, proyección más próxima, propiedad de monotonía]]></keywords><authors><element><attendee_id><![CDATA[336]]></attendee_id><normalized_name><![CDATA[J. Aparicio Baeza]]></normalized_name><name><![CDATA[Juan]]></name><lastname><![CDATA[Aparicio Baeza]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[92]]></id><title><![CDATA[Cambios en la productividad de bibliotecas de universidades españolas]]></title><text><![CDATA[This work analyzes productivity growth, technical progress, and efficiency change in a sample of 34 Spanish university libraries between 2003 and 2007. Data envelopment analysis and a Malmquist index are combined with a bootstrap method to provide statistical inference estimators of individual productivity, technical progress, pure efficiency, and scale efficiency scores. To calculate productivity, a three-stage service model has been developed, examining productivity changes in the relationships between the libraries’ basic inputs, intermediate outputs, and final outputs. The results indicate a growth in the productivity of the libraries and in the productivity of the service. The growth in productivity in both relationships is due to technical progress. If the variable representing the use of electronic information resources is removed from the final output, the result is a significant reduction in productivity.]]></text><keywords><![CDATA[DEA, indice de malmquist]]></keywords><authors><element><attendee_id><![CDATA[63]]></attendee_id><normalized_name><![CDATA[C. Simon de Blas]]></normalized_name><name><![CDATA[Clara]]></name><lastname><![CDATA[Simon de Blas]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[J. Simón Martin]]></normalized_name><name><![CDATA[Jose]]></name><lastname><![CDATA[Simón Martin]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[A. Arias Coello]]></normalized_name><name><![CDATA[Alicia]]></name><lastname><![CDATA[Arias Coello]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[51]]></id><identifier><![CDATA[VD5]]></identifier><name><![CDATA[Optimización bajo incertidumbre]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[10]]></id><name><![CDATA[Sala Viena]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[382]]></id><normalized_name><![CDATA[C. Pizarro Romero]]></normalized_name><name><![CDATA[Celeste]]></name><lastname><![CDATA[Pizarro Romero]]></lastname></chairperson><papers><element><id><![CDATA[200]]></id><title><![CDATA[An improvement of the large-scale energy plan for Angola. An application of two-stage stochastic optimization]]></title><text><![CDATA[We present important improvements to Angola’s energy plan applying a two-stage stochastic linear optimization model with continuous variables to maximize profit considering a risk neutral strategy and the uncertainty of the main parameters in the second stages. The model covers hydropower generation, the actual 36.4\% share of crude oil exploitation by the government against the international companies and, additionally, starting to produce 22.8\% of natural gas and maintaining the actual 20\% of non-technical losses in electricity consumption under three major scenarios of production capacity and demand for the time horizons periods 2012 and average of 2013-2015, and 2016 and average 2017-2020. Considering the sensitivity analyzes of these time horizons, a government increase on investment, it results in increases of 152.27\% in the government profit for the first stage and an estimate of 149.11\% per year of the second stage.]]></text><keywords><![CDATA[energy planning, optimal energy mix, stochastic optimization, sensitivity analysis, Angola]]></keywords><authors><element><attendee_id><![CDATA[291]]></attendee_id><normalized_name><![CDATA[A. R. N. Simbo]]></normalized_name><name><![CDATA[Alcides Romualdo Neto]]></name><lastname><![CDATA[Simbo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[59]]></attendee_id><normalized_name><![CDATA[L. F. Escudero Bueno]]></normalized_name><name><![CDATA[Laureano F.]]></name><lastname><![CDATA[Escudero Bueno]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[446]]></attendee_id><normalized_name><![CDATA[D. Ríos Insua]]></normalized_name><name><![CDATA[David ]]></name><lastname><![CDATA[Ríos Insua]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[120]]></id><title><![CDATA[MPI parallel programming for solving a large number of mixed integer optimization problems using CPLEX within COIN-OR]]></title><text><![CDATA[The aim of this paper is firstly to help to understand the paradigm of parallel programming for solving a sequence of mixed integer optimization problems and secondly to present some detailed explanations about its practical implementation. We have developed a C++ experimental code that uses the IBM ILOG CPLEX optimizer within the COmputational INfrastructure for Operations Research (COIN-OR) and the Message Passing Interface (MPI) library for the distributed memory environment. The practical experiments have been performed at the ARINA computational cluster provided by the SGI/IZO-SGIker at the UPV/EHU and report the optimization of 44 asymmetric problems by using different parallelization strategies and number of threads. Also, we extend this analysis to the resolution of a testbed of multistage stochastic mixed 0-1 instances that have been used as a pilot case for testing our exact decomposition algorithm Branch and Fix Coordination Multistage (BFC-MS).]]></text><keywords><![CDATA[optimization, message passing interface, parallel computing, COIN-OR, CPLEX]]></keywords><authors><element><attendee_id><![CDATA[253]]></attendee_id><normalized_name><![CDATA[U. Aldasoro Marcellan]]></normalized_name><name><![CDATA[Unai]]></name><lastname><![CDATA[Aldasoro Marcellan]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[59]]></attendee_id><normalized_name><![CDATA[L. F. Escudero Bueno]]></normalized_name><name><![CDATA[Laureano F.]]></name><lastname><![CDATA[Escudero Bueno]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[M. Merino Maestre]]></normalized_name><name><![CDATA[María]]></name><lastname><![CDATA[Merino Maestre]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[G. Pérez Sainz de Rozas]]></normalized_name><name><![CDATA[Gloria]]></name><lastname><![CDATA[Pérez Sainz de Rozas]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[190]]></id><title><![CDATA[A parallel computing metaheuristic algorithm for solving multistage stochastic mixed integer programs]]></title><text><![CDATA[We present an inexact algorithm for solving huge instances of multistage mixed integer optimization problems under uncertainty, represented by multistage scenarios trees. The algorithm is based on a metaheuristic methodology since in an iterative way repeatedly solves at each node of the tree up to optimality an stochastic multistage mixed integer model for the subtree whose root-node is the given node related to the scenario group in the original scenario tree. This multistage submodel to solve will relax in each optimization the non-anticipativity constraints related to the successor nodes of the nodes in the subtree that the modeler selects for being considered without any relaxation of the constraints in the problem.]]></text><keywords><![CDATA[stochastic mixed integer, optimization, heuristics, metaheuristics, parallel concurrent programming]]></keywords><authors><element><attendee_id><![CDATA[373]]></attendee_id><normalized_name><![CDATA[P. Olaso Redondo]]></normalized_name><name><![CDATA[Pablo]]></name><lastname><![CDATA[Olaso Redondo]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[50]]></attendee_id><normalized_name><![CDATA[A. Alonso-Ayuso]]></normalized_name><name><![CDATA[Antonio]]></name><lastname><![CDATA[Alonso-Ayuso]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[59]]></attendee_id><normalized_name><![CDATA[L. F. Escudero Bueno]]></normalized_name><name><![CDATA[Laureano F.]]></name><lastname><![CDATA[Escudero Bueno]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[382]]></attendee_id><normalized_name><![CDATA[C. Pizarro Romero]]></normalized_name><name><![CDATA[Celeste]]></name><lastname><![CDATA[Pizarro Romero]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[93]]></id><identifier><![CDATA[VD6]]></identifier><name><![CDATA[Modelos estadisticos 3]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[11]]></id><name><![CDATA[Sala Roma I]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[326]]></id><normalized_name><![CDATA[B. Sinova Fernández]]></normalized_name><name><![CDATA[Beatriz]]></name><lastname><![CDATA[Sinova Fernández]]></lastname></chairperson><papers><element><id><![CDATA[258]]></id><title><![CDATA[Métodos de decisión en la evaluación de las predicciones]]></title><text><![CDATA[La mayoría de las técnicas de evaluación de las funciones de densidad de las predicciones (fdp) se han desarrollado en un marco estadístico: el criterio de información Kullback-Leibler, Hall y Mitchell (2005), el criterio de apuntamiento de Gneiting, Balabdaoui y Raftery (2007) y a través de las pit's, Rosenblatt (1952). Estas técnicas no tienen en cuenta el propósito para el que se ha realizado la predicción. En este trabajo consideramos un enfoque más general para evaluar las fdp siguiendo los trabajos de Granger (1999), Pesaran y Skouras (2000), Granger y Pesaran (1996), Granger y Machina (2007) o Granger y Pesaran (1999) utilizando cuatro vías: 1) Dominación estocástica de segundo orden, Machina y Pratt (1997), Rothschild y Stiglitz (1980), Klecan, L.; MacFadden, R. y McFadden, D. (1991);  2) Dominación estocástica de pérdida convexa, 3) valor monetario esperado y 4) Utilidad esperada, Von Neumann y Morgenstern (1944) y Luce y Raiffa (1957) aplicados al IPCA de la eurozona.]]></text><keywords><![CDATA[evaluación de las predicciones, dominación estocástica, utilidad esperada y valor monetario esperado]]></keywords><authors/></element><element><id><![CDATA[311]]></id><title><![CDATA[Eficiencia de los contrastes tipo Phi-divergencias para modelos loglineales con restricciones de orden]]></title><text><![CDATA[Se consideran dos variables categóricas ordenadas  X e Y y se desea contrastar si los ``local odds ratios'' son iguales a uno frente a que son mayores que uno. Se utiliza la parametrización dada a través de un modelo loglineal saturado. Con el fin de realizar el contraste de hipótesis se considera como estadistico de contraste distancias entre el vector de probabilidades del modelo loglineal evaluado en el estimador que se obtiene sin ninguna restricción y el estimador que se obtiene bajo la hipótesis nula. Esta familia de distancias contiene al test del cociente de verosimilitudes como caso paticular. El trabajo establece que para tamaños muestrales pequeños o moderados se pueden conseguir estadisticos de contraste que dan lugar a tests mas eficientes que el del cociente de verosimilitudes.]]></text><keywords><![CDATA[contraste de hipótesis, restricciones de desigualdad, distribución Ji-barra]]></keywords><authors><element><attendee_id><![CDATA[293]]></attendee_id><normalized_name><![CDATA[N. Martin Apaolaza]]></normalized_name><name><![CDATA[Nirian]]></name><lastname><![CDATA[Martin Apaolaza]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[523]]></attendee_id><normalized_name><![CDATA[L. Pardo Llorente]]></normalized_name><name><![CDATA[Leandro]]></name><lastname><![CDATA[Pardo Llorente]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[524]]></attendee_id><normalized_name><![CDATA[R. Mata Crespo]]></normalized_name><name><![CDATA[Raquel]]></name><lastname><![CDATA[Mata Crespo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[166]]></id><title><![CDATA[M-estimadores para los números difusos aleatorios]]></title><text><![CDATA[El empleo de la escala de números difusos permite, mediante un cómodo manejo, capturar la imprecisión subyacente a numerosos experimentos aleatorios realizados en campos del saber tan diversos como las Ciencias Sociales, la Medicina o las Ingenierías. La medida resumen de tendencia central más usual para los datos difusos es la esperanza tipo Aumann, pero debido a su excesiva sensibilidad al cambio de datos o la existencia de valores extremos, se han propuesto medidas más robustas como la mediana o las medias recortadas. El objetivo de este trabajo ha sido introducir el concepto de M-estimador, tan útil en el caso real y espacios más generales, para los números difusos aleatorios y compararlo con las medidas resumen ya existentes.]]></text><keywords><![CDATA[número difuso aleatorio, M-estimador, mediana, media recortada, robustez]]></keywords><authors><element><attendee_id><![CDATA[326]]></attendee_id><normalized_name><![CDATA[B. Sinova Fernández]]></normalized_name><name><![CDATA[Beatriz]]></name><lastname><![CDATA[Sinova Fernández]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[549]]></attendee_id><normalized_name><![CDATA[M. Á. Gil]]></normalized_name><name><![CDATA[María Ángeles]]></name><lastname><![CDATA[Gil]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[G. González Rodríguez]]></normalized_name><name><![CDATA[Gil]]></name><lastname><![CDATA[González Rodríguez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[S. Van Aelst]]></normalized_name><name><![CDATA[Stefan]]></name><lastname><![CDATA[Van Aelst]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element></papers></element><element><id><![CDATA[88]]></id><identifier><![CDATA[VD7]]></identifier><name><![CDATA[Modelos estocásticos]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[15:30:00]]></start><end><![CDATA[16:30:00]]></end><location><id><![CDATA[12]]></id><name><![CDATA[Sala Roma II]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><id><![CDATA[359]]></id><normalized_name><![CDATA[J. Villarroel Rodriguez]]></normalized_name><name><![CDATA[Javier]]></name><lastname><![CDATA[Villarroel Rodriguez ]]></lastname></chairperson><papers><element><id><![CDATA[206]]></id><title><![CDATA[Distribuciones cuasi-estacionarias en modelos estocásticos SIR de epidemias]]></title><text><![CDATA[Los modelos susceptible-infected-removed (SIR) explican la evolución de una epidemia en términos de una cadena de Markov absorbente. En este contexto la distribución límite es degenerada por lo que habitualmente se describe el comportamiento del modelo antes de la absorción en términos de la distribución cuasi-estacionaria. En esta charla se analizan dos cuestiones: i) la distribución del cociente de medias como alternativa a la cuasi-estacionaridad, y ii) la determinación del subconjunto de estados con probabilidad cuasi-estacionaria positiva, cuando el subconjunto de estados transitorios es reducible.]]></text><keywords><![CDATA[modelos SIR de epidemias, distribución cuasi-estacionaria]]></keywords><authors/></element><element><id><![CDATA[125]]></id><title><![CDATA[Sobre la identificabilidad del proceso de llegadas Markoviano en grupo con dos estados]]></title><text><![CDATA[En la literatura sobre procesos puntuales y modelos de colas se introdujo el proceso BMAP (Batch Markovian arrival process) porque reúne propiedades interesantes en la modelización de datos en diversos contextos como fiabilidad, ingeniería o finanzas. Desde el punto de vista teórico estos procesos son más flexibles que los clásicos porque permiten llegadas dependientes, no exponenciales y además llegadas en grupos que también pueden ser dependientes. Existen muchos trabajos dedicados a estudiar las propiedades probabilísticas de estos modelos, pero pocas referencias que consideren la estimación del proceso BMAP debido a problemas de sobreparametrización y falta de identificabilidad que suelen caracterizar a los modelos markovianos ocultos (Hidden Markov Models), la información observada es parcial. En esta charla probaremos que a diferencia del MAP, el BMAP con dos estados es identificable, asumiendo que la información observada son los tiempos entre llegadas y el tamaño de las mismas.]]></text><keywords><![CDATA[proceso Markoviano con llegadas en grupo (BMAP), problemas de identificabilidad]]></keywords><authors><element><attendee_id><![CDATA[318]]></attendee_id><normalized_name><![CDATA[J. V. Rodríguez César]]></normalized_name><name><![CDATA[Joanna Virginia]]></name><lastname><![CDATA[Rodríguez César]]></lastname><submitter><![CDATA[1]]></submitter></element><element><attendee_id><![CDATA[]]></attendee_id><normalized_name><![CDATA[R. E. Lillo Rodriguez]]></normalized_name><name><![CDATA[Rosa Elvira]]></name><lastname><![CDATA[Lillo Rodriguez]]></lastname><submitter><![CDATA[0]]></submitter></element><element><attendee_id><![CDATA[292]]></attendee_id><normalized_name><![CDATA[P. Ramirez Cobo]]></normalized_name><name><![CDATA[Pepa]]></name><lastname><![CDATA[Ramirez Cobo]]></lastname><submitter><![CDATA[0]]></submitter></element></authors></element><element><id><![CDATA[264]]></id><title><![CDATA[Exit times of general renewal and point processes]]></title><text><![CDATA[Renewal processes are generalizations of the classical (compound) Poisson process where  the waiting times are iidrv with  general distribution.  Let $X_t$ be such a process. We consider the issue  of how  those statistics contingent on the actual state-like exit times- are affected depending on whether the actual time is or not a jump time. We suppose that the  only available information is the present state $X_r=x$. The answer involves ideas drawn from classical renewal theory. Implications  to  risk theory are clear: by allowing the classical Lundberg-Cramer model  to have arbitrary i.i.d. holding times  those results derived at jump times will not carry over to arbitrary present due to the lack of Markoviannes. In particular exit times depend on the actual stateand available information. Here we consider mean ruin times assuming that the present is not necessarily a jump instant, and also a partial knowledge from the observer.]]></text><keywords><![CDATA[renewal processes, waiting times, mean exit times]]></keywords><authors/></element></papers></element><element><id><![CDATA[130]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Pausa]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[16:30:00]]></start><end><![CDATA[16:45:00]]></end><location><![CDATA[]]></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[37]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Asamblea SEIO]]></name><description><![CDATA[La entrega del Premio Ramiro Melendreras tendrá lugar al final de la Asamblea]]></description><comments><![CDATA[]]></comments><start><![CDATA[16:45:00]]></start><end><![CDATA[18:45:00]]></end><location><id><![CDATA[5]]></id><name><![CDATA[Salón Madrid]]></name><venue><![CDATA[Hotel NH Eurobuilding]]></venue><gps_coords><![CDATA[40.45824,-3.685814]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element><element><id><![CDATA[41]]></id><identifier><![CDATA[]]></identifier><name><![CDATA[Cena de clausura]]></name><description><![CDATA[]]></description><comments><![CDATA[]]></comments><start><![CDATA[21:00:00]]></start><end><![CDATA[00:00:00]]></end><location><id><![CDATA[15]]></id><name><![CDATA[Hotel Melia Princesa]]></name><venue><![CDATA[Hotel Meliá Princesa]]></venue><gps_coords><![CDATA[40.427441,-3.713963]]></gps_coords></location><chairperson><![CDATA[]]></chairperson><papers/></element></sessions></element></root>